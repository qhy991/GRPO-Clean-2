#!/usr/bin/env python3
"""ç®€å•æµ‹è¯•è®¾å¤‡ä¿®å¤æ˜¯å¦æœ‰æ•ˆ"""

import torch
import os
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_device_fix():
    """æµ‹è¯•è®¾å¤‡ä¿®å¤"""
    print("ğŸ”§ æµ‹è¯•è®¾å¤‡ä¿®å¤...")
    
    # æ£€æŸ¥GPU
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨")
        return False
    
    gpu_count = torch.cuda.device_count()
    print(f"ğŸ“Š æ£€æµ‹åˆ° {gpu_count} å¼ GPU")
    
    if gpu_count < 2:
        print("âš ï¸ GPUæ•°é‡ä¸è¶³ï¼Œæ— æ³•æµ‹è¯•æ¨¡å‹å¹¶è¡Œ")
        return False
    
    # æ¨¡æ‹ŸGRPOä¸­çš„é”™è¯¯æƒ…å†µ
    print("ğŸ§ª æ¨¡æ‹ŸGRPOé”™è¯¯æƒ…å†µ...")
    
    try:
        # åˆ›å»ºä¸åŒè®¾å¤‡ä¸Šçš„å¼ é‡
        is_eos = torch.tensor([[True, False, True], [False, True, False]]).cuda(1)
        eos_idx = torch.zeros(2, dtype=torch.long).cuda(0)
        
        print(f"  - is_eosè®¾å¤‡: {is_eos.device}")
        print(f"  - eos_idxè®¾å¤‡: {eos_idx.device}")
        
        # è¿™ä¼šå¯¼è‡´é”™è¯¯ï¼šExpected all tensors to be on the same device
        try:
            eos_idx[is_eos.any(dim=1)] = is_eos.int().argmax(dim=1)[is_eos.any(dim=1)]
            print("âŒ æ„å¤–ï¼šé”™è¯¯æ“ä½œæˆåŠŸäº†")
            return False
        except RuntimeError as e:
            if "Expected all tensors to be on the same device" in str(e):
                print("âœ… ç¡®è®¤ï¼šé‡ç°äº†GRPOé”™è¯¯")
                print(f"  é”™è¯¯ä¿¡æ¯: {e}")
                
                # æµ‹è¯•ä¿®å¤æ–¹æ³•
                print("ğŸ”§ æµ‹è¯•ä¿®å¤æ–¹æ³•...")
                
                # æ–¹æ³•1ï¼šç»Ÿä¸€è®¾å¤‡
                is_eos_fixed = is_eos.to(eos_idx.device)
                eos_idx[is_eos_fixed.any(dim=1)] = is_eos_fixed.int().argmax(dim=1)[is_eos_fixed.any(dim=1)]
                print("âœ… ä¿®å¤æ–¹æ³•1æˆåŠŸï¼šç»Ÿä¸€è®¾å¤‡")
                
                # æ–¹æ³•2ï¼šå¼ºåˆ¶åˆ°cuda:0
                is_eos_cuda0 = is_eos.to('cuda:0')
                eos_idx_cuda0 = eos_idx.to('cuda:0')
                eos_idx_cuda0[is_eos_cuda0.any(dim=1)] = is_eos_cuda0.int().argmax(dim=1)[is_eos_cuda0.any(dim=1)]
                print("âœ… ä¿®å¤æ–¹æ³•2æˆåŠŸï¼šå¼ºåˆ¶cuda:0")
                
                return True
            else:
                print(f"âŒ å…¶ä»–é”™è¯¯: {e}")
                return False
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_import_pipeline():
    """æµ‹è¯•å¯¼å…¥ç®¡é“"""
    print("ğŸ”§ æµ‹è¯•å¯¼å…¥è®­ç»ƒç®¡é“...")
    
    try:
        from main import GRPOTrainingPipeline
        print("âœ… æˆåŠŸå¯¼å…¥GRPOTrainingPipeline")
        return True
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹è®¾å¤‡ä¿®å¤æµ‹è¯•...")
    
    success = True
    
    # æµ‹è¯•è®¾å¤‡ä¿®å¤
    if not test_device_fix():
        success = False
    
    # æµ‹è¯•å¯¼å…¥
    if not test_import_pipeline():
        success = False
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è®¾å¤‡ä¿®å¤åº”è¯¥æœ‰æ•ˆ")
        print("ğŸ’¡ å»ºè®®ï¼šé‡æ–°è¿è¡Œè®­ç»ƒè„šæœ¬æµ‹è¯•ä¿®å¤æ•ˆæœ")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    sys.exit(0 if success else 1) 