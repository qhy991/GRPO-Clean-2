#!/usr/bin/env python3
"""æµ‹è¯•EOSé”™è¯¯ä¿®å¤çš„ç®€å•è„šæœ¬"""

import torch
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_batch_type_detection():
    """æµ‹è¯•æ‰¹æ¬¡ç±»å‹æ£€æµ‹"""
    logger.info("ğŸ§ª æµ‹è¯•æ‰¹æ¬¡ç±»å‹æ£€æµ‹...")
    
    # æµ‹è¯•å­—å…¸ç±»å‹
    dict_batch = {'input_ids': torch.randn(2, 10)}
    logger.info(f"å­—å…¸æ‰¹æ¬¡: {type(dict_batch)}")
    logger.info(f"æ˜¯å¦ä¸ºå­—å…¸: {isinstance(dict_batch, dict)}")
    
    # æµ‹è¯•å…ƒç»„ç±»å‹
    tuple_batch = (torch.randn(2, 10), torch.randn(2, 10))
    logger.info(f"å…ƒç»„æ‰¹æ¬¡: {type(tuple_batch)}")
    logger.info(f"æ˜¯å¦ä¸ºå­—å…¸: {isinstance(tuple_batch, dict)}")
    
    # æµ‹è¯•åˆ—è¡¨ç±»å‹
    list_batch = [torch.randn(2, 10), torch.randn(2, 10)]
    logger.info(f"åˆ—è¡¨æ‰¹æ¬¡: {type(list_batch)}")
    logger.info(f"æ˜¯å¦ä¸ºå­—å…¸: {isinstance(list_batch, dict)}")
    
    # æµ‹è¯•å¼ é‡ç±»å‹
    tensor_batch = torch.randn(2, 10)
    logger.info(f"å¼ é‡æ‰¹æ¬¡: {type(tensor_batch)}")
    logger.info(f"æ˜¯å¦ä¸ºå­—å…¸: {isinstance(tensor_batch, dict)}")
    logger.info(f"å¼ é‡æ˜¯å¦æœ‰toæ–¹æ³•: {hasattr(tensor_batch, 'to')}")

def simulate_device_error_handling():
    """æ¨¡æ‹Ÿè®¾å¤‡é”™è¯¯å¤„ç†"""
    logger.info("ğŸ§ª æ¨¡æ‹Ÿè®¾å¤‡é”™è¯¯å¤„ç†...")
    
    # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„batch
    test_batches = [
        {'input_ids': torch.randn(2, 10, device='cuda:0'), 'attention_mask': torch.ones(2, 10, device='cuda:0')},
        (torch.randn(2, 10, device='cuda:0'), torch.randn(2, 10, device='cuda:0')),
        [torch.randn(2, 10, device='cuda:0'), torch.randn(2, 10, device='cuda:0')],
        torch.randn(2, 10, device='cuda:0')
    ]
    
    def enhanced_fallback_wrapper(batch):
        """å¢å¼ºçš„é”™è¯¯å¤„ç†åŒ…è£…å™¨ï¼ˆå¤åˆ¶è‡ªmain.pyï¼‰"""
        try:
            # æ¨¡æ‹Ÿè®¾å¤‡é”™è¯¯
            raise RuntimeError("Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0!")
        except RuntimeError as e:
            if "Expected all tensors to be on the same device" in str(e):
                logger.warning(f"ğŸ”§ GRPOé”™è¯¯å›é€€ï¼šæ£€æµ‹åˆ°è®¾å¤‡ä¸ä¸€è‡´é”™è¯¯: {e}")
                
                # å°è¯•å¼ºåˆ¶æ‰€æœ‰å¼ é‡åˆ°cuda:0
                try:
                    logger.info("ğŸ”§ é”™è¯¯å›é€€ï¼šå°è¯•å¼ºåˆ¶æ‰€æœ‰å¼ é‡åˆ°cuda:0")
                    if hasattr(batch, 'to'):
                        unified_batch = batch.to('cuda:0')
                    elif isinstance(batch, dict):
                        unified_batch = {}
                        for k, v in batch.items():
                            if torch.is_tensor(v):
                                unified_batch[k] = v.to('cuda:0', non_blocking=True)
                            else:
                                unified_batch[k] = v
                    elif isinstance(batch, (list, tuple)):
                        unified_batch = []
                        for item in batch:
                            if torch.is_tensor(item):
                                unified_batch.append(item.to('cuda:0', non_blocking=True))
                            else:
                                unified_batch.append(item)
                        unified_batch = type(batch)(unified_batch)
                    else:
                        logger.warning(f"âš ï¸ æœªçŸ¥çš„batchç±»å‹: {type(batch)}")
                        raise e
                    
                    logger.info(f"âœ… æˆåŠŸå¤„ç† {type(batch)} ç±»å‹çš„batch")
                    return {"status": "success", "batch_type": type(batch).__name__}
                    
                except Exception as fallback_e:
                    logger.error(f"âŒ é”™è¯¯å›é€€ä¹Ÿå¤±è´¥: {fallback_e}")
                    # æœ€åçš„å®‰å…¨æªæ–½ï¼šè¿”å›ç©ºç»“æœ
                    if isinstance(batch, dict) and 'input_ids' in batch:
                        batch_size = batch['input_ids'].shape[0]
                        return {
                            'sequences': batch['input_ids'].to('cuda:0'),
                            'logprobs': torch.zeros(batch_size, device='cuda:0'),
                            'ref_logprobs': torch.zeros(batch_size, device='cuda:0'),
                            'values': torch.zeros(batch_size, device='cuda:0')
                        }
                    else:
                        raise e
            else:
                raise e
    
    # æµ‹è¯•æ‰€æœ‰ç±»å‹çš„batch
    for i, batch in enumerate(test_batches):
        logger.info(f"\næµ‹è¯•æ‰¹æ¬¡ {i+1}: {type(batch)}")
        try:
            result = enhanced_fallback_wrapper(batch)
            logger.info(f"âœ… å¤„ç†æˆåŠŸ: {result}")
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    if not torch.cuda.is_available():
        logger.error("âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
        return
    
    logger.info("ğŸš€ å¼€å§‹EOSé”™è¯¯ä¿®å¤æµ‹è¯•...")
    
    test_batch_type_detection()
    print("\n" + "="*50 + "\n")
    simulate_device_error_handling()
    
    logger.info("\nâœ… æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main() 