#!/bin/bash
# run_enhanced_grpo_training_multi_gpu_fixed.sh - ä¿®å¤ç‰ˆå¤šGPUæ¨¡å‹å¹¶è¡Œè®­ç»ƒè„šæœ¬

# --- Exit on error ---
set -e

# å¦‚æœè„šæœ¬ç”± torchrun è§¦å‘ï¼Œåˆ™ä¸æ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡
if [ -z "$RUNNING_WITH_TORCHRUN" ]; then
  echo "ğŸ§¹ æ¸…é™¤æ—§çš„åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡..."
  unset RANK 2>/dev/null || true
  unset LOCAL_RANK 2>/dev/null || true
  unset WORLD_SIZE 2>/dev/null || true
  unset MASTER_ADDR 2>/dev/null || true
  unset MASTER_PORT 2>/dev/null || true
fi

# ğŸ”§ å…³é”®ä¿®å¤ï¼šè®¾ç½®GPUä½†é¿å…åˆ†å¸ƒå¼æ¨¡å¼
export CUDA_VISIBLE_DEVICES=0,1

# ğŸ”§ å¤šGPUæ¨¡å‹å¹¶è¡Œä¼˜åŒ–è®¾ç½®ï¼ˆä¿®å¤åï¼‰
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True,max_split_size_mb:256"
export CUDA_LAUNCH_BLOCKING=0  # å¼‚æ­¥æ‰§è¡Œä»¥æé«˜æ€§èƒ½
export TORCH_NCCL_BLOCKING_WAIT=1  # ä½¿ç”¨æ–°çš„ç¯å¢ƒå˜é‡å
export TORCH_NCCL_ASYNC_ERROR_HANDLING=1  # ä½¿ç”¨æ–°çš„ç¯å¢ƒå˜é‡å
export NCCL_TIMEOUT=7200
export NCCL_DEBUG=WARN
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=0  # å¯ç”¨P2Pé€šä¿¡

# ğŸ”§ Flash Attention ä¼˜åŒ–
export FLASH_ATTENTION_V2=1

# --- Get the directory where the script is located ---
SCRIPT_DIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" &> /dev/null && pwd)
PYTHON_EXECUTABLE="python3"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# æ—¥å¿—å‡½æ•°
log_info() { echo -e "${GREEN}[INFO]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_debug() { echo -e "${BLUE}[DEBUG]${NC} $1"; }

# ğŸ”§ GPUç¯å¢ƒæ£€æŸ¥å‡½æ•°ï¼ˆä¿®å¤ç‰ˆï¼‰
check_gpu_environment() {
    log_info "ğŸ” æ£€æŸ¥GPUç¯å¢ƒ..."
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if ! command -v nvidia-smi &> /dev/null; then
        log_error "âŒ nvidia-smiæœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥CUDAå®‰è£…"
        return 1
    fi
    
    # æ£€æŸ¥GPUæ•°é‡
    local gpu_count=$(nvidia-smi --query-gpu=count --format=csv,noheader,nounits | head -1)
    log_info "ğŸ“Š æ£€æµ‹åˆ° ${gpu_count} å¼ GPU"
    
    if [ "${gpu_count}" -lt 2 ]; then
        log_warning "âš ï¸ æ£€æµ‹åˆ°å°‘äº2å¼ GPUï¼Œå°†ä½¿ç”¨å•GPUæ¨¡å¼"
        export USE_MODEL_PARALLEL=false
        return 0
    fi
    
    # æ£€æŸ¥GPUå†…å­˜
    log_info "ğŸ’¾ GPUå†…å­˜ä¿¡æ¯:"
    nvidia-smi --query-gpu=index,name,memory.total,memory.used,memory.free --format=csv,noheader
    
    # ğŸ”§ ä¿®å¤ï¼šç®€åŒ–çš„GPUé€šä¿¡æµ‹è¯•
    log_debug "ğŸ”— æµ‹è¯•GPUé€šä¿¡..."
    if ${PYTHON_EXECUTABLE} -c "
import torch
import sys
try:
    if torch.cuda.device_count() >= 2:
        device0 = torch.device('cuda:0')
        device1 = torch.device('cuda:1')
        
        x = torch.randn(100, 100, device=device0)
        y = x.to(device1)
        z = y.to(device0)
        
        print('âœ… GPUé€šä¿¡æµ‹è¯•æˆåŠŸ')
        print(f'   æ•°æ®ä¸€è‡´æ€§: {torch.allclose(x, z)}')
    else:
        print('âš ï¸ GPUæ•°é‡ä¸è¶³ï¼Œè·³è¿‡é€šä¿¡æµ‹è¯•')
        sys.exit(1)
except Exception as e:
    print(f'âŒ GPUé€šä¿¡æµ‹è¯•å¤±è´¥: {e}')
    sys.exit(1)
"; then
        log_info "âœ… GPUé€šä¿¡æµ‹è¯•é€šè¿‡"
        export USE_MODEL_PARALLEL=true
    else
        log_warning "âš ï¸ GPUé€šä¿¡æµ‹è¯•å¤±è´¥ï¼Œå°†ä½¿ç”¨å•GPUæ¨¡å¼"
        export USE_MODEL_PARALLEL=false
    fi
    
    return 0
}

# --- Enhanced Environment Setup ---
export WANDB_PROJECT="VerilogGRPO_ModelParallel"
export WANDB_ENTITY="qhy0227-tsinghua-university"

# --- Model and Data Configuration ---
BASE_MODEL_NAME_OR_PATH="/home/share/Qwen3-8B/models--Qwen--Qwen3-8B/snapshots/a80f5e57cce20e57b65145f4213844dec1a80834"
STAGE1_ADAPTER_PATH="/home/share/ReasoningV/Qwen3/ckpts/sft-qwen3-lora-5epoch-origen200k-S1-20250429_211831/checkpoint-34695/"
DATASET_PATH="/home/qhy/Research/LLM/GRPO-RV/dataset/all-with-module-2.jsonl"
DATASET_BASE_PATH="/home/qhy/Research/LLM/GRPO-RV/dataset"

# éªŒè¯è·¯å¾„å­˜åœ¨
if [ ! -f "${DATASET_PATH}" ]; then
    log_error "âŒ æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: ${DATASET_PATH}"
    exit 1
fi

if [ ! -d "${DATASET_BASE_PATH}" ]; then
    log_error "âŒ æ•°æ®é›†åŸºç¡€è·¯å¾„ä¸å­˜åœ¨: ${DATASET_BASE_PATH}"
    exit 1
fi

log_info "âœ… æ•°æ®é›†è·¯å¾„éªŒè¯æˆåŠŸ:"
log_info "  - æ•°æ®é›†æ–‡ä»¶: ${DATASET_PATH}"
log_info "  - åŸºç¡€è·¯å¾„: ${DATASET_BASE_PATH}"

# --- RESUME FROM CHECKPOINT CONFIGURATION ---
RESUME_FROM_CHECKPOINT_DIR=""  # å…ˆæ¸…ç©ºï¼Œé¿å…æ¢å¤æ—¶çš„é¢å¤–å¤æ‚æ€§

OUTPUT_DIR_BASE="./model_parallel_outputs"

# ğŸ”§ æ¨¡å‹å¹¶è¡Œä¼˜åŒ–é…ç½®
USE_MODEL_PARALLEL=true
MAX_MEMORY_PER_GPU="75GiB"
LOW_CPU_MEM_USAGE=true

# ğŸ”§ ç¡®ä¿å¤šGPUå¯è§æ€§ï¼ˆä¸è¦é™åˆ¶åˆ°å•GPUï¼‰
export CUDA_VISIBLE_DEVICES=0,1

# ğŸ”§ LoRAé…ç½®
LORA_RANK=64
LORA_ALPHA=128
LORA_DROPOUT=0.05
LORA_TARGET_MODULES="q_proj k_proj v_proj o_proj gate_proj up_proj down_proj"

# ğŸ”§ é•¿åº¦é…ç½®
MAX_SEQ_LENGTH=6144
MAX_PROMPT_LENGTH=1536
MAX_COMPLETION_LENGTH=4608
LENGTH_ALLOCATION_STRATEGY="custom"

# ğŸ”§ è®­ç»ƒé…ç½®
PER_DEVICE_TRAIN_BATCH_SIZE=2
GRADIENT_ACCUMULATION_STEPS=4
LEARNING_RATE=1e-5
NUM_TRAIN_EPOCHS=3
WARMUP_RATIO=0.1
LR_SCHEDULER_TYPE="cosine"
WEIGHT_DECAY=0.01

# ğŸ”§ æ€§èƒ½è®¾ç½®
BF16_ENABLED=true
FP16_ENABLED=false
GRADIENT_CHECKPOINTING_ENABLED=false  # æ¨¡å‹å¹¶è¡Œæ—¶ç¦ç”¨
OPTIMIZER_TYPE="adamw_torch"

# ğŸ”§ æ•°æ®åŠ è½½é…ç½®
DATALOADER_NUM_WORKERS=0  # æ¨¡å‹å¹¶è¡Œæ—¶è®¾ä¸º0é¿å…å†²çª
DATALOADER_PIN_MEMORY=false

# ğŸ”§ å…¶ä»–é…ç½®
NUM_GENERATIONS_GRPO=2
CALLBACK_NUM_SAMPLES=2
CALLBACK_EVAL_EVERY_N_STEPS=15  # å‡å°‘é¢‘ç‡
SAVE_STRATEGY="steps"
SAVE_STEPS=50
SAVE_TOTAL_LIMIT=2
LOGGING_STEPS=10

# --- è¯¾ç¨‹å­¦ä¹ é…ç½® ---
ENABLE_CURRICULUM=true
CURRICULUM_TYPE="dual_layer"
CURRICULUM_FOCUS_LEVELS="advanced basic intermediate"
CURRICULUM_COMPLEXITY_EMPHASIS="simple"
CURRICULUM_PERFORMANCE_CHECK_INTERVAL=15

# è¯¾ç¨‹å­¦ä¹ é˜ˆå€¼
CURRICULUM_PERFORMANCE_THRESHOLD_1=0.75
CURRICULUM_PERFORMANCE_THRESHOLD_2=0.70
CURRICULUM_PERFORMANCE_THRESHOLD_3=0.65
CURRICULUM_PERFORMANCE_THRESHOLD_4=0.60
CURRICULUM_PERFORMANCE_THRESHOLD_5=0.55
CURRICULUM_MIN_EVALUATIONS=3

# å¯¼å‡ºç¯å¢ƒå˜é‡
export CURRICULUM_PERFORMANCE_THRESHOLD_1
export CURRICULUM_PERFORMANCE_THRESHOLD_2
export CURRICULUM_PERFORMANCE_THRESHOLD_3
export CURRICULUM_PERFORMANCE_THRESHOLD_4
export CURRICULUM_PERFORMANCE_THRESHOLD_5
export CURRICULUM_MIN_EVALUATIONS

# --- ç»éªŒå›æ”¾é…ç½® ---
ENABLE_EXPERIENCE_REPLAY=true
EXPERIENCE_BUFFER_SIZE=1500
REPLAY_SAMPLE_RATIO=0.2

# --- å¥–åŠ±é…ç½® ---
REWARD_COMPILATION_SUCCESS=2.0
REWARD_COMPILATION_FAILURE=-4.0
REWARD_TEST_PASS_BASE=1.5
REWARD_TEST_PASS_BONUS_MULTIPLIER=1.2
REWARD_MAX_FUNCTIONAL=15.0
REWARD_ALL_TESTS_PASSED_BONUS=5.0

# --- ç”Ÿæˆå‚æ•° ---
GEN_TEMPERATURE=0.7
GEN_TOP_K=40
GEN_TOP_P=0.8
GEN_REPETITION_PENALTY=1.05

# --- éªŒè¯é•¿åº¦é…ç½®å‡½æ•° ---
validate_length_config() {
    local total_length=$((MAX_PROMPT_LENGTH + MAX_COMPLETION_LENGTH))
    log_info "ğŸ“ é•¿åº¦é…ç½®éªŒè¯:"
    log_info "  - æ€»åºåˆ—é•¿åº¦: ${MAX_SEQ_LENGTH}"
    log_info "  - æœ€å¤§æç¤ºé•¿åº¦: ${MAX_PROMPT_LENGTH} ($(( MAX_PROMPT_LENGTH * 100 / MAX_SEQ_LENGTH ))%)"
    log_info "  - æœ€å¤§è¾“å‡ºé•¿åº¦: ${MAX_COMPLETION_LENGTH} ($(( MAX_COMPLETION_LENGTH * 100 / MAX_SEQ_LENGTH ))%)"
    log_info "  - åˆ†é…ç­–ç•¥: ${LENGTH_ALLOCATION_STRATEGY}"
    
    if [ ${total_length} -gt ${MAX_SEQ_LENGTH} ]; then
        log_error "âŒ é…ç½®é”™è¯¯: æç¤ºé•¿åº¦ + è¾“å‡ºé•¿åº¦ (${total_length}) > æ€»åºåˆ—é•¿åº¦ (${MAX_SEQ_LENGTH})"
        return 1
    else
        log_info "âœ… é•¿åº¦é…ç½®æœ‰æ•ˆ"
        return 0
    fi
}

# --- ä¸»è¦æ£€æŸ¥æµç¨‹ ---
main_checks() {
    log_info "ğŸš€ å¼€å§‹æ¨¡å‹å¹¶è¡Œè®­ç»ƒç¯å¢ƒæ£€æŸ¥..."
    
    # 1. GPUç¯å¢ƒæ£€æŸ¥
    if ! check_gpu_environment; then
        log_error "âŒ GPUç¯å¢ƒæ£€æŸ¥å¤±è´¥"
        exit 1
    fi
    
    # 2. éªŒè¯é•¿åº¦é…ç½®
    if ! validate_length_config; then
        log_error "âŒ é•¿åº¦é…ç½®éªŒè¯å¤±è´¥"
        exit 1
    fi
    
    log_info "âœ… æ‰€æœ‰æ£€æŸ¥å®Œæˆï¼Œå‡†å¤‡å¼€å§‹è®­ç»ƒ"
}

# è¿è¡Œæ£€æŸ¥
main_checks

# --- æ•°æ®é›†æ£€æŸ¥ ---
if [ ! -f "${DATASET_PATH}" ]; then
    log_error "âŒ æ•°æ®é›†æ–‡ä»¶æœªæ‰¾åˆ°: ${DATASET_PATH}"
    exit 1
fi

log_info "ğŸ” æ£€æŸ¥æ•°æ®é›†æ ¼å¼..."
FIRST_LINE=$(head -1 "${DATASET_PATH}")
if echo "${FIRST_LINE}" | grep -q '"level"' && echo "${FIRST_LINE}" | grep -q '"complexity_score"'; then
    log_info "âœ… æ£€æµ‹åˆ°å¢å¼ºæ•°æ®é›†æ ¼å¼"
else
    log_warning "âš ï¸ æ•°æ®é›†å¯èƒ½ä¸ºæ—§æ ¼å¼ï¼Œè®­ç»ƒè„šæœ¬å°†å°è¯•è‡ªåŠ¨å‡çº§"
fi

# --- åŠ¨æ€WandBè¿è¡Œåç§° ---
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
export WANDB_RUN_NAME="model-parallel-LR${LEARNING_RATE}-R${LORA_RANK}-${TIMESTAMP}"

# --- æ„å»ºå‘½ä»¤å‚æ•° ---
CMD_ARGS=""

# FSDP ç‰¹å®šé…ç½®
CMD_ARGS="${CMD_ARGS} --fsdp \"full_shard\""
# æ³¨æ„ï¼šfsdp_min_num_params å’Œ fsdp_transformer_layer_cls_to_wrap æ˜¯äº’æ–¥çš„ï¼Œåªèƒ½è®¾ç½®ä¸€ä¸ª
# CMD_ARGS="${CMD_ARGS} --fsdp_min_num_params 100000000"  # å·²ç¦ç”¨ï¼Œä¸transformer_layer_cls_to_wrapå†²çª
CMD_ARGS="${CMD_ARGS} --fsdp_transformer_layer_cls_to_wrap \"QWenBlock\""  # ä½¿ç”¨Qwenæ¨¡å‹çš„å®é™…layerç±»å
CMD_ARGS="${CMD_ARGS} --low_cpu_mem_usage ${LOW_CPU_MEM_USAGE}"

# åŸºç¡€é…ç½®
CMD_ARGS="${CMD_ARGS} --wandb_project \"${WANDB_PROJECT}\""
CMD_ARGS="${CMD_ARGS} --wandb_entity \"${WANDB_ENTITY}\""
CMD_ARGS="${CMD_ARGS} --model_name_or_path \"${BASE_MODEL_NAME_OR_PATH}\""
CMD_ARGS="${CMD_ARGS} --stage1_adapter_path \"${STAGE1_ADAPTER_PATH}\""
CMD_ARGS="${CMD_ARGS} --dataset_path \"${DATASET_PATH}\""
CMD_ARGS="${CMD_ARGS} --dataset_base_path \"${DATASET_BASE_PATH}\""
CMD_ARGS="${CMD_ARGS} --output_dir_base \"${OUTPUT_DIR_BASE}\""

# LoRAé…ç½®
CMD_ARGS="${CMD_ARGS} --lora_rank ${LORA_RANK}"
CMD_ARGS="${CMD_ARGS} --lora_alpha ${LORA_ALPHA}"
CMD_ARGS="${CMD_ARGS} --lora_dropout ${LORA_DROPOUT}"
CMD_ARGS="${CMD_ARGS} --lora_target_modules ${LORA_TARGET_MODULES}"

# é•¿åº¦é…ç½®
CMD_ARGS="${CMD_ARGS} --max_seq_length ${MAX_SEQ_LENGTH}"
CMD_ARGS="${CMD_ARGS} --script_max_prompt_length ${MAX_PROMPT_LENGTH}"
CMD_ARGS="${CMD_ARGS} --script_max_completion_length ${MAX_COMPLETION_LENGTH}"
CMD_ARGS="${CMD_ARGS} --length_allocation_strategy ${LENGTH_ALLOCATION_STRATEGY}"

# è®­ç»ƒé…ç½®
CMD_ARGS="${CMD_ARGS} --per_device_train_batch_size ${PER_DEVICE_TRAIN_BATCH_SIZE}"
CMD_ARGS="${CMD_ARGS} --gradient_accumulation_steps ${GRADIENT_ACCUMULATION_STEPS}"
CMD_ARGS="${CMD_ARGS} --learning_rate ${LEARNING_RATE}"
CMD_ARGS="${CMD_ARGS} --num_train_epochs ${NUM_TRAIN_EPOCHS}"
CMD_ARGS="${CMD_ARGS} --warmup_ratio ${WARMUP_RATIO}"
CMD_ARGS="${CMD_ARGS} --lr_scheduler_type \"${LR_SCHEDULER_TYPE}\""
CMD_ARGS="${CMD_ARGS} --weight_decay ${WEIGHT_DECAY}"

# GRPOé…ç½®
CMD_ARGS="${CMD_ARGS} --num_generations ${NUM_GENERATIONS_GRPO}"
CMD_ARGS="${CMD_ARGS} --max_prompt_length ${MAX_PROMPT_LENGTH}"
CMD_ARGS="${CMD_ARGS} --max_completion_length ${MAX_COMPLETION_LENGTH}"

# å›è°ƒé…ç½®
CMD_ARGS="${CMD_ARGS} --callback_num_samples ${CALLBACK_NUM_SAMPLES}"
CMD_ARGS="${CMD_ARGS} --callback_eval_every_n_steps ${CALLBACK_EVAL_EVERY_N_STEPS}"

# è¯¾ç¨‹å­¦ä¹ é…ç½®
CMD_ARGS="${CMD_ARGS} --enable_curriculum ${ENABLE_CURRICULUM}"
CMD_ARGS="${CMD_ARGS} --curriculum_type ${CURRICULUM_TYPE}"
CMD_ARGS="${CMD_ARGS} --curriculum_focus_levels ${CURRICULUM_FOCUS_LEVELS}"
CMD_ARGS="${CMD_ARGS} --curriculum_complexity_emphasis ${CURRICULUM_COMPLEXITY_EMPHASIS}"
CMD_ARGS="${CMD_ARGS} --curriculum_performance_check_interval ${CURRICULUM_PERFORMANCE_CHECK_INTERVAL}"

# è¯¾ç¨‹å­¦ä¹ é˜ˆå€¼
CMD_ARGS="${CMD_ARGS} --curriculum_performance_threshold_1 ${CURRICULUM_PERFORMANCE_THRESHOLD_1}"
CMD_ARGS="${CMD_ARGS} --curriculum_performance_threshold_2 ${CURRICULUM_PERFORMANCE_THRESHOLD_2}"
CMD_ARGS="${CMD_ARGS} --curriculum_performance_threshold_3 ${CURRICULUM_PERFORMANCE_THRESHOLD_3}"
CMD_ARGS="${CMD_ARGS} --curriculum_performance_threshold_4 ${CURRICULUM_PERFORMANCE_THRESHOLD_4}"
CMD_ARGS="${CMD_ARGS} --curriculum_performance_threshold_5 ${CURRICULUM_PERFORMANCE_THRESHOLD_5}"
CMD_ARGS="${CMD_ARGS} --curriculum_min_evaluations ${CURRICULUM_MIN_EVALUATIONS}"

# ç»éªŒå›æ”¾é…ç½®
CMD_ARGS="${CMD_ARGS} --enable_experience_replay ${ENABLE_EXPERIENCE_REPLAY}"
CMD_ARGS="${CMD_ARGS} --experience_buffer_size ${EXPERIENCE_BUFFER_SIZE}"
CMD_ARGS="${CMD_ARGS} --replay_sample_ratio ${REPLAY_SAMPLE_RATIO}"

# å¥–åŠ±é…ç½®
CMD_ARGS="${CMD_ARGS} --compilation_success ${REWARD_COMPILATION_SUCCESS}"
CMD_ARGS="${CMD_ARGS} --compilation_failure ${REWARD_COMPILATION_FAILURE}"
CMD_ARGS="${CMD_ARGS} --test_pass_base_reward ${REWARD_TEST_PASS_BASE}"
CMD_ARGS="${CMD_ARGS} --test_pass_bonus_multiplier ${REWARD_TEST_PASS_BONUS_MULTIPLIER}"
CMD_ARGS="${CMD_ARGS} --max_functional_reward ${REWARD_MAX_FUNCTIONAL}"
CMD_ARGS="${CMD_ARGS} --all_tests_passed_bonus ${REWARD_ALL_TESTS_PASSED_BONUS}"

# ç”Ÿæˆå‚æ•°
CMD_ARGS="${CMD_ARGS} --gen_temperature ${GEN_TEMPERATURE}"
CMD_ARGS="${CMD_ARGS} --gen_top_k ${GEN_TOP_K}"
CMD_ARGS="${CMD_ARGS} --gen_top_p ${GEN_TOP_P}"
CMD_ARGS="${CMD_ARGS} --gen_repetition_penalty ${GEN_REPETITION_PENALTY}"

# æ€§èƒ½è®¾ç½®
if [ "$BF16_ENABLED" = true ]; then CMD_ARGS="${CMD_ARGS} --bf16"; fi
if [ "$FP16_ENABLED" = true ] && [ "$BF16_ENABLED" = false ]; then CMD_ARGS="${CMD_ARGS} --fp16"; fi
if [ "$GRADIENT_CHECKPOINTING_ENABLED" = true ]; then CMD_ARGS="${CMD_ARGS} --gradient_checkpointing"; fi

# æ•°æ®åŠ è½½é…ç½®
CMD_ARGS="${CMD_ARGS} --dataloader_num_workers ${DATALOADER_NUM_WORKERS}"
if [ "$DATALOADER_PIN_MEMORY" = true ]; then CMD_ARGS="${CMD_ARGS} --dataloader_pin_memory"; fi

# ä¿å­˜å’Œæ—¥å¿—é…ç½®
CMD_ARGS="${CMD_ARGS} --logging_strategy \"steps\""
CMD_ARGS="${CMD_ARGS} --logging_steps ${LOGGING_STEPS}"
CMD_ARGS="${CMD_ARGS} --save_strategy \"${SAVE_STRATEGY}\""
CMD_ARGS="${CMD_ARGS} --save_steps ${SAVE_STEPS}"
CMD_ARGS="${CMD_ARGS} --save_total_limit ${SAVE_TOTAL_LIMIT}"
CMD_ARGS="${CMD_ARGS} --report_to \"wandb\""
CMD_ARGS="${CMD_ARGS} --remove_unused_columns False"
CMD_ARGS="${CMD_ARGS} --optim \"${OPTIMIZER_TYPE}\""
CMD_ARGS="${CMD_ARGS} --ddp_find_unused_parameters False"

# æ¢å¤é…ç½®
if [ -n "${RESUME_FROM_CHECKPOINT_DIR}" ] && [ -d "${RESUME_FROM_CHECKPOINT_DIR}" ]; then
    CMD_ARGS="${CMD_ARGS} --resume_from_checkpoint \"${RESUME_FROM_CHECKPOINT_DIR}\""
fi

# ç¼“å­˜ç›®å½•
CACHE_DIR_BASE="${SCRIPT_DIR}/.model_parallel_cache"
mkdir -p "${CACHE_DIR_BASE}/datasets"
mkdir -p "${CACHE_DIR_BASE}/models"
CMD_ARGS="${CMD_ARGS} --cache_dir \"${CACHE_DIR_BASE}/models\""

# --- ğŸ”§ å…³é”®ä¿®å¤ï¼šè®­ç»ƒæ‰§è¡Œé…ç½® ---
PYTHON_SCRIPT_TO_RUN="${SCRIPT_DIR}/main.py"

# ğŸ”§ ä½¿ç”¨ torchrun å¯åŠ¨åˆ†å¸ƒå¼ FSDP
log_info "ğŸš€ ä½¿ç”¨ torchrun å¯åŠ¨åˆ†å¸ƒå¼ FSDP è®­ç»ƒ"
NPROC_PER_NODE=2  # å¦‚éœ€è°ƒæ•´ GPU æ•°é‡ï¼Œè¯·ä¿®æ”¹æ­¤å¤„
# ä½¿ç”¨éšæœºç«¯å£é¿å…å†²çª
MASTER_PORT=${MASTER_PORT:-$((29500 + RANDOM % 1000))}

# ç¡®ä¿condaç¯å¢ƒæ¿€æ´»
FULL_CMD="conda activate ReasoningV && torchrun --nnodes 1 --nproc_per_node ${NPROC_PER_NODE} --master_port ${MASTER_PORT} ${PYTHON_SCRIPT_TO_RUN} ${CMD_ARGS}"

# --- åˆ›å»ºè¾“å‡ºç›®å½• ---
mkdir -p ${OUTPUT_DIR_BASE}

# --- è®­ç»ƒå‰æ‘˜è¦ ---
echo ""
echo "========================================================================"
echo "                    æ¨¡å‹å¹¶è¡ŒGRPOè®­ç»ƒå¯åŠ¨"
echo "========================================================================"
log_info "ğŸ¯ è®­ç»ƒé…ç½®æ‘˜è¦:"
log_info "  - æ¨¡å¼: å•è¿›ç¨‹æ¨¡å‹å¹¶è¡Œï¼ˆé¿å…DDPå†²çªï¼‰"
log_info "  - æ¨¡å‹: $(basename "${BASE_MODEL_NAME_OR_PATH}")"
log_info "  - æ•°æ®é›†: $(basename "${DATASET_PATH}")"
log_info "  - åºåˆ—é•¿åº¦: ${MAX_SEQ_LENGTH} (Prompt: ${MAX_PROMPT_LENGTH}, Completion: ${MAX_COMPLETION_LENGTH})"
log_info "  - LoRA: rank=${LORA_RANK}, alpha=${LORA_ALPHA}"
log_info "  - æ‰¹æ¬¡å¤§å°: ${PER_DEVICE_TRAIN_BATCH_SIZE}"
log_info "  - æœ‰æ•ˆæ‰¹æ¬¡: $((PER_DEVICE_TRAIN_BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS))"
log_info "  - å­¦ä¹ ç‡: ${LEARNING_RATE}"
log_info "  - è¾“å‡ºç›®å½•: ${OUTPUT_DIR_BASE}"
log_info "  - å¯åŠ¨æ–¹å¼: ç›´æ¥pythonï¼ˆéåˆ†å¸ƒå¼ï¼‰"

echo ""
log_info "ğŸ“Š å†…å­˜é¢„ä¼°:"
MODEL_PARAMS=8  # 8Bå‚æ•°
MODEL_MEMORY=$((MODEL_PARAMS * 2))  # bf16
log_info "  - æ¨¡å‹å‚æ•°: ~${MODEL_PARAMS}B"
log_info "  - æ¨¡å‹å†…å­˜: ~${MODEL_MEMORY}GBï¼ˆå°†åˆ†å¸ƒåˆ°2å¼ GPUï¼‰"
log_info "  - æ¯GPUé¢„ä¼°: ~$((MODEL_MEMORY / 2 + 10))GB"

echo ""
echo "âš ï¸  é‡è¦æç¤º:"
echo "  - ä½¿ç”¨å•è¿›ç¨‹æ¨¡å‹å¹¶è¡Œï¼Œé¿å…DDPå†²çª"
echo "  - æ¨¡å‹æƒé‡å°†åˆ†å¸ƒåˆ°GPU 0å’Œ1ï¼Œè€Œéå¤åˆ¶"
echo "  - ä¸ä½¿ç”¨torchrunå¯åŠ¨"
echo ""
echo "ç›‘æ§é“¾æ¥: https://wandb.ai/${WANDB_ENTITY}/${WANDB_PROJECT}"
echo "========================================================================"

# ä¿å­˜å®Œæ•´å‘½ä»¤
echo "${FULL_CMD}" > "${OUTPUT_DIR_BASE}/full_training_command.txt"
log_info "ğŸ’¾ å®Œæ•´å‘½ä»¤å·²ä¿å­˜åˆ°: ${OUTPUT_DIR_BASE}/full_training_command.txt"

# --- è®­ç»ƒå‰æœ€ç»ˆGPUçŠ¶æ€ ---
echo ""
log_info "ğŸ” è®­ç»ƒå‰GPUçŠ¶æ€:"
nvidia-smi --query-gpu=index,name,memory.used,memory.total --format=csv,noheader

# --- æ‰§è¡Œè®­ç»ƒ ---
echo ""
log_info "ğŸš€ å¼€å§‹æ¨¡å‹å¹¶è¡ŒGRPOè®­ç»ƒ ($(date))..."

# è®¾ç½®æ¸…ç†å‡½æ•°
cleanup_on_exit() {
    echo ""
    log_info "ğŸ›‘ è®­ç»ƒç»“æŸ/ä¸­æ–­ï¼Œæ‰§è¡Œæ¸…ç†..."
    log_info "ğŸ“Š æœ€ç»ˆGPUçŠ¶æ€:"
    nvidia-smi --query-gpu=index,name,memory.used,memory.total --format=csv,noheader
    log_info "â° è®­ç»ƒç»“æŸæ—¶é—´: $(date)"
}
trap cleanup_on_exit INT TERM EXIT

# ğŸ”§ å…³é”®ï¼šæ‰§è¡Œè®­ç»ƒå‘½ä»¤
eval ${FULL_CMD}

status=$?

# --- è®­ç»ƒåæ‘˜è¦ ---
echo ""
echo "========================================================================"
echo "                      æ¨¡å‹å¹¶è¡Œè®­ç»ƒå®Œæˆæ‘˜è¦"
echo "========================================================================"
log_info "â° è®­ç»ƒç»“æŸæ—¶é—´: $(date)"
log_info "ğŸ¯ é€€å‡ºçŠ¶æ€: ${status}"

if [ $status -eq 0 ]; then
    log_info "âœ… æ¨¡å‹å¹¶è¡ŒGRPOè®­ç»ƒæˆåŠŸå®Œæˆ!"
    
    # æ£€æŸ¥è¾“å‡º
    if [ -d "${OUTPUT_DIR_BASE}" ]; then
        FINAL_MODEL_DIR=$(find "${OUTPUT_DIR_BASE}" -name "*final*model*" -type d 2>/dev/null | head -1)
        if [ -n "${FINAL_MODEL_DIR}" ]; then
            MODEL_SIZE=$(du -sh "${FINAL_MODEL_DIR}" 2>/dev/null | cut -f1 || echo "Unknown")
            log_info "âœ… æœ€ç»ˆæ¨¡å‹ä¿å­˜åˆ°: ${FINAL_MODEL_DIR}"
            log_info "  ğŸ“¦ æ¨¡å‹å¤§å°: ${MODEL_SIZE}"
        fi
        
        # æ£€æŸ¥æ—¥å¿—
        LOG_FILE=$(find "${OUTPUT_DIR_BASE}" -name "*log*.txt" 2>/dev/null | head -1)
        if [ -f "${LOG_FILE}" ]; then
            LOG_SIZE=$(wc -l < "${LOG_FILE}" 2>/dev/null || echo "0")
            log_info "âœ… è®­ç»ƒæ—¥å¿—: ${LOG_SIZE} è¡Œ"
        fi
        
        # æ£€æŸ¥æ¨¡å‹å¹¶è¡Œä¿¡æ¯
        DEVICE_MAP_FILE=$(find "${OUTPUT_DIR_BASE}" -name "model_device_map.json" 2>/dev/null | head -1)
        if [ -f "${DEVICE_MAP_FILE}" ]; then
            log_info "âœ… æ¨¡å‹è®¾å¤‡æ˜ å°„å·²ä¿å­˜: $(basename "${DEVICE_MAP_FILE}")"
        fi
    fi
    
    echo ""
    log_info "ğŸ‰ åç»­æ­¥éª¤:"
    log_info "1. æŸ¥çœ‹WandBä»ªè¡¨æ¿äº†è§£è¯¦ç»†æŒ‡æ ‡"
    log_info "2. æ£€æŸ¥æ¨¡å‹è®¾å¤‡åˆ†å¸ƒæƒ…å†µ"
    log_info "3. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½"
    log_info "4. éªŒè¯æ¨¡å‹å¹¶è¡Œçš„å†…å­˜æ•ˆç‡"
    
else
    log_error "âŒ æ¨¡å‹å¹¶è¡Œè®­ç»ƒå¤±è´¥ï¼Œé€€å‡ºç : ${status}"
    echo ""
    log_info "ğŸ”§ æ•…éšœæ’é™¤:"
    log_info "1. æ£€æŸ¥è®­ç»ƒæ—¥å¿—: ${OUTPUT_DIR_BASE}/*/training_log.txt"
    log_info "2. éªŒè¯GPUçŠ¶æ€: nvidia-smi"
    log_info "3. æ£€æŸ¥æ˜¯å¦æœ‰DDPå†²çªé”™è¯¯"
    log_info "4. ç¡®è®¤ä½¿ç”¨å•è¿›ç¨‹å¯åŠ¨è€Œétorchrun"
    log_info "5. æŸ¥çœ‹WandBæ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯"
    
    # é”™è¯¯è¯Šæ–­
    if [ $status -ne 0 ]; then
        log_error "ğŸ” å¯èƒ½çš„é”™è¯¯åŸå› :"
        log_error "  - å¦‚æœçœ‹åˆ°DTensor/DDPé”™è¯¯ï¼šç¡®ä¿æ¸…é™¤äº†æ‰€æœ‰åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡"
        log_error "  - å¦‚æœçœ‹åˆ°OOMé”™è¯¯ï¼šå‡å°‘æ‰¹æ¬¡å¤§å°æˆ–åºåˆ—é•¿åº¦"
        log_error "  - å¦‚æœçœ‹åˆ°å¯¼å…¥é”™è¯¯ï¼šæ£€æŸ¥ç¯å¢ƒå’Œä¾èµ–"
        log_error "  - å¦‚æœçœ‹åˆ°é…ç½®é”™è¯¯ï¼šæ£€æŸ¥å‚æ•°è®¾ç½®æ˜¯å¦æ­£ç¡®"
    fi
fi

echo "========================================================================"

# æœ€ç»ˆGPUçŠ¶æ€
if command -v nvidia-smi &> /dev/null; then
    echo ""
    log_info "ğŸ“Š æœ€ç»ˆGPUçŠ¶æ€:"
    nvidia-smi --query-gpu=index,name,memory.used,memory.total,temperature.gpu --format=csv,noheader
fi

echo ""
log_info "ğŸ’¡ ä½¿ç”¨æç¤º:"
log_info "  - æœ¬è„šæœ¬ä½¿ç”¨å•è¿›ç¨‹æ¨¡å‹å¹¶è¡Œï¼Œé¿å…äº†DDPå†²çª"
log_info "  - æ¨¡å‹æƒé‡åˆ†å¸ƒåœ¨ä¸¤å¼ GPUä¸Šï¼Œå®ç°çœŸæ­£çš„å¹¶è¡Œ"
log_info "  - å¯ä»¥é€šè¿‡è°ƒæ•´MAX_MEMORY_PER_GPUæ¥æ§åˆ¶å†…å­˜åˆ†é…"
log_info "  - å¦‚éœ€è°ƒæ•´é…ç½®ï¼Œä¿®æ”¹è„šæœ¬ä¸­çš„ç›¸åº”å˜é‡å³å¯"

exit ${status}