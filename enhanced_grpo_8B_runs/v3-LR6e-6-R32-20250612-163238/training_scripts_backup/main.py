# main.py - å®Œæ•´ä¿®å¤ç‰ˆæœ¬
import os
import logging
import numpy as np
import torch
import gc
import sys
from dataclasses import asdict
import json
from typing import Dict, Any, Optional, List
from pathlib import Path
import re

# --- BEGIN: PyTorch Safe Unpickling Configuration ---
logger_temp = logging.getLogger(__name__ + "_startup")
try:
    from numpy.core.multiarray import _reconstruct
    from numpy import dtype as numpy_dtype
    from numpy.dtypes import UInt32DType

    safe_globals_list = []
    if callable(_reconstruct): safe_globals_list.append(_reconstruct)
    if isinstance(numpy_dtype, type): safe_globals_list.append(numpy_dtype)
    if isinstance(np.ndarray, type): safe_globals_list.append(np.ndarray)
    if isinstance(UInt32DType, type): safe_globals_list.append(UInt32DType)

    # Add numpy scalar types
    numpy_scalar_types_to_add = [
        np.bool_, np.byte, np.ubyte, np.short, np.ushort, np.intc, np.uintc,
        np.int_, np.uint, np.longlong, np.ulonglong,
        np.half, np.float16, np.single, np.double, np.longdouble,
        np.csingle, np.cdouble, np.clongdouble,
        np.int8, np.int16, np.int32, np.int64,
        np.uint8, np.uint16, np.uint32, np.uint64,
        np.float32, np.float64
    ]
    
    for nt_class in numpy_scalar_types_to_add:
        if isinstance(nt_class, type):
            safe_globals_list.append(nt_class)

    if safe_globals_list:
        torch.serialization.add_safe_globals(safe_globals_list)
        logger_temp.info(f"Successfully updated torch safe global variables list with {len(safe_globals_list)} items.")

except Exception as e_globals:
    logger_temp.error(f"Error setting up torch safe globals: {e_globals}", exc_info=True)
# --- END: PyTorch Safe Unpickling Configuration ---

from transformers import HfArgumentParser
from trl import GRPOConfig

# Configuration imports
from grpo_project.configs import EnvConfig, ScriptConfig, EnhancedRewardConfig
from grpo_project.utils.logging import setup_global_logging
from grpo_project.utils.reporting_utils import PeriodicStatusReporter
from grpo_project.core.models import ModelManager
from grpo_project.data.dataset import load_and_prepare_dataset
from grpo_project.rewards.calculator import RewardCalculator
from grpo_project.curriculum.manager import setup_fixed_curriculum_manager
from grpo_project.utils import ExperienceBuffer

# Callbacks
from grpo_project.callbacks.monitoring import StepLoggingCallback, DetailedRewardCallback, RewardStabilityMonitor
from grpo_project.callbacks.persistence import CustomStatePersistenceCallback
from grpo_project.callbacks.inference import DetailedInferenceCallback
from grpo_project.callbacks.wandb import DetailedWandbCallback as TrainDetailedWandbCallback
from grpo_project.curriculum.callbacks import CurriculumProgressCallback, EnhancedCurriculumDebugCallback, OptimizedCurriculumCallback
from grpo_project.core.wandb_sync_manager import initialize_wandb_sync_manager, get_wandb_sync_manager

logger = logging.getLogger(__name__)

class GRPOTrainingPipeline:
    def __init__(self):
        # 1. Load Configurations
        parser = HfArgumentParser((EnvConfig, ScriptConfig, EnhancedRewardConfig, GRPOConfig))
        self.env_cfg, self.script_cfg, self.reward_cfg, self.grpo_cfg = parser.parse_args_into_dataclasses()
        
        # ğŸ”§ åŒæ­¥é•¿åº¦é…ç½®ä»ScriptConfigåˆ°GRPOConfig
        self._sync_length_configs()

        # ğŸ”§ æ–°å¢ï¼šè‡ªåŠ¨é…ç½®WandBæ¢å¤
        self._configure_wandb_resume()

        # Setup logging first
        self._setup_logging()
        logger.info("GRPOTrainingPipeline initialized.")
        self._log_configs()

        # ğŸ”§ æ–°å¢ï¼šåˆå§‹åŒ–WandBåŒæ­¥ç®¡ç†å™¨
        self._setup_wandb_sync_manager()

        # Initialize core components
        self.model_manager = ModelManager(
            script_cfg=self.script_cfg,
            grpo_cfg=self.grpo_cfg,
            model_name_or_path=self.script_cfg.model_name_or_path,
            cache_dir=self.env_cfg.cache_dir
        )

        self.reward_calculator = RewardCalculator(
            reward_config=self.reward_cfg,
            simulator=None
        )

        self.curriculum_manager = None
        self.experience_buffer = None
        self.callbacks = []
        self.status_reporter = PeriodicStatusReporter(self.grpo_cfg.output_dir, report_interval=50)

        self.model = None
        self.tokenizer = None
        self.trainer = None

    def _sync_length_configs(self):
        """ğŸ”§ åŒæ­¥é•¿åº¦é…ç½®ä»ScriptConfigåˆ°GRPOConfigï¼Œé¿å…å‚æ•°å†²çª"""
        logger.info("ğŸ”§ åŒæ­¥é•¿åº¦é…ç½®åˆ°GRPOConfig...")
        
        # å°†æˆ‘ä»¬çš„è„šæœ¬é…ç½®åŒæ­¥åˆ°GRPOé…ç½®
        self.grpo_cfg.max_prompt_length = self.script_cfg.script_max_prompt_length
        self.grpo_cfg.max_completion_length = self.script_cfg.script_max_completion_length
        
        logger.info(f"  âœ… GRPO max_prompt_length: {self.grpo_cfg.max_prompt_length}")
        logger.info(f"  âœ… GRPO max_completion_length: {self.grpo_cfg.max_completion_length}")

    def _setup_stable_environment(self):
        """ğŸ”§ è®¾ç½®ç¨³å®šçš„è®­ç»ƒç¯å¢ƒï¼Œé¿å…æ®µé”™è¯¯"""
        try:
            logger.info("ğŸ”§ è®¾ç½®ç¨³å®šè®­ç»ƒç¯å¢ƒ...")
            
            # è®¾ç½®CUDAç¯å¢ƒå˜é‡ä»¥æé«˜ç¨³å®šæ€§
            stable_envs = {
                "CUDA_LAUNCH_BLOCKING": "1",  # åŒæ­¥CUDAæ“ä½œï¼Œä¾¿äºè°ƒè¯•
                "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:128",  # é™åˆ¶å†…å­˜åˆ†å‰²
                "NCCL_BLOCKING_WAIT": "1",  # NCCLé˜»å¡ç­‰å¾…
            }
            
            for key, value in stable_envs.items():
                if key not in os.environ:
                    os.environ[key] = value
                    logger.info(f"  è®¾ç½®ç¯å¢ƒå˜é‡: {key}={value}")
            
            # å¦‚æœå¯ç”¨äº†æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œå¼ºåˆ¶ç¦ç”¨ä»¥é¿å…æ®µé”™è¯¯
            if hasattr(self.grpo_cfg, 'gradient_checkpointing') and self.grpo_cfg.gradient_checkpointing:
                logger.warning("âš ï¸ æ£€æµ‹åˆ°æ¢¯åº¦æ£€æŸ¥ç‚¹å·²å¯ç”¨ï¼Œä¸ºé¿å…æ®µé”™è¯¯è‡ªåŠ¨ç¦ç”¨")
                self.grpo_cfg.gradient_checkpointing = False
            
            # æ¸…ç†GPUå†…å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                logger.info("âœ… GPUå†…å­˜å·²æ¸…ç†")
            
            logger.info("âœ… ç¨³å®šè®­ç»ƒç¯å¢ƒè®¾ç½®å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç¨³å®šç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")

    def _configure_wandb_resume(self):
        """ğŸ”§ è‡ªåŠ¨é…ç½®WandBæ¢å¤ï¼Œæ— éœ€å¤–éƒ¨è„šæœ¬"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä»checkpointæ¢å¤
            is_resuming = (
                self.grpo_cfg.resume_from_checkpoint and
                isinstance(self.grpo_cfg.resume_from_checkpoint, str) and
                os.path.isdir(self.grpo_cfg.resume_from_checkpoint)
            )
            
            if not is_resuming:
                logger.info("ğŸš€ å¼€å§‹æ–°çš„è®­ç»ƒï¼Œæ— éœ€WandBæ¢å¤é…ç½®")
                # ç¡®ä¿æ¸…é™¤å¯èƒ½å­˜åœ¨çš„æ¢å¤ç›¸å…³ç¯å¢ƒå˜é‡
                for env_var in ["WANDB_RUN_ID", "WANDB_RESUME"]:
                    if env_var in os.environ:
                        del os.environ[env_var]
                        logger.info(f"ğŸ§¹ æ¸…é™¤ç¯å¢ƒå˜é‡: {env_var}")
                return
            
            checkpoint_path = Path(self.grpo_cfg.resume_from_checkpoint)
            logger.info(f"ğŸ”„ æ£€æµ‹åˆ°checkpointæ¢å¤: {checkpoint_path}")
            
            # å°è¯•ä»checkpointç›®å½•æå–WandB run ID
            run_id, run_url = self._extract_wandb_run_id(checkpoint_path)
            
            if run_id:
                # è®¾ç½®ç²¾ç¡®æ¢å¤
                os.environ["WANDB_RUN_ID"] = run_id
                os.environ["WANDB_RESUME"] = "must"
                logger.info(f"âœ… WandBç²¾ç¡®æ¢å¤é…ç½®:")
                logger.info(f"  - Run ID: {run_id}")
                logger.info(f"  - Resume Mode: must")
                if run_url:
                    logger.info(f"  - Run URL: {run_url}")
            else:
                # ä½¿ç”¨è‡ªåŠ¨æ¢å¤æ¨¡å¼
                os.environ["WANDB_RESUME"] = "allow"
                logger.info("âš ï¸ æœªæ‰¾åˆ°å…·ä½“çš„Run IDï¼Œä½¿ç”¨è‡ªåŠ¨æ¢å¤æ¨¡å¼")
                logger.info("  - Resume Mode: allow")
            
            logger.info("âœ… WandBæ¢å¤é…ç½®å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ WandBæ¢å¤é…ç½®å¤±è´¥: {e}")
            logger.info("ğŸ”„ å°†ä½¿ç”¨é»˜è®¤çš„WandBé…ç½®")

    def _setup_wandb_sync_manager(self):
        """ğŸ”§ è®¾ç½®WandBåŒæ­¥ç®¡ç†å™¨"""
        try:
            # ä»é…ç½®ä¸­è·å–é¡¹ç›®ä¿¡æ¯
            project_name = getattr(self.env_cfg, 'wandb_project', 'VerilogGRPO_Enhanced_v3')
            run_name = f"grpo_run_{os.path.basename(self.grpo_cfg.output_dir)}"
            
            # åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨
            sync_manager = initialize_wandb_sync_manager(
                output_dir=self.grpo_cfg.output_dir,
                project_name=project_name,
                run_name=run_name
            )
            
            logger.info("âœ… WandBåŒæ­¥ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"  - é¡¹ç›®: {project_name}")
            logger.info(f"  - è¿è¡Œåç§°: {run_name}")
            logger.info(f"  - è¾“å‡ºç›®å½•: {self.grpo_cfg.output_dir}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ WandBåŒæ­¥ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.info("ğŸ”„ å°†ä½¿ç”¨åŸç”ŸWandBåŠŸèƒ½")

    def _setup_wandb_run(self):
        """ğŸ”§ è®¾ç½®WandBè¿è¡Œï¼Œå¤„ç†æ–­ç»­è®­ç»ƒ"""
        try:
            sync_manager = get_wandb_sync_manager()
            if not sync_manager:
                logger.warning("âš ï¸ WandBåŒæ­¥ç®¡ç†å™¨æœªæ‰¾åˆ°ï¼Œè·³è¿‡WandBè¿è¡Œè®¾ç½®")
                return
                
            # æ£€æŸ¥æ˜¯å¦ä»checkpointæ¢å¤
            resume_from_checkpoint = None
            if (self.grpo_cfg.resume_from_checkpoint and 
                isinstance(self.grpo_cfg.resume_from_checkpoint, str) and
                os.path.isdir(self.grpo_cfg.resume_from_checkpoint)):
                resume_from_checkpoint = self.grpo_cfg.resume_from_checkpoint
                
            # å‡†å¤‡é…ç½®
            config = {
                "model_name_or_path": self.script_cfg.model_name_or_path,
                "learning_rate": self.grpo_cfg.learning_rate,
                "per_device_train_batch_size": self.grpo_cfg.per_device_train_batch_size,
                "max_seq_length": self.script_cfg.max_seq_length,
                "callback_eval_every_n_steps": self.script_cfg.callback_eval_every_n_steps,
                "lora_rank": getattr(self.script_cfg, 'lora_rank', None),
                "curriculum_enabled": self.curriculum_manager is not None,
                "resume_from_checkpoint": resume_from_checkpoint,
            }
            
            # è®¾ç½®WandBè¿è¡Œ
            success = sync_manager.setup_wandb_run(
                resume_from_checkpoint=resume_from_checkpoint,
                config=config
            )
            
            if success:
                logger.info("âœ… WandBè¿è¡Œè®¾ç½®æˆåŠŸ")
            else:
                logger.warning("âš ï¸ WandBè¿è¡Œè®¾ç½®å¤±è´¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ—¥å¿—")
                
        except Exception as e:
            logger.warning(f"âš ï¸ WandBè¿è¡Œè®¾ç½®å¼‚å¸¸: {e}")

    def _extract_wandb_run_id(self, checkpoint_path: Path) -> tuple[Optional[str], Optional[str]]:
        """ä»checkpointç›®å½•ä¸­æå–WandB run ID"""
        try:
            # æ–¹æ³•1: ä»wandbç›®å½•ä¸­æŸ¥æ‰¾
            parent_dir = checkpoint_path.parent
            wandb_dir = parent_dir / "wandb"
            
            if wandb_dir.exists():
                logger.info(f"ğŸ” åœ¨ {wandb_dir} ä¸­æŸ¥æ‰¾WandB runä¿¡æ¯...")
                
                # æŸ¥æ‰¾runç›®å½•
                run_dirs = list(wandb_dir.glob("run-*"))
                if run_dirs:
                    latest_run_dir = sorted(run_dirs)[-1]
                    logger.info(f"ğŸ“ æ‰¾åˆ°runç›®å½•: {latest_run_dir.name}")
                    
                    # æå–run ID (æ ¼å¼: run-20231201_123456-abcd1234)
                    run_name = latest_run_dir.name
                    if "-" in run_name:
                        parts = run_name.split("-")
                        if len(parts) >= 3:
                            run_id = parts[-1]  # æœ€åä¸€éƒ¨åˆ†æ˜¯run ID
                            logger.info(f"âœ… æå–åˆ°run ID: {run_id}")
                            
                            # å°è¯•è¯»å–runä¿¡æ¯
                            run_info_file = latest_run_dir / "files" / "wandb-metadata.json"
                            run_url = None
                            if run_info_file.exists():
                                try:
                                    with open(run_info_file, 'r') as f:
                                        metadata = json.load(f)
                                        run_url = metadata.get('url', '')
                                        if run_url:
                                            logger.info(f"ğŸ”— æ‰¾åˆ°Run URL: {run_url}")
                                except Exception as e:
                                    logger.warning(f"âš ï¸ è¯»å–metadataå¤±è´¥: {e}")
                            
                            return run_id, run_url
            
            # æ–¹æ³•2: ä»trainer_state.jsonä¸­æŸ¥æ‰¾
            trainer_state_file = checkpoint_path / "trainer_state.json"
            if trainer_state_file.exists():
                logger.info(f"ğŸ” åœ¨ {trainer_state_file} ä¸­æŸ¥æ‰¾è®­ç»ƒçŠ¶æ€...")
                try:
                    with open(trainer_state_file, 'r') as f:
                        state_data = json.load(f)
                        
                    # æŸ¥æ‰¾log_historyä¸­çš„wandbç›¸å…³ä¿¡æ¯
                    log_history = state_data.get('log_history', [])
                    for entry in log_history:
                        if isinstance(entry, dict):
                            for key, value in entry.items():
                                if 'wandb' in key.lower() or '_wandb' in str(value):
                                    logger.info(f"ğŸ“Š æ‰¾åˆ°WandBç›¸å…³æ—¥å¿—: {key}")
                                    break
                                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–trainer_state.jsonå¤±è´¥: {e}")
            
            # æ–¹æ³•3: æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­æ˜¯å¦å·²æœ‰run ID
            env_run_id = os.getenv("WANDB_RUN_ID")
            if env_run_id:
                logger.info(f"ğŸ”„ ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„WandB run ID: {env_run_id}")
                return env_run_id, None
            
            logger.info("âŒ æœªèƒ½æ‰¾åˆ°WandB run ID")
            return None, None
            
        except Exception as e:
            logger.warning(f"âš ï¸ æå–WandB run IDæ—¶å‡ºé”™: {e}")
            return None, None

    def _setup_logging(self):
        """Setup logging with improved error handling"""
        from datetime import datetime

        run_specific_name_from_env = os.getenv("WANDB_RUN_NAME")
        if not run_specific_name_from_env:
            run_specific_name_from_env = f"{self.env_cfg.wandb_run_name_prefix}_{datetime.now().strftime('%Y%m%d-%H%M%S')}" \
                if self.env_cfg.wandb_run_name_prefix else f"run_{datetime.now().strftime('%Y%m%d-%H%M%S')}"

        sanitized_run_name = re.sub(r'[^\w\-.]', '_', run_specific_name_from_env)

        # Determine if resuming
        is_resuming = (
            self.grpo_cfg.resume_from_checkpoint and
            isinstance(self.grpo_cfg.resume_from_checkpoint, str) and
            os.path.isdir(self.grpo_cfg.resume_from_checkpoint)
        )

        if is_resuming:
            actual_output_dir = os.path.dirname(self.grpo_cfg.resume_from_checkpoint)
        else:
            actual_output_dir = os.path.join(self.env_cfg.output_dir_base, sanitized_run_name)

        if self.grpo_cfg.local_rank <= 0:
            os.makedirs(actual_output_dir, exist_ok=True)

        # Update config objects
        self.grpo_cfg.output_dir = actual_output_dir
        self.script_cfg.output_dir = actual_output_dir

        log_file_path = os.path.join(self.grpo_cfg.output_dir, "grpo_pipeline_log.txt")
        setup_global_logging(
            log_level=self.grpo_cfg.get_process_log_level(),
            log_file_path=log_file_path,
            local_rank=self.grpo_cfg.local_rank
        )
        logger.info(f"Global logging set up. Output directory: {self.grpo_cfg.output_dir}")

    def _log_configs(self):
        # ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºé•¿åº¦é…ç½®ä¿¡æ¯
        logger.info("ğŸ“ é•¿åº¦é…ç½®:")
        logger.info(f"  - æ€»åºåˆ—é•¿åº¦: {self.script_cfg.max_seq_length}")
        logger.info(f"  - æœ€å¤§æç¤ºé•¿åº¦: {self.script_cfg.script_max_prompt_length} ({self.script_cfg.script_max_prompt_length/self.script_cfg.max_seq_length*100:.1f}%)")
        logger.info(f"  - æœ€å¤§è¾“å‡ºé•¿åº¦: {self.script_cfg.script_max_completion_length} ({self.script_cfg.script_max_completion_length/self.script_cfg.max_seq_length*100:.1f}%)")
        logger.info(f"  - åˆ†é…ç­–ç•¥: {self.script_cfg.length_allocation_strategy}")
        logger.info(f"  - GRPO max_prompt_length: {self.grpo_cfg.max_prompt_length}")
        logger.info(f"  - GRPO max_completion_length: {self.grpo_cfg.max_completion_length}")
        
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(f"EnvConfig: \n{json.dumps(asdict(self.env_cfg), indent=2)}")
            logger.debug(f"ScriptConfig: \n{json.dumps(asdict(self.script_cfg), indent=2)}")
            logger.debug(f"EnhancedRewardConfig: \n{json.dumps(asdict(self.reward_cfg), indent=2)}")

    def _setup_model_and_tokenizer(self):
        """ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®è®¾ç½®æ¨¡å‹å’Œtokenizer"""
        try:
            logger.info("Setting up model and tokenizer...")
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šè°ƒç”¨ModelManagerçš„æ–¹æ³•
            self.model, self.tokenizer = self.model_manager.setup_model_and_tokenizer()
            
            # åº”ç”¨PEFTé€‚é…å™¨
            is_resuming = (
                self.grpo_cfg.resume_from_checkpoint and 
                isinstance(self.grpo_cfg.resume_from_checkpoint, str) and 
                os.path.isdir(self.grpo_cfg.resume_from_checkpoint)
            )
            
            self.model = self.model_manager.apply_peft_adapter(
                model=self.model,
                is_resuming=is_resuming,
                resume_checkpoint_path=str(self.grpo_cfg.resume_from_checkpoint) if is_resuming else None
            )
            
            logger.info("âœ… Model and tokenizer setup completed successfully.")
            return self.model, self.tokenizer
            
        except Exception as e:
            logger.error(f"âŒ Failed to setup model and tokenizer: {e}", exc_info=True)
            raise
    def _initialize_trainer(self):
        logger.info("Initializing GRPOTrainer...")

        reward_function = self._get_reward_function_with_context()

        self.trainer = GRPOTrainer(
            model=self.model,
            args=self.grpo_cfg,
            train_dataset=self.dataset_for_trainer,
            reward_funcs=[reward_function],
            tokenizer=self.tokenizer,
            callbacks=self.callbacks,
        )

        # ğŸ”§ é‡è¦ï¼šè®¾ç½® trainer_ref ä¸ºæ‰€æœ‰éœ€è¦çš„å›è°ƒ
        for cb in self.callbacks:
            if hasattr(cb, 'trainer_ref') and cb.trainer_ref is None:
                cb.trainer_ref = self.trainer
                logger.info(f"âœ… Set trainer_ref for {type(cb).__name__}")

        logger.info("GRPOTrainer initialized successfully.")

        # ğŸ”§ é¢å¤–çš„è¯¾ç¨‹å­¦ä¹ çŠ¶æ€éªŒè¯
        if self.curriculum_manager:
            logger.info("ğŸ“š æœ€ç»ˆè¯¾ç¨‹å­¦ä¹ çŠ¶æ€éªŒè¯:")
            logger.info(f"  - è¯¾ç¨‹ç®¡ç†å™¨ç±»å‹: {type(self.curriculum_manager).__name__}")
            
            # éªŒè¯è¯¾ç¨‹ç®¡ç†å™¨æ˜¯å¦æœ‰è°ƒè¯•æ—¥å¿—
            if hasattr(self.curriculum_manager, 'debug_log'):
                logger.info(f"  - è°ƒè¯•æ—¥å¿—æ¡ç›®: {len(self.curriculum_manager.debug_log)}")
                if self.curriculum_manager.debug_log:
                    logger.info(f"  - æœ€æ–°æ—¥å¿—: {self.curriculum_manager.debug_log[-1]}")
            
            # éªŒè¯å½“å‰é˜¶æ®µæ•°æ®é›†
            try:
                current_dataset = self.curriculum_manager.get_current_stage_dataset()
                logger.info(f"  - å½“å‰æ•°æ®é›†éªŒè¯: {len(current_dataset)} samples")
            except Exception as e:
                logger.error(f"  - æ•°æ®é›†éªŒè¯å¤±è´¥: {e}")

            # éªŒè¯è¯¾ç¨‹é˜¶æ®µé…ç½®
            for i, stage in enumerate(self.curriculum_manager.curriculum_stages):
                status = "ğŸ”„ å½“å‰" if i == self.curriculum_manager.current_stage else "â³ å¾…è¿›å…¥"
                logger.info(f"  - é˜¶æ®µ{i}: {stage.name} ({status})")

    def _initialize_components(self, dataset_processed):
        """Initialize components that depend on the processed dataset"""
        try:
            logger.info("Initializing training components...")
            
            # Experience buffer setup
            if self.script_cfg.enable_experience_replay:
                self.experience_buffer = ExperienceBuffer(max_size=self.script_cfg.experience_buffer_size)
                logger.info(f"Experience buffer initialized (size: {self.script_cfg.experience_buffer_size}).")
                
                # Restore experience buffer state if resuming
                if self.grpo_cfg.resume_from_checkpoint and os.path.isdir(self.grpo_cfg.resume_from_checkpoint):
                    buffer_state_path = os.path.join(self.grpo_cfg.resume_from_checkpoint, "enhanced_experience_buffer_state.json")
                    if os.path.exists(buffer_state_path):
                        try:
                            logger.info(f"Loading experience buffer state from: {buffer_state_path}")
                            with open(buffer_state_path, "r", encoding="utf-8") as f:
                                state_data = json.load(f)
                            self.experience_buffer.load_buffer_state(state_data)
                            logger.info("âœ… Experience buffer state loaded successfully.")
                        except Exception as e:
                            logger.warning(f"âš ï¸ Failed to load experience buffer state: {e}")

            # Curriculum learning setup
            if self.script_cfg.enable_curriculum:
                self.curriculum_manager = setup_fixed_curriculum_manager(self.script_cfg, dataset_processed)
                if self.curriculum_manager:
                    logger.info(f"Curriculum learning enabled: {type(self.curriculum_manager).__name__}.")
                    
                    # Restore curriculum state if resuming
                    if self.grpo_cfg.resume_from_checkpoint and os.path.isdir(self.grpo_cfg.resume_from_checkpoint):
                        curriculum_state_path = os.path.join(self.grpo_cfg.resume_from_checkpoint, "enhanced_curriculum_state.json")
                        if os.path.exists(curriculum_state_path):
                            try:
                                logger.info(f"Loading curriculum state from: {curriculum_state_path}")
                                with open(curriculum_state_path, "r", encoding="utf-8") as f:
                                    state_data = json.load(f)
                                self.curriculum_manager.load_curriculum_state(state_data)
                                logger.info("âœ… Curriculum state loaded successfully.")
                            except Exception as e:
                                logger.warning(f"âš ï¸ Failed to load curriculum state: {e}")

            # Setup callbacks
            self._setup_callbacks(dataset_processed)
            logger.info("âœ… All components initialized successfully.")
            
        except Exception as e:
            logger.error(f"âŒ Error during component initialization: {e}", exc_info=True)
            raise

    def _setup_callbacks(self, dataset_processed):
        """Setup all callbacks with enhanced curriculum debugging"""
        try:
            self.callbacks = []
            
            # Basic monitoring callbacks
            self.callbacks.append(StepLoggingCallback())
            self.callbacks.append(DetailedRewardCallback(self.script_cfg.output_dir))
            self.callbacks.append(RewardStabilityMonitor(self.script_cfg.output_dir))

            # ğŸ”§ ä¿®å¤ï¼šå¢å¼ºçš„è¯¾ç¨‹å­¦ä¹ å›è°ƒè®¾ç½®
            if self.curriculum_manager:
                # 1. æ·»åŠ åŸºç¡€çš„è¯¾ç¨‹è¿›åº¦å›è°ƒ
                curriculum_progress_cb = CurriculumProgressCallback(
                    curriculum_manager=self.curriculum_manager, 
                    trainer_ref=None,  # ç¨åè®¾ç½®
                    output_dir=self.script_cfg.output_dir,
                    performance_check_interval=self.script_cfg.curriculum_performance_check_interval
                )
                self.callbacks.append(curriculum_progress_cb)
                logger.info("âœ… æ·»åŠ  CurriculumProgressCallback")

                # 2. æ·»åŠ å¢å¼ºçš„è¯¾ç¨‹è°ƒè¯•å›è°ƒ
                enhanced_curriculum_cb = EnhancedCurriculumDebugCallback(
                    curriculum_manager=self.curriculum_manager, 
                    trainer_ref=None,  # ç¨åè®¾ç½®
                    output_dir=self.script_cfg.output_dir
                )
                self.callbacks.append(enhanced_curriculum_cb)
                logger.info("âœ… æ·»åŠ  EnhancedCurriculumDebugCallback")

                # 3. æ·»åŠ ä¼˜åŒ–çš„è¯¾ç¨‹å›è°ƒï¼ˆå¦‚æœéœ€è¦ï¼‰
                optimized_curriculum_cb = OptimizedCurriculumCallback(
                    curriculum_manager=self.curriculum_manager,
                    trainer_ref=None,  # ç¨åè®¾ç½®
                    output_dir=self.script_cfg.output_dir
                )
                self.callbacks.append(optimized_curriculum_cb)
                logger.info("âœ… æ·»åŠ  OptimizedCurriculumCallback")

            # State persistence callback
            self.callbacks.append(CustomStatePersistenceCallback(
                curriculum_manager=self.curriculum_manager, 
                experience_buffer=self.experience_buffer, 
                script_cfg=self.script_cfg
            ))

            # Inference callback (éœ€è¦ tokenizer)
            # ğŸš€ ä½¿ç”¨æµå¼å¼•å¯¼æ¨ç†å›è°ƒæ›¿ä»£åŸæœ‰çš„DetailedInferenceCallback
            if self.tokenizer and dataset_processed and len(dataset_processed) > 0:
                sample_dataset_for_inf_cb = dataset_processed.select(
                    range(min(len(dataset_processed), self.script_cfg.callback_num_samples * 5))
                )

                if len(sample_dataset_for_inf_cb) > 0:
                    # å¯¼å…¥æµå¼å¼•å¯¼åŠŸèƒ½
                    from grpo_project.utils.streaming_guidance import create_streaming_inference_callback, GuidanceConfig
                    
                    # é…ç½®å¼•å¯¼å‚æ•°
                    guidance_config = GuidanceConfig(
                        min_reasoning_length=self.script_cfg.min_reasoning_length if hasattr(self.script_cfg, 'min_reasoning_length') else 60,
                        guidance_trigger_threshold=self.script_cfg.guidance_trigger_threshold if hasattr(self.script_cfg, 'guidance_trigger_threshold') else 40,
                        max_guidance_attempts=self.script_cfg.max_guidance_attempts if hasattr(self.script_cfg, 'max_guidance_attempts') else 2,
                        guidance_tokens_limit=self.script_cfg.guidance_tokens_limit if hasattr(self.script_cfg, 'guidance_tokens_limit') else 25
                    )
                    
                    # åˆ›å»ºå¢å¼ºçš„æ¨ç†å›è°ƒ
                    streaming_callback = create_streaming_inference_callback(
                        model=self.model,
                        tokenizer=self.tokenizer,
                        eval_dataset=sample_dataset_for_inf_cb,
                        num_samples=self.script_cfg.callback_num_samples,
                        eval_every_n_steps=self.script_cfg.callback_eval_every_n_steps,
                        max_new_tokens=self.script_cfg.script_max_completion_length,
                        max_seq_length=self.script_cfg.max_seq_length,
                        experience_buffer=self.experience_buffer,
                        output_dir=self.script_cfg.output_dir,
                        guidance_config=guidance_config
                    )
                    
                    self.callbacks.append(streaming_callback)
                    logger.info(f"âœ… æµå¼å¼•å¯¼æ¨ç†å›è°ƒå·²æ·»åŠ  (samples: {len(sample_dataset_for_inf_cb)})")
                else:
                    logger.warning("âš ï¸ æ ·æœ¬æ•°æ®ä¸è¶³ï¼Œè·³è¿‡æµå¼å¼•å¯¼æ¨ç†å›è°ƒ")

            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¦ç”¨åŸç”ŸWandBå›è°ƒï¼Œä½¿ç”¨åŒæ­¥ç®¡ç†å™¨
            if self.grpo_cfg.local_rank <= 0 and "wandb" in self.grpo_cfg.report_to:
                # åˆ›å»ºä½¿ç”¨åŒæ­¥ç®¡ç†å™¨çš„WandBå›è°ƒ
                from grpo_project.callbacks.wandb_sync_callback import SyncedWandbCallback
                wandb_cb = SyncedWandbCallback(
                    env_cfg=self.env_cfg, 
                    script_cfg=self.script_cfg, 
                    reward_cfg=self.reward_cfg, 
                    experience_buffer=self.experience_buffer
                )
                self.callbacks.append(wandb_cb)
                # å­˜å‚¨ wandb_callback å¼•ç”¨ä¾› reward function ä½¿ç”¨
                self.wandb_callback = wandb_cb
                logger.info("âœ… SyncedWandbCallback added (æ›¿ä»£åŸç”ŸWandB).")

            logger.info(f"Total callbacks prepared: {len(self.callbacks)}")
            
            # ğŸ”§ é‡è¦ï¼šç¡®ä¿è¯¾ç¨‹å­¦ä¹ å›è°ƒæœ‰è¯¦ç»†çš„åˆå§‹åŒ–æ—¥å¿—
            if self.curriculum_manager:
                logger.info("ğŸ“š è¯¾ç¨‹å­¦ä¹ å›è°ƒè¯¦ç»†ä¿¡æ¯:")
                logger.info(f"  - å½“å‰é˜¶æ®µ: {self.curriculum_manager.current_stage}")
                logger.info(f"  - æ€»é˜¶æ®µæ•°: {len(self.curriculum_manager.curriculum_stages)}")
                
                # è®°å½•å½“å‰é˜¶æ®µè¯¦æƒ…
                if self.curriculum_manager.current_stage < len(self.curriculum_manager.curriculum_stages):
                    current_stage = self.curriculum_manager.curriculum_stages[self.curriculum_manager.current_stage]
                    logger.info(f"  - å½“å‰é˜¶æ®µåç§°: {current_stage.name}")
                    logger.info(f"  - æ€§èƒ½é˜ˆå€¼: {current_stage.performance_threshold}")
                    logger.info(f"  - æœ€å°è¯„ä¼°æ¬¡æ•°: {current_stage.min_evaluations}")
                    
                    # è®°å½•æ•°æ®é›†å¤§å°
                    current_dataset = self.curriculum_manager.get_current_stage_dataset()
                    logger.info(f"  - å½“å‰é˜¶æ®µæ•°æ®é›†å¤§å°: {len(current_dataset)}")

        except Exception as e:
            logger.error(f"âŒ Error setting up callbacks: {e}", exc_info=True)
            # è‡³å°‘ä¿è¯åŸºæœ¬çš„å›è°ƒ
            self.callbacks = [StepLoggingCallback()]
            logger.warning("âš ï¸ Using minimal callback setup due to errors.")
    def get_reward_function(self):
        """Create reward function closure with enhanced debugging"""
        def reward_fn_closure(prompts: List[str], completions: List[str], **kwargs_from_trainer_dataset) -> List[float]:
            try:
                current_training_step = self.trainer.state.global_step if self.trainer and self.trainer.state else 0

                # ğŸ”§ æ·»åŠ è¯¦ç»†çš„å¥–åŠ±è®¡ç®—æ—¥å¿—
                if current_training_step % 10 == 0:  # æ¯10æ­¥è®°å½•ä¸€æ¬¡
                    logger.info(f"ğŸ¯ æ­¥æ•° {current_training_step}: å¼€å§‹å¥–åŠ±è®¡ç®—")
                    logger.info(f"  - æ‰¹æ¬¡å¤§å°: {len(prompts)}")
                    logger.info(f"  - å®Œæˆé•¿åº¦: {[len(c) for c in completions[:3]]}{'...' if len(completions) > 3 else ''}")

                batch_rewards_args = {
                    "prompts": prompts,
                    "completions": completions,
                    "testbench_paths": kwargs_from_trainer_dataset.get('testbench_path', []),
                    "expected_total_tests_list": kwargs_from_trainer_dataset.get('expected_total_tests', []),
                    "reference_verilog_paths": kwargs_from_trainer_dataset.get('reference_verilog_path', []),
                    "original_enhanced_prompts": kwargs_from_trainer_dataset.get('original_enhanced_prompt'),
                    "training_step": current_training_step,
                    "output_dir_for_debug": self.script_cfg.output_dir,
                    # ğŸ”§ ç¡®ä¿ä¼ é€’æ­£ç¡®çš„ wandb_callback å¼•ç”¨
                    "wandb_callback_obj": getattr(self, 'wandb_callback', None),
                    "experience_buffer_obj": self.experience_buffer,
                    "script_config_obj": self.script_cfg
                }
                
                rewards_list, aggregated_metrics = self.reward_calculator.calculate_batch_rewards(**batch_rewards_args)
                
                # ğŸ”§ æ·»åŠ å¥–åŠ±ç»Ÿè®¡æ—¥å¿—
                if current_training_step % 10 == 0:
                    reward_stats = {
                        'mean': np.mean(rewards_list) if rewards_list else 0,
                        'std': np.std(rewards_list) if rewards_list else 0,
                        'min': np.min(rewards_list) if rewards_list else 0,
                        'max': np.max(rewards_list) if rewards_list else 0
                    }
                    logger.info(f"  - å¥–åŠ±ç»Ÿè®¡: mean={reward_stats['mean']:.4f}, std={reward_stats['std']:.4f}")
                    logger.info(f"  - å¥–åŠ±èŒƒå›´: [{reward_stats['min']:.4f}, {reward_stats['max']:.4f}]")
                
                return rewards_list
                    
            except Exception as e:
                logger.error(f"âŒ Error in reward function at step {current_training_step}: {e}", exc_info=True)
                # è¿”å›é»˜è®¤å¥–åŠ±é¿å…è®­ç»ƒä¸­æ–­
                return [0.0] * len(prompts)
        
        return reward_fn_closure

    def train(self):
        """Main training function with comprehensive error handling"""
        try:
            logger.info("ğŸš€ Starting GRPO training process...")
            
            # ğŸ”§ æ–°å¢ï¼šè®¾ç½®ç¨³å®šçš„è®­ç»ƒç¯å¢ƒ
            self._setup_stable_environment()
            
            # ğŸ”§ å…³é”®ï¼šåœ¨è®­ç»ƒå¼€å§‹å‰é…ç½®WandBæ¢å¤
            logger.info("ğŸ“ Step 0: Configuring WandB resume settings...")
            self._configure_wandb_resume()
            
            # ğŸ”§ æ–°å¢ï¼šè®¾ç½®WandBåŒæ­¥ç®¡ç†å™¨è¿è¡Œ
            logger.info("ğŸ“ Step 0.5: Setting up WandB sync manager run...")
            self._setup_wandb_run()

            # 1. Setup model and tokenizer - ğŸ”§ ä¿®å¤è°ƒç”¨
            logger.info("ğŸ“ Step 1: Setting up model and tokenizer...")
            self._setup_model_and_tokenizer()  # ğŸ”§ è¿™é‡Œä¸å†è§£åŒ…ï¼Œå› ä¸ºå·²ç»åœ¨æ–¹æ³•å†…éƒ¨è®¾ç½®äº†self.modelå’Œself.tokenizer

            # 2. Load and preprocess data
            logger.info("ğŸ“ Step 2: Loading and preparing dataset...")
            dataset_processed = load_and_prepare_dataset(
                script_cfg=self.script_cfg,
                env_cfg=self.env_cfg,
                tokenizer=self.tokenizer
            )

            if not dataset_processed or len(dataset_processed) == 0:
                raise ValueError("âŒ Dataset is empty after processing!")

            # 3. Initialize components
            logger.info("ğŸ“ Step 3: Initializing training components...")
            self._initialize_components(dataset_processed)

            # 4. Determine training dataset
            dataset_for_trainer = dataset_processed
            if self.curriculum_manager:
                dataset_for_trainer = self.curriculum_manager.get_current_stage_dataset()
                current_stage_name = self.curriculum_manager.get_current_stage_info()['stage_name']
                logger.info(f"ğŸ“š Using curriculum dataset: {len(dataset_for_trainer)} samples from stage '{current_stage_name}'.")
            else:
                logger.info(f"ğŸ“š Using full processed dataset: {len(dataset_for_trainer)} samples.")

            if not dataset_for_trainer or len(dataset_for_trainer) == 0:
                raise ValueError("âŒ Training dataset is empty!")

            # 5. Create trainer
            logger.info("ğŸ“ Step 4: Creating GRPOTrainer...")
            from trl import GRPOTrainer
            
            # ğŸ”§ å…³é”®ï¼šç¦ç”¨å†…ç½®WandBï¼Œå®Œå…¨ä½¿ç”¨æˆ‘ä»¬çš„åŒæ­¥å›è°ƒ
            grpo_cfg_copy = self.grpo_cfg
            if "wandb" in grpo_cfg_copy.report_to:
                # åˆ›å»ºä¸€ä¸ªä¸åŒ…å«wandbçš„copy
                import copy
                grpo_cfg_copy = copy.deepcopy(self.grpo_cfg)
                grpo_cfg_copy.report_to = [r for r in grpo_cfg_copy.report_to if r != "wandb"]
                logger.info("ğŸ”§ ç¦ç”¨GRPOTrainerå†…ç½®WandBæŠ¥å‘Šï¼Œä½¿ç”¨åŒæ­¥å›è°ƒ")
            
            self.trainer = GRPOTrainer(
                model=self.model,
                args=grpo_cfg_copy,
                train_dataset=dataset_for_trainer,
                reward_funcs=[self.get_reward_function()],
                callbacks=self.callbacks
            )

            # Set trainer references for callbacks
            for cb in self.callbacks:
                if hasattr(cb, 'trainer_ref') and cb.trainer_ref is None:
                    cb.trainer_ref = self.trainer
                    logger.debug(f"Set trainer_ref for {type(cb).__name__}")

            # 6. Start training
            logger.info("ğŸ“ Step 5: Starting training...")
            logger.info(f"ğŸ¯ Training with {len(dataset_for_trainer)} examples.")
            
            train_result = self.trainer.train(resume_from_checkpoint=self.grpo_cfg.resume_from_checkpoint)
            logger.info("âœ… Training completed successfully!")

            # 7. Save artifacts
            if self.grpo_cfg.local_rank <= 0:
                self._save_training_artifacts(train_result)

        except Exception as e:
            logger.error(f"âŒ Training failed: {e}", exc_info=True)
            raise

    def _save_training_artifacts(self, train_result):
        """Save training artifacts"""
        try:
            logger.info("ğŸ’¾ Saving training artifacts...")
            
            # Save final model
            final_model_dir = os.path.join(self.grpo_cfg.output_dir, "final_model_adapter")
            self.trainer.save_model(final_model_dir)
            logger.info(f"âœ… Final model saved to: {final_model_dir}")

            # Save metrics and state
            metrics = train_result.metrics if hasattr(train_result, 'metrics') else {}
            
            if hasattr(self.trainer, 'log_metrics'):
                self.trainer.log_metrics("train_summary", metrics)
            
            if hasattr(self.trainer, 'save_metrics'):
                metrics_file = os.path.join(self.grpo_cfg.output_dir, "final_train_metrics.json")
                self.trainer.save_metrics("train_summary", metrics_file)
                logger.info(f"âœ… Metrics saved to: {metrics_file}")
            
            if hasattr(self.trainer, 'save_state'):
                self.trainer.save_state()
                logger.info("âœ… Trainer state saved.")

            logger.info(f"ğŸ‰ All training artifacts saved to: {self.grpo_cfg.output_dir}")
            
        except Exception as e:
            logger.error(f"âŒ Error saving training artifacts: {e}", exc_info=True)

    def cleanup(self):
        """Cleanup resources"""
        try:
            logger.info("ğŸ§¹ Cleaning up resources...")
            
            # 1. æ¸…ç†WandBåŒæ­¥ç®¡ç†å™¨
            try:
                sync_manager = get_wandb_sync_manager()
                if sync_manager:
                    sync_manager.finish()
                    logger.info("âœ… WandBåŒæ­¥ç®¡ç†å™¨å·²æ¸…ç†")
            except Exception as e:
                logger.warning(f"âš ï¸ WandBåŒæ­¥ç®¡ç†å™¨æ¸…ç†å¤±è´¥: {e}")
            
            # 2. Clear GPU memory
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                logger.info("âœ… GPU cache cleared.")
            
            # 3. Force garbage collection
            gc.collect()
            logger.info("âœ… Garbage collection completed.")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Error during cleanup: {e}")


def main():
    """Main entry point with comprehensive error handling"""
    pipeline = None
    try:
        logger_temp.info("ğŸš€ Initializing GRPO Training Pipeline...")
        pipeline = GRPOTrainingPipeline()
        
        logger_temp.info("ğŸ¯ Starting training...")
        pipeline.train()
        
        logger_temp.info("âœ… Training completed successfully!")
        
    except KeyboardInterrupt:
        logger_temp.warning("âš ï¸ Training interrupted by user (Ctrl+C)")
        return 1
        
    except Exception as e:
        logger_temp.error(f"ğŸ’¥ Fatal error in training pipeline: {e}", exc_info=True)
        return 1
        
    finally:
        if pipeline:
            try:
                pipeline.cleanup()
            except Exception as cleanup_error:
                logger_temp.warning(f"âš ï¸ Error during cleanup: {cleanup_error}")
        
        logger_temp.info("ğŸ GRPO Training Pipeline execution finished.")
        return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)