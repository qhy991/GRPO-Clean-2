#!/usr/bin/env python3
"""
DEBUGæ•°æ®åˆ†æè„šæœ¬
ç”¨äºåˆ†æè®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„æ‰€æœ‰DEBUGæ•°æ®
"""

import os
import json
import glob
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import argparse

def analyze_debug_data(debug_output_base):
    """åˆ†æDEBUGæ•°æ®çš„ä¸»å‡½æ•°"""
    
    print(f"ğŸ” å¼€å§‹åˆ†æDEBUGæ•°æ®: {debug_output_base}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(debug_output_base):
        print(f"âŒ DEBUGç›®å½•ä¸å­˜åœ¨: {debug_output_base}")
        return
    
    # è·å–æ‰€æœ‰æ—¶é—´æˆ³ç›®å½•
    timestamp_dirs = glob.glob(os.path.join(debug_output_base, "*", "*"))
    timestamp_dirs = [d for d in timestamp_dirs if os.path.isdir(d)]
    
    print(f"ğŸ“ æ‰¾åˆ° {len(timestamp_dirs)} ä¸ªæ—¶é—´æˆ³ç›®å½•")
    
    for timestamp_dir in sorted(timestamp_dirs):
        print(f"\nğŸ“Š åˆ†ææ—¶é—´æˆ³: {os.path.basename(timestamp_dir)}")
        analyze_timestamp_data(timestamp_dir)
    
    # ç”Ÿæˆæ€»ä½“åˆ†ææŠ¥å‘Š
    generate_overall_report(debug_output_base, timestamp_dirs)

def analyze_timestamp_data(timestamp_dir):
    """åˆ†æå•ä¸ªæ—¶é—´æˆ³çš„æ•°æ®"""
    
    # åˆ†æç”Ÿæˆæ ·æœ¬
    generations_dir = os.path.join(timestamp_dir, "generations")
    if os.path.exists(generations_dir):
        analyze_generations(generations_dir)
    
    # åˆ†æå¤±è´¥æ ·æœ¬
    failed_dir = os.path.join(timestamp_dir, "failed_generations") 
    if os.path.exists(failed_dir):
        analyze_failed_generations(failed_dir)
    
    # åˆ†ææˆåŠŸæ ·æœ¬
    success_dir = os.path.join(timestamp_dir, "successful_generations")
    if os.path.exists(success_dir):
        analyze_successful_generations(success_dir)
    
    # åˆ†æè¯¦ç»†æŒ‡æ ‡
    metrics_dir = os.path.join(timestamp_dir, "detailed_metrics")
    if os.path.exists(metrics_dir):
        analyze_detailed_metrics(metrics_dir)
    
    # åˆ†æå¥–åŠ±è¯¦æƒ…
    reward_dir = os.path.join(timestamp_dir, "reward_details")
    if os.path.exists(reward_dir):
        analyze_reward_details(reward_dir)

def analyze_generations(generations_dir):
    """åˆ†æç”Ÿæˆæ ·æœ¬"""
    json_files = glob.glob(os.path.join(generations_dir, "*.json"))
    print(f"  ğŸ“ ç”Ÿæˆæ ·æœ¬æ–‡ä»¶: {len(json_files)}")
    
    if json_files:
        total_samples = 0
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        total_samples += len(data)
                    else:
                        total_samples += 1
            except Exception as e:
                print(f"    âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {json_file}, é”™è¯¯: {e}")
        
        print(f"  ğŸ“Š æ€»ç”Ÿæˆæ ·æœ¬æ•°: {total_samples}")

def analyze_failed_generations(failed_dir):
    """åˆ†æå¤±è´¥çš„ç”Ÿæˆæ ·æœ¬"""
    json_files = glob.glob(os.path.join(failed_dir, "*.json"))
    print(f"  âŒ å¤±è´¥æ ·æœ¬æ–‡ä»¶: {len(json_files)}")
    
    if json_files:
        failure_reasons = {}
        total_failed = 0
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                    if isinstance(data, list):
                        for item in data:
                            total_failed += 1
                            reason = item.get('failure_reason', 'unknown')
                            failure_reasons[reason] = failure_reasons.get(reason, 0) + 1
                    else:
                        total_failed += 1
                        reason = data.get('failure_reason', 'unknown')
                        failure_reasons[reason] = failure_reasons.get(reason, 0) + 1
                        
            except Exception as e:
                print(f"    âŒ è¯»å–å¤±è´¥æ–‡ä»¶é”™è¯¯: {json_file}, é”™è¯¯: {e}")
        
        print(f"  ğŸ“Š æ€»å¤±è´¥æ ·æœ¬æ•°: {total_failed}")
        print(f"  ğŸ“‹ å¤±è´¥åŸå› ç»Ÿè®¡:")
        for reason, count in sorted(failure_reasons.items(), key=lambda x: x[1], reverse=True):
            print(f"    - {reason}: {count}")

def analyze_successful_generations(success_dir):
    """åˆ†ææˆåŠŸçš„ç”Ÿæˆæ ·æœ¬"""
    json_files = glob.glob(os.path.join(success_dir, "*.json"))
    print(f"  âœ… æˆåŠŸæ ·æœ¬æ–‡ä»¶: {len(json_files)}")
    
    if json_files:
        total_success = 0
        reward_scores = []
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                    if isinstance(data, list):
                        for item in data:
                            total_success += 1
                            if 'reward_score' in item:
                                reward_scores.append(item['reward_score'])
                    else:
                        total_success += 1
                        if 'reward_score' in data:
                            reward_scores.append(data['reward_score'])
                            
            except Exception as e:
                print(f"    âŒ è¯»å–æˆåŠŸæ–‡ä»¶é”™è¯¯: {json_file}, é”™è¯¯: {e}")
        
        print(f"  ğŸ“Š æ€»æˆåŠŸæ ·æœ¬æ•°: {total_success}")
        if reward_scores:
            print(f"  ğŸ† å¹³å‡å¥–åŠ±åˆ†æ•°: {sum(reward_scores)/len(reward_scores):.4f}")
            print(f"  ğŸ† æœ€é«˜å¥–åŠ±åˆ†æ•°: {max(reward_scores):.4f}")
            print(f"  ğŸ† æœ€ä½å¥–åŠ±åˆ†æ•°: {min(reward_scores):.4f}")

def analyze_detailed_metrics(metrics_dir):
    """åˆ†æè¯¦ç»†æŒ‡æ ‡"""
    json_files = glob.glob(os.path.join(metrics_dir, "*.json"))
    print(f"  ğŸ“ˆ æŒ‡æ ‡æ–‡ä»¶: {len(json_files)}")

def analyze_reward_details(reward_dir):
    """åˆ†æå¥–åŠ±è¯¦æƒ…"""
    json_files = glob.glob(os.path.join(reward_dir, "*.json"))
    print(f"  ğŸ¯ å¥–åŠ±è¯¦æƒ…æ–‡ä»¶: {len(json_files)}")

def generate_overall_report(debug_output_base, timestamp_dirs):
    """ç”Ÿæˆæ€»ä½“åˆ†ææŠ¥å‘Š"""
    report_file = os.path.join(debug_output_base, f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=== DEBUGæ•°æ®åˆ†ææŠ¥å‘Š ===\n")
        f.write(f"åˆ†ææ—¶é—´: {datetime.now()}\n")
        f.write(f"æ•°æ®ç›®å½•: {debug_output_base}\n")
        f.write(f"æ—¶é—´æˆ³ç›®å½•æ•°: {len(timestamp_dirs)}\n")
        f.write("\n")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„ç»Ÿè®¡åˆ†æ
        
    print(f"\nğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

def main():
    parser = argparse.ArgumentParser(description='åˆ†æè®­ç»ƒDEBUGæ•°æ®')
    parser.add_argument('--debug_dir', 
                       default='./model_parallel_only_outputs/debug_data',
                       help='DEBUGæ•°æ®ç›®å½•è·¯å¾„')
    
    args = parser.parse_args()
    
    analyze_debug_data(args.debug_dir)

if __name__ == "__main__":
    main() 