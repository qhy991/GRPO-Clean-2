import os
import logging
import json
from datetime import datetime
from typing import Optional, Any, Dict # Added for type hints

logger = logging.getLogger(__name__)

class PeriodicStatusReporter:
    def __init__(self, output_dir, report_interval=100):
        self.output_dir = output_dir
        self.report_interval = report_interval
        # Ensure output_dir exists for status_log_path
        os.makedirs(self.output_dir, exist_ok=True)
        self.status_log_path = os.path.join(output_dir, "training_status.txt")

    def report_status(self, step: int, trainer_state: Any,
                      curriculum_manager: Optional[Any] = None,
                      experience_buffer: Optional[Any] = None):
        """ç”Ÿæˆå®šæœŸçŠ¶æ€æŠ¥å‘Š"""
        if step % self.report_interval != 0:
            return

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        status_report = f"""
========================================
è®­ç»ƒçŠ¶æ€æŠ¥å‘Š - æ­¥æ•° {step}
æ—¶é—´: {timestamp}
========================================

ğŸ“ˆ è®­ç»ƒè¿›åº¦:
  - å½“å‰æ­¥æ•°: {step}
  - æœ€å¤§æ­¥æ•°: {trainer_state.max_steps if hasattr(trainer_state, 'max_steps') and trainer_state.max_steps > 0 else 'æ— é™åˆ¶'}
  - å®Œæˆç™¾åˆ†æ¯”: {(step/trainer_state.max_steps*100) if hasattr(trainer_state, 'max_steps') and trainer_state.max_steps > 0 else 'N/A'}%

ğŸ“š è¯¾ç¨‹å­¦ä¹ çŠ¶æ€:"""

        if curriculum_manager and hasattr(curriculum_manager, 'current_stage') and hasattr(curriculum_manager, 'curriculum_stages'):
            current_stage = curriculum_manager.current_stage
            total_stages = len(curriculum_manager.curriculum_stages)
            stage_name = "Unknown/Final"
            if current_stage < total_stages and hasattr(curriculum_manager.curriculum_stages[current_stage], 'name'):
                 stage_name = curriculum_manager.curriculum_stages[current_stage].name

            dataset_size = 0
            if hasattr(curriculum_manager, 'get_current_stage_dataset'):
                current_ds = curriculum_manager.get_current_stage_dataset()
                if current_ds is not None:
                    dataset_size = len(current_ds)

            status_report += f"""
  - å½“å‰é˜¶æ®µ: {current_stage}/{total_stages-1 if total_stages > 0 else 0}
  - é˜¶æ®µåç§°: {stage_name}
  - é˜¶æ®µè¿›åº¦: {len(getattr(curriculum_manager, 'stage_performance_history', []))}æ¬¡è¯„ä¼°
  - æ•°æ®é›†å¤§å°: {dataset_size}"""
        else:
            status_report += "\n  - è¯¾ç¨‹å­¦ä¹ : æœªå¯ç”¨æˆ–ä¿¡æ¯ä¸å®Œæ•´"

        status_report += f"""

ğŸ”„ ç»éªŒå›æ”¾çŠ¶æ€:"""

        if experience_buffer and hasattr(experience_buffer, 'get_stats') and hasattr(experience_buffer, 'max_size'):
            buffer_stats = experience_buffer.get_stats()
            status_report += f"""
  - ç¼“å­˜å¤§å°: {buffer_stats.get('size', 'N/A')}/{experience_buffer.max_size}
  - å¹³å‡å¥–åŠ±: {buffer_stats.get('mean_reward', 0.0):.2f}
  - æœ€é«˜å¥–åŠ±: {buffer_stats.get('max_reward', 0.0):.2f}"""
        else:
            status_report += "\n  - ç»éªŒå›æ”¾: æœªå¯ç”¨æˆ–ä¿¡æ¯ä¸å®Œæ•´"

        # æœ€è¿‘çš„æŸå¤±ä¿¡æ¯
        if hasattr(trainer_state, 'log_history') and trainer_state.log_history:
            recent_log = trainer_state.log_history[-1]
            recent_loss = recent_log.get('loss', 'N/A')
            learning_rate = recent_log.get('learning_rate', 'N/A')
            status_report += f"""

ğŸ“Š æœ€è¿‘æŒ‡æ ‡:
  - è®­ç»ƒæŸå¤±: {recent_loss}
  - å­¦ä¹ ç‡: {learning_rate}"""
        else:
            status_report += f"""

ğŸ“Š æœ€è¿‘æŒ‡æ ‡:
  - è®­ç»ƒæŸå¤±: N/A
  - å­¦ä¹ ç‡: N/A"""

        status_report += f"""

========================================
"""

        # è¾“å‡ºåˆ°æ§åˆ¶å°
        logger.info(status_report)

        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open(self.status_log_path, 'a', encoding='utf-8') as f:
                f.write(status_report + "\n")
        except Exception as e:
            logger.error(f"Failed to write status report to {self.status_log_path}: {e}")

def debug_checkpoint_contents(checkpoint_path: str):
    """è°ƒè¯•checkpointå†…å®¹"""
    if not os.path.exists(checkpoint_path):
        logger.error(f"Checkpointè·¯å¾„ä¸å­˜åœ¨: {checkpoint_path}")
        return

    logger.info(f"ğŸ” æ£€æŸ¥checkpointå†…å®¹: {checkpoint_path}")

    # åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
    try:
        files = os.listdir(checkpoint_path)
        logger.info(f"Checkpointæ–‡ä»¶åˆ—è¡¨: {files}")

        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        key_files: Dict[str, str] = {
            'config.json': 'æ¨¡å‹é…ç½®',
            'pytorch_model.bin': 'PyTorchæ¨¡å‹æƒé‡',
            'model.safetensors': 'SafeTensorsæ¨¡å‹æƒé‡',
            'adapter_config.json': 'PEFTé€‚é…å™¨é…ç½®',
            'adapter_model.bin': 'PEFTé€‚é…å™¨æƒé‡(bin)',
            'adapter_model.safetensors': 'PEFTé€‚é…å™¨æƒé‡(safetensors)',
            'training_args.bin': 'è®­ç»ƒå‚æ•°',
            'trainer_state.json': 'è®­ç»ƒçŠ¶æ€',
            'optimizer.pt': 'ä¼˜åŒ–å™¨çŠ¶æ€',
            'scheduler.pt': 'è°ƒåº¦å™¨çŠ¶æ€'
        }

        logger.info("ğŸ“ å…³é”®æ–‡ä»¶æ£€æŸ¥:")
        for filename, description in key_files.items():
            exists = filename in files
            status = "âœ…" if exists else "âŒ"
            logger.info(f"   {status} {filename}: {description}")

    except Exception as e:
        logger.error(f"æ— æ³•è¯»å–checkpointç›®å½•: {e}")
