import os
import logging
import json
from datetime import datetime
from typing import Optional, Any, Dict # Added for type hints

logger = logging.getLogger(__name__)

class PeriodicStatusReporter:
    def __init__(self, output_dir, report_interval=100):
        self.output_dir = output_dir
        self.report_interval = report_interval
        # Ensure output_dir exists for status_log_path
        os.makedirs(self.output_dir, exist_ok=True)
        self.status_log_path = os.path.join(output_dir, "training_status.txt")

    def report_status(self, step: int, trainer_state: Any,
                      curriculum_manager: Optional[Any] = None,
                      experience_buffer: Optional[Any] = None):
        """ç”Ÿæˆå®šæœŸçŠ¶æ€æŠ¥å‘Š"""
        if step % self.report_interval != 0:
            return

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        status_report = f"""
========================================
è®­ç»ƒçŠ¶æ€æŠ¥å‘Š - æ­¥æ•° {step}
æ—¶é—´: {timestamp}
========================================

ğŸ“ˆ è®­ç»ƒè¿›åº¦:
  - å½“å‰æ­¥æ•°: {step}
  - æœ€å¤§æ­¥æ•°: {trainer_state.max_steps if hasattr(trainer_state, 'max_steps') and trainer_state.max_steps > 0 else 'æ— é™åˆ¶'}
  - å®Œæˆç™¾åˆ†æ¯”: {(step/trainer_state.max_steps*100) if hasattr(trainer_state, 'max_steps') and trainer_state.max_steps > 0 else 'N/A'}%

ğŸ“š è¯¾ç¨‹å­¦ä¹ çŠ¶æ€:"""

        if curriculum_manager and hasattr(curriculum_manager, 'current_stage') and hasattr(curriculum_manager, 'curriculum_stages'):
            current_stage = curriculum_manager.current_stage
            total_stages = len(curriculum_manager.curriculum_stages)
            stage_name = "Unknown/Final"
            if current_stage < total_stages and hasattr(curriculum_manager.curriculum_stages[current_stage], 'name'):
                 stage_name = curriculum_manager.curriculum_stages[current_stage].name

            dataset_size = 0
            if hasattr(curriculum_manager, 'get_current_stage_dataset'):
                current_ds = curriculum_manager.get_current_stage_dataset()
                if current_ds is not None:
                    dataset_size = len(current_ds)

            status_report += f"""
  - å½“å‰é˜¶æ®µ: {current_stage}/{total_stages-1 if total_stages > 0 else 0}
  - é˜¶æ®µåç§°: {stage_name}
  - é˜¶æ®µè¿›åº¦: {len(getattr(curriculum_manager, 'stage_performance_history', []))}æ¬¡è¯„ä¼°
  - æ•°æ®é›†å¤§å°: {dataset_size}"""
        else:
            status_report += "\n  - è¯¾ç¨‹å­¦ä¹ : æœªå¯ç”¨æˆ–ä¿¡æ¯ä¸å®Œæ•´"

        status_report += f"""

ğŸ”„ ç»éªŒå›æ”¾çŠ¶æ€:"""

        if experience_buffer and hasattr(experience_buffer, 'get_stats') and hasattr(experience_buffer, 'max_size'):
            buffer_stats = experience_buffer.get_stats()
            status_report += f"""
  - ç¼“å­˜å¤§å°: {buffer_stats.get('size', 'N/A')}/{experience_buffer.max_size}
  - å¹³å‡å¥–åŠ±: {buffer_stats.get('mean_reward', 0.0):.2f}
  - æœ€é«˜å¥–åŠ±: {buffer_stats.get('max_reward', 0.0):.2f}"""
        else:
            status_report += "\n  - ç»éªŒå›æ”¾: æœªå¯ç”¨æˆ–ä¿¡æ¯ä¸å®Œæ•´"

        # æœ€è¿‘çš„æŸå¤±ä¿¡æ¯
        if hasattr(trainer_state, 'log_history') and trainer_state.log_history:
            recent_log = trainer_state.log_history[-1]
            recent_loss = recent_log.get('loss', 'N/A')
            learning_rate = recent_log.get('learning_rate', 'N/A')
            status_report += f"""

ğŸ“Š æœ€è¿‘æŒ‡æ ‡:
  - è®­ç»ƒæŸå¤±: {recent_loss}
  - å­¦ä¹ ç‡: {learning_rate}"""
        else:
            status_report += f"""

ğŸ“Š æœ€è¿‘æŒ‡æ ‡:
  - è®­ç»ƒæŸå¤±: N/A
  - å­¦ä¹ ç‡: N/A"""

        status_report += f"""

========================================
"""

        # è¾“å‡ºåˆ°æ§åˆ¶å°
        logger.info(status_report)

        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open(self.status_log_path, 'a', encoding='utf-8') as f:
                f.write(status_report + "\n")
        except Exception as e:
            logger.error(f"Failed to write status report to {self.status_log_path}: {e}")

def debug_checkpoint_contents(checkpoint_path: str):
    """è°ƒè¯•checkpointå†…å®¹"""
    if not os.path.exists(checkpoint_path):
        logger.error(f"Checkpointè·¯å¾„ä¸å­˜åœ¨: {checkpoint_path}")
        return

    logger.info(f"ğŸ” æ£€æŸ¥checkpointå†…å®¹: {checkpoint_path}")

    # åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
    try:
        files = os.listdir(checkpoint_path)
        logger.info(f"Checkpointæ–‡ä»¶åˆ—è¡¨: {files}")

        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        key_files: Dict[str, str] = {
            'config.json': 'æ¨¡å‹é…ç½®',
            'pytorch_model.bin': 'PyTorchæ¨¡å‹æƒé‡',
            'model.safetensors': 'SafeTensorsæ¨¡å‹æƒé‡',
            'adapter_config.json': 'PEFTé€‚é…å™¨é…ç½®',
            'adapter_model.bin': 'PEFTé€‚é…å™¨æƒé‡(bin)',
            'adapter_model.safetensors': 'PEFTé€‚é…å™¨æƒé‡(safetensors)',
            'training_args.bin': 'è®­ç»ƒå‚æ•°',
            'trainer_state.json': 'è®­ç»ƒçŠ¶æ€',
            'optimizer.pt': 'ä¼˜åŒ–å™¨çŠ¶æ€',
            'scheduler.pt': 'è°ƒåº¦å™¨çŠ¶æ€'
        }

        logger.info("ğŸ“ å…³é”®æ–‡ä»¶æ£€æŸ¥:")
        for filename, description in key_files.items():
            exists = filename in files
            status = "âœ…" if exists else "âŒ"
            logger.info(f"   {status} {filename}: {description}")

    except Exception as e:
        logger.error(f"æ— æ³•è¯»å–checkpointç›®å½•: {e}")

# --- Performance Monitoring Utilities (Moved from root utils.py) ---
import numpy as np # For AdvancedPerformanceMonitor
# datetime is already imported at the top of the file

class AdvancedPerformanceMonitor:
    """é«˜çº§æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self, output_dir: str = None):
        self.output_dir = output_dir
        self.performance_history: List[Dict[str, Any]] = [] # Type hint for clarity
        self.stage_history: List[Any] = [] # Type hint for clarity
        if output_dir and not os.path.exists(output_dir): # Ensure output_dir exists if provided
            os.makedirs(output_dir, exist_ok=True)

    def log_step_performance(self, step: int, loss: float, rewards: List[float],
                           stage: Optional[int] = None, additional_metrics: Optional[Dict[str, Any]] = None): # Type hints
        """è®°å½•å•æ­¥æ€§èƒ½"""

        performance_data: Dict[str, Any] = { # Type hint
            'step': step,
            'timestamp': datetime.now().isoformat(),
            'loss': loss,
            'avg_reward': float(np.mean(rewards)) if rewards else 0.0, # Ensure float
            'reward_std': float(np.std(rewards)) if rewards else 0.0,  # Ensure float
            'min_reward': float(np.min(rewards)) if rewards else 0.0,  # Ensure float
            'max_reward': float(np.max(rewards)) if rewards else 0.0,  # Ensure float
            'batch_size': len(rewards) if rewards else 0,
            'stage': stage
        }

        if additional_metrics:
            performance_data.update(additional_metrics)

        self.performance_history.append(performance_data)

        # æ¯10æ­¥è¾“å‡ºæ‘˜è¦
        if step % 10 == 0: # Make this configurable?
            self._log_performance_summary(performance_data)

    def _log_performance_summary(self, current_data: Dict[str, Any]): # Type hint
        """è¾“å‡ºæ€§èƒ½æ‘˜è¦"""
        step = current_data['step']

        logger.info(f"""
        ğŸ“Š æ­¥æ•° {step} æ€§èƒ½æ‘˜è¦:
        â”œâ”€ æŸå¤±: {current_data['loss']:.4f}
        â”œâ”€ å¹³å‡å¥–åŠ±: {current_data['avg_reward']:.4f}
        â”œâ”€ å¥–åŠ±æ ‡å‡†å·®: {current_data['reward_std']:.4f}
        â”œâ”€ å¥–åŠ±èŒƒå›´: [{current_data['min_reward']:.4f}, {current_data['max_reward']:.4f}]
        â”œâ”€ æ‰¹æ¬¡å¤§å°: {current_data['batch_size']}
        â””â”€ å½“å‰é˜¶æ®µ: {current_data.get('stage', 'Unknown')}
        """)

    def analyze_recent_performance(self, window_size: int = 20) -> Dict[str, float]:
        """åˆ†ææœ€è¿‘çš„æ€§èƒ½è¶‹åŠ¿"""
        if len(self.performance_history) < window_size:
            return {} # Return empty if not enough data

        recent_data = self.performance_history[-window_size:]

        losses = [float(d['loss']) for d in recent_data] # Ensure float
        avg_rewards = [float(d['avg_reward']) for d in recent_data] # Ensure float

        # Calculate trend if there are enough points for polyfit (at least 2)
        loss_trend = 0.0
        reward_trend = 0.0
        if len(losses) >= 2:
            loss_trend = float(np.polyfit(range(len(losses)), losses, 1)[0])
        if len(avg_rewards) >= 2:
            reward_trend = float(np.polyfit(range(len(avg_rewards)), avg_rewards, 1)[0])

        analysis: Dict[str, float] = { # Type hint
            'avg_loss': float(np.mean(losses)) if losses else 0.0,
            'loss_trend': loss_trend,
            'avg_reward': float(np.mean(avg_rewards)) if avg_rewards else 0.0,
            'reward_trend': reward_trend,
            'loss_stability': float(np.std(losses)) if losses else 0.0,
            'reward_stability': float(np.std(avg_rewards)) if avg_rewards else 0.0
        }

        return analysis

def create_performance_monitor(output_dir: Optional[str] = None) -> AdvancedPerformanceMonitor: # Type hint
    """åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨çš„å·¥å‚å‡½æ•°"""
    return AdvancedPerformanceMonitor(output_dir)

def monitor_advanced_stage_training(curriculum_manager: Any, performance_history: List[Dict[str, Any]]): # Type hints
    """ç›‘æ§é«˜éš¾åº¦é˜¶æ®µçš„è®­ç»ƒçŠ¶å†µ"""

    # Assuming curriculum_manager has 'current_stage' attribute
    if not hasattr(curriculum_manager, 'current_stage') or curriculum_manager.current_stage != 3:  # åªç›‘æ§æœ€é«˜éš¾åº¦é˜¶æ®µ (example stage)
        return

    recent_performance = performance_history[-20:] if len(performance_history) >= 20 else performance_history

    if not recent_performance:
        return

    # Assuming 'performance' key exists in performance_history dicts
    performances = [float(p.get('performance', 0.0)) for p in recent_performance] # Ensure float and provide default

    avg_performance = float(np.mean(performances)) if performances else 0.0
    performance_trend = 0.0
    if len(performances) >= 2:
        performance_trend = float(np.polyfit(range(len(performances)), performances, 1)[0])  # çº¿æ€§è¶‹åŠ¿

    logger.info(f"""
    ğŸ¯ é«˜éš¾åº¦é˜¶æ®µæ€§èƒ½åˆ†æ:
    - å¹³å‡æ€§èƒ½: {avg_performance:.4f}
    - æ€§èƒ½è¶‹åŠ¿: {'ä¸Šå‡' if performance_trend > 0.0001 else ('ä¸‹é™' if performance_trend < -0.0001 else 'å¹³ç¨³')} ({performance_trend:.6f}/æ­¥)
    - æœ€è¿‘æ€§èƒ½: {performances[-1]:.4f} if performances else N/A
    - æ€§èƒ½æ³¢åŠ¨: {float(np.std(performances)):.4f} if performances else 0.0
    """)

    # ç»™å‡ºå»ºè®® (example thresholds)
    if avg_performance > 0.95 and performance_trend > 0:
        logger.info("ğŸ’¡ å»ºè®®: æ¨¡å‹åœ¨é«˜éš¾åº¦é˜¶æ®µè¡¨ç°ä¼˜ç§€ï¼Œå¯ä»¥è€ƒè™‘å¢åŠ æ•°æ®é›†éš¾åº¦æˆ–å»¶é•¿è®­ç»ƒ")
    elif avg_performance < 0.85:
        logger.info("ğŸ’¡ å»ºè®®: é«˜éš¾åº¦é˜¶æ®µæ€§èƒ½åä½ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ ç‡æˆ–å¢åŠ è®­ç»ƒæ­¥æ•°")
    elif performances and float(np.std(performances)) > 0.1:
        logger.info("ğŸ’¡ å»ºè®®: æ€§èƒ½æ³¢åŠ¨è¾ƒå¤§ï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡æˆ–å¢åŠ batch size")
