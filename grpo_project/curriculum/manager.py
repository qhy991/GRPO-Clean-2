import logging
import numpy as np
from typing import List, Dict, Any, Tuple, Optional
from datasets import Dataset
from datetime import datetime
import json
import os
try:
    from grpo_project.configs import ScriptConfig
    from .stages import CurriculumStageConfig, create_default_curriculum_stages, create_custom_curriculum_stages
except ImportError:
    logger_init = logging.getLogger(__name__)
    logger_init.warning("Could not import from grpo_project.configs or .stages. Using placeholders for ScriptConfig/CurriculumStageConfig.")
    class ScriptConfig: pass # type: ignore
    class CurriculumStageConfig: pass # type: ignore
    def create_default_curriculum_stages() -> List[Any]: return []
    def create_custom_curriculum_stages(*args, **kwargs) -> List[Any]: return []


logger = logging.getLogger(__name__)

class EnhancedCurriculumManager:
    """å¢å¼ºçš„åŒå±‚è¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨ (from enhanced_curriculum.py)"""

    def __init__(self, curriculum_stages: List[CurriculumStageConfig], dataset: Dataset):
        self.stage_progression_configs = {
            0: {"performance_threshold": 0.7, "min_evaluations": 8, "stability_window": 4},
            1: {"performance_threshold": 0.65, "min_evaluations": 10, "stability_window": 5},
            2: {"performance_threshold": 0.6, "min_evaluations": 15, "stability_window": 6},
            3: {"performance_threshold": 0.55, "min_evaluations": 20, "stability_window": 8, "max_stay_steps": 200}
        }
        self.curriculum_stages = curriculum_stages
        self.full_dataset = dataset
        self.current_stage = 0
        self.stage_performance_history: List[Dict[str, Any]] = [] # More specific type
        self.stage_statistics: List[Dict[str, Any]] = []
        self.stage_start_steps: Dict[int, int] = {} # To track steps per stage

        self._analyze_dataset_distribution()
        self._validate_curriculum_design()

        logger.info(f"EnhancedCurriculumManager initialized with {len(curriculum_stages)} stages")
        # ... (rest of init logging)

    def should_advance_to_next_stage(self, current_loss: float, training_step: int) -> bool:
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager.should_advance_to_next_stage)
        # This method uses self.stage_progression_configs, self.curriculum_stages, self.current_stage,
        # self.stage_performance_history, self.stage_start_steps
        # For brevity, the full logic is not pasted here again but should be moved.
        logger.debug(f"Placeholder should_advance_to_next_stage called with loss {current_loss} at step {training_step}")
        if self.current_stage >= len(self.curriculum_stages) -1: return False
        # Simplified logic for stub:
        if len(self.stage_performance_history) > self.curriculum_stages[self.current_stage].min_evaluations:
            if np.mean([p['performance'] for p in self.stage_performance_history[-3:]]) > self.curriculum_stages[self.current_stage].performance_threshold:
                return True
        return False


    def get_curriculum_state(self) -> Dict[str, Any]:
        return {
            "current_stage": self.current_stage,
            "stage_performance_history": self.stage_performance_history,
            "stage_start_steps": self.stage_start_steps,
            "stage_statistics": self.stage_statistics
        }

    def load_curriculum_state(self, state_dict: Dict[str, Any]):
        self.current_stage = state_dict.get("current_stage", 0)
        self.stage_performance_history = state_dict.get("stage_performance_history", [])
        self.stage_start_steps = state_dict.get("stage_start_steps", {})
        self.stage_statistics = state_dict.get("stage_statistics", [])
        logger.info(f"EnhancedCurriculumManager state loaded. Current stage: {self.current_stage}")

    def get_current_stage_name(self) -> str:
        """Get the name of the current curriculum stage"""
        if self.current_stage >= len(self.curriculum_stages):
            return "completed"
        return self.curriculum_stages[self.current_stage].name


    def advance_stage(self) -> bool:
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager.advance_stage)
        if self.current_stage < len(self.curriculum_stages) - 1:
            self.current_stage += 1
            self.stage_performance_history = []
            logger.info(f"Advanced to curriculum stage {self.current_stage}")
            return True
        return False


# Moved from curriculum_debug_config.py
class FixedEnhancedCurriculumManager:
    """ä¿®å¤ç‰ˆæœ¬çš„å¢å¼ºè¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨ - å¢å¼ºè°ƒè¯•æ—¥å¿—"""
    
    def __init__(self, curriculum_stages: List[CurriculumStageConfig], dataset: Dataset):
        self.curriculum_stages = curriculum_stages
        self.full_dataset = dataset
        self.current_stage = 0
        self.stage_performance_history = []
        self.all_stage_history = []
        self.stage_statistics = []
        self.debug_log = []
        
        # ğŸ”§ å¢å¼ºï¼šæ·»åŠ æ›´å¤šè°ƒè¯•ä¿¡æ¯
        self.last_advancement_check_step = 0
        self.total_advancement_checks = 0
        self.advancement_attempts = 0
        self.successful_advancements = 0
        
        self._log_debug("ğŸš€ FixedEnhancedCurriculumManager å¼€å§‹åˆå§‹åŒ–")
        self._log_debug(f"ğŸ“Š è¯¾ç¨‹é…ç½®: æ€»é˜¶æ®µæ•°={len(curriculum_stages)}, æ•°æ®é›†å¤§å°={len(dataset)}")
        
        # è¯¦ç»†è®°å½•æ¯ä¸ªé˜¶æ®µçš„é…ç½®
        for i, stage in enumerate(curriculum_stages):
            self._log_debug(f"  é˜¶æ®µ{i} ({stage.name}):")
            self._log_debug(f"    - ç­‰çº§: {stage.dataset_levels}")
            self._log_debug(f"    - å¤æ‚åº¦: {stage.complexity_range}")
            self._log_debug(f"    - æ€§èƒ½é˜ˆå€¼: {stage.performance_threshold}")
            self._log_debug(f"    - æœ€å°è¯„ä¼°: {stage.min_evaluations}")
        
        self._analyze_dataset_distribution()
        self._validate_curriculum_design()
        
        # éªŒè¯å½“å‰é˜¶æ®µæ•°æ®é›†
        current_dataset = self.get_current_stage_dataset()
        self._log_debug(f"âœ… åˆå§‹åŒ–å®Œæˆ: å½“å‰é˜¶æ®µæ•°æ®é›†å¤§å°={len(current_dataset)}")
    def _validate_curriculum_design(self):
        """éªŒè¯è¯¾ç¨‹è®¾è®¡çš„åˆç†æ€§"""
        available_levels = set(self.dataset_distribution['level_counts'].keys())
        covered_levels = set()
        
        for stage in self.curriculum_stages:
            covered_levels.update([level.lower() for level in stage.dataset_levels])
        
        uncovered_levels = available_levels - covered_levels
        if uncovered_levels:
            self._log_debug(f"âš ï¸ æœªè¦†ç›–çš„æ•°æ®é›†ç­‰çº§: {uncovered_levels}")
        
        total_ratio = sum(stage.epochs_ratio for stage in self.curriculum_stages)
        if abs(total_ratio - 1.0) > 0.01:
            self._log_debug(f"âš ï¸ Epochæ¯”ä¾‹æ€»å’Œ: {total_ratio:.3f} (åº”è¯¥æ¥è¿‘1.0)")
    def _log_debug(self, message: str):
        """è®°å½•è°ƒè¯•ä¿¡æ¯ - å¢å¼ºç‰ˆæœ¬"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        debug_entry = f"[{timestamp}] {message}"
        self.debug_log.append(debug_entry)
        
        # ğŸ”§ ç¡®ä¿è°ƒè¯•ä¿¡æ¯è¾“å‡ºåˆ°æ­£ç¡®çš„ logger
        logger.info(f"ğŸ“š CURRICULUM (Fixed): {message}")
        
        # ğŸ”§ é¢å¤–ï¼šæ¯100æ¡è°ƒè¯•æ—¥å¿—è¾“å‡ºä¸€æ¬¡ç»Ÿè®¡
        if len(self.debug_log) % 100 == 0:
            logger.info(f"ğŸ“Š è¯¾ç¨‹è°ƒè¯•ç»Ÿè®¡: {len(self.debug_log)} æ¡æ—¥å¿—, å½“å‰é˜¶æ®µ={self.current_stage}")
    def _analyze_dataset_distribution(self):
        """åˆ†ææ•°æ®é›†çš„ç­‰çº§å’Œå¤æ‚åº¦åˆ†å¸ƒ"""
        if len(self.full_dataset) == 0:
            self._log_debug("âŒ ç©ºæ•°æ®é›†")
            return
        
        level_counts = {}
        complexity_by_level = {}
        
        for example in self.full_dataset:
            level = example.get('level', 'unknown').lower()
            complexity = example.get('complexity_score', 5.0)
            
            level_counts[level] = level_counts.get(level, 0) + 1
            
            if level not in complexity_by_level:
                complexity_by_level[level] = []
            complexity_by_level[level].append(complexity)
        
        self.dataset_distribution = {
            'level_counts': level_counts,
            'complexity_by_level': complexity_by_level,
            'total_samples': len(self.full_dataset)
        }
        
        # è¯¦ç»†è®°å½•åˆ†å¸ƒä¿¡æ¯
        self._log_debug(f"æ•°æ®é›†åˆ†å¸ƒåˆ†æ - æ€»æ ·æœ¬: {len(self.full_dataset)}")
        for level, count in level_counts.items():
            if level in complexity_by_level and complexity_by_level[level]:
                avg_complexity = np.mean(complexity_by_level[level])
                complexity_range = (np.min(complexity_by_level[level]), np.max(complexity_by_level[level]))
                self._log_debug(f"  {level}: {count}æ ·æœ¬, å¹³å‡å¤æ‚åº¦: {avg_complexity:.2f}, èŒƒå›´: {complexity_range}")
    def should_advance_stage(self, recent_performance: float) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ - å¢å¼ºè°ƒè¯•ç‰ˆæœ¬"""
        self.total_advancement_checks += 1
        current_step = self.total_advancement_checks  # ç®€å•çš„æ­¥æ•°è®¡æ•°
        
        self._log_debug(f"ğŸ” ç¬¬{self.total_advancement_checks}æ¬¡è¿›é˜¶æ£€æŸ¥")
        self._log_debug(f"  - å½“å‰æ€§èƒ½: {recent_performance:.4f}")
        self._log_debug(f"  - å½“å‰é˜¶æ®µ: {self.current_stage}")
        self._log_debug(f"  - å†å²é•¿åº¦: {len(self.stage_performance_history)}")
        
        if self.current_stage >= len(self.curriculum_stages) - 1:
            self._log_debug("âŒ å·²åœ¨æœ€åé˜¶æ®µï¼Œä¸èƒ½ç»§ç»­è¿›é˜¶")
            return False
        
        stage = self.curriculum_stages[self.current_stage]
        self.stage_performance_history.append(recent_performance)
        
        self._log_debug(f"  - æ€§èƒ½å·²è®°å½•ï¼Œæ–°å†å²é•¿åº¦: {len(self.stage_performance_history)}")
        self._log_debug(f"  - é˜¶æ®µé…ç½®: {stage.name}, é˜ˆå€¼={stage.performance_threshold}, æœ€å°è¯„ä¼°={stage.min_evaluations}")
        
        # éœ€è¦è¶³å¤Ÿçš„è¯„ä¼°æ¬¡æ•°
        if len(self.stage_performance_history) < stage.min_evaluations:
            self._log_debug(f"âŒ è¯„ä¼°æ¬¡æ•°ä¸è¶³: {len(self.stage_performance_history)}/{stage.min_evaluations}")
            return False
        
        # æ£€æŸ¥æœ€è¿‘çš„æ€§èƒ½è¡¨ç°
        recent_window = min(3, len(self.stage_performance_history))
        recent_performances = self.stage_performance_history[-recent_window:]
        recent_avg = np.mean(recent_performances)
        
        self._log_debug(f"  - æœ€è¿‘{recent_window}æ¬¡æ€§èƒ½: {recent_performances}")
        self._log_debug(f"  - æœ€è¿‘å¹³å‡æ€§èƒ½: {recent_avg:.4f}")
        self._log_debug(f"  - æ€§èƒ½é˜ˆå€¼: {stage.performance_threshold}")
        
        should_advance = recent_avg >= stage.performance_threshold
        
        # ğŸ”§ è¯¦ç»†è®°å½•å†³ç­–è¿‡ç¨‹
        if should_advance:
            self._log_debug(f"âœ… æ»¡è¶³è¿›é˜¶æ¡ä»¶!")
            self._log_debug(f"  - æ€§èƒ½æ£€æŸ¥: {recent_avg:.4f} >= {stage.performance_threshold} âœ…")
            self._log_debug(f"  - è¯„ä¼°æ£€æŸ¥: {len(self.stage_performance_history)} >= {stage.min_evaluations} âœ…")
        else:
            self._log_debug(f"âŒ ä¸æ»¡è¶³è¿›é˜¶æ¡ä»¶")
            if recent_avg < stage.performance_threshold:
                self._log_debug(f"  - æ€§èƒ½ä¸è¶³: {recent_avg:.4f} < {stage.performance_threshold}")
            
        self._log_debug(f"  - è¿›é˜¶å†³ç­–: {should_advance}")
        return should_advance

    def advance_stage(self) -> bool:
        """è¿›å…¥ä¸‹ä¸€é˜¶æ®µ - å¢å¼ºè°ƒè¯•ç‰ˆæœ¬"""
        self.advancement_attempts += 1
        
        self._log_debug(f"ğŸ¯ ç¬¬{self.advancement_attempts}æ¬¡è¿›é˜¶å°è¯•")
        
        if self.current_stage >= len(self.curriculum_stages) - 1:
            self._log_debug("âŒ å·²åœ¨æœ€åé˜¶æ®µï¼Œæ— æ³•è¿›é˜¶")
            return False
        
        # è®°å½•å½“å‰é˜¶æ®µçš„æœ€ç»ˆç»Ÿè®¡
        old_stage = self.current_stage
        old_stage_name = self.curriculum_stages[old_stage].name
        
        # ğŸ”§ è¯¦ç»†è®°å½•è¿›é˜¶å‰çš„çŠ¶æ€
        self._log_debug(f"ğŸ“Š è¿›é˜¶å‰çŠ¶æ€ç»Ÿè®¡:")
        self._log_debug(f"  - ç¦»å¼€é˜¶æ®µ: {old_stage} ({old_stage_name})")
        self._log_debug(f"  - è¯¥é˜¶æ®µè¯„ä¼°æ¬¡æ•°: {len(self.stage_performance_history)}")
        
        if self.stage_performance_history:
            final_performance = self.stage_performance_history[-1]
            avg_performance = np.mean(self.stage_performance_history)
            best_performance = np.max(self.stage_performance_history)
            worst_performance = np.min(self.stage_performance_history)
            
            self._log_debug(f"  - æœ€ç»ˆæ€§èƒ½: {final_performance:.4f}")
            self._log_debug(f"  - å¹³å‡æ€§èƒ½: {avg_performance:.4f}")
            self._log_debug(f"  - æœ€ä½³æ€§èƒ½: {best_performance:.4f}")
            self._log_debug(f"  - æœ€å·®æ€§èƒ½: {worst_performance:.4f}")
        
        final_stats = {
            'completed_stage': old_stage,
            'stage_name': old_stage_name,
            'total_evaluations': len(self.stage_performance_history),
            'final_performance': self.stage_performance_history[-1] if self.stage_performance_history else 0,
            'average_performance': np.mean(self.stage_performance_history) if self.stage_performance_history else 0,
            'performance_history': self.stage_performance_history.copy(),
            'completion_timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜åˆ°å…¨éƒ¨å†å²
        self.all_stage_history.append(final_stats)
        
        # è¿›é˜¶åˆ°ä¸‹ä¸€é˜¶æ®µ
        self.current_stage += 1
        self.stage_performance_history = []  # é‡ç½®æ€§èƒ½å†å²
        
        new_stage_name = self.curriculum_stages[self.current_stage].name if self.current_stage < len(self.curriculum_stages) else "Final"
        
        self.successful_advancements += 1
        
        self._log_debug(f"ğŸ‰ æˆåŠŸè¿›é˜¶!")
        self._log_debug(f"  - è¿›é˜¶è·¯å¾„: {old_stage}({old_stage_name}) -> {self.current_stage}({new_stage_name})")
        self._log_debug(f"  - æˆåŠŸè¿›é˜¶æ¬¡æ•°: {self.successful_advancements}/{self.advancement_attempts}")
        self._log_debug(f"  - å‰é˜¶æ®µæœ€ç»ˆæ€§èƒ½: {final_stats['final_performance']:.4f}")
        
        # ğŸ”§ è¯¦ç»†è®°å½•æ–°é˜¶æ®µä¿¡æ¯
        if self.current_stage < len(self.curriculum_stages):
            new_stage = self.curriculum_stages[self.current_stage]
            new_dataset = self.get_current_stage_dataset()
            
            self._log_debug(f"ğŸ“ˆ æ–°é˜¶æ®µè¯¦æƒ…:")
            self._log_debug(f"  - é˜¶æ®µåç§°: {new_stage.name}")
            self._log_debug(f"  - ç›®æ ‡ç­‰çº§: {new_stage.dataset_levels}")
            self._log_debug(f"  - å¤æ‚åº¦èŒƒå›´: {new_stage.complexity_range}")
            self._log_debug(f"  - æ€§èƒ½é˜ˆå€¼: {new_stage.performance_threshold}")
            self._log_debug(f"  - æ•°æ®é›†å¤§å°: {len(new_dataset)}")
            self._log_debug(f"  - æ•°æ®é›†æ¯”ä¾‹: {len(new_dataset)/len(self.full_dataset)*100:.1f}%")
        else:
            self._log_debug("ğŸ“ æ‰€æœ‰é˜¶æ®µå·²å®Œæˆ!")
        
        return True

    def get_current_stage_dataset(self) -> Dataset:
        """è·å–å½“å‰é˜¶æ®µçš„æ•°æ®é›† - å¢å¼ºè°ƒè¯•ç‰ˆæœ¬"""
        if self.current_stage >= len(self.curriculum_stages):
            self._log_debug("âœ… è¯¾ç¨‹å­¦ä¹ å®Œæˆï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®é›†")
            return self.full_dataset
        
        stage = self.curriculum_stages[self.current_stage]
        
        # ğŸ”§ è¯¦ç»†çš„è¿‡æ»¤è¿‡ç¨‹æ—¥å¿—
        self._log_debug(f"ğŸ” å¼€å§‹è¿‡æ»¤é˜¶æ®µ{self.current_stage}æ•°æ®é›†")
        self._log_debug(f"  - é˜¶æ®µåç§°: {stage.name}")
        self._log_debug(f"  - ç›®æ ‡ç­‰çº§: {stage.dataset_levels}")
        self._log_debug(f"  - å¤æ‚åº¦èŒƒå›´: {stage.complexity_range}")
        self._log_debug(f"  - åŸå§‹æ•°æ®é›†å¤§å°: {len(self.full_dataset)}")
        
        # åŒå±‚è¿‡æ»¤ï¼šæ•°æ®é›†ç­‰çº§ + å¤æ‚åº¦èŒƒå›´
        filtered_indices = []
        level_filter_count = 0
        complexity_filter_count = 0
        
        # ğŸ”§ æŒ‰ç­‰çº§åˆ†ç±»ç»Ÿè®¡
        level_stats = {}
        complexity_stats = {}
        
        for i, example in enumerate(self.full_dataset):
            # ç¬¬ä¸€å±‚è¿‡æ»¤ï¼šæ•°æ®é›†ç­‰çº§
            example_level = example.get('level', 'unknown').lower()
            level_stats[example_level] = level_stats.get(example_level, 0) + 1
            
            if example_level not in [level.lower() for level in stage.dataset_levels]:
                continue
            level_filter_count += 1
            
            # ç¬¬äºŒå±‚è¿‡æ»¤ï¼šå¤æ‚åº¦èŒƒå›´
            complexity = example.get('complexity_score', 5.0)
            complexity_key = f"{int(complexity)}-{int(complexity)+1}"
            complexity_stats[complexity_key] = complexity_stats.get(complexity_key, 0) + 1
            
            min_complexity, max_complexity = stage.complexity_range
            if not (min_complexity <= complexity <= max_complexity):
                continue
            complexity_filter_count += 1
            
            filtered_indices.append(i)
        
        # ğŸ”§ è¯¦ç»†çš„è¿‡æ»¤ç»Ÿè®¡æ—¥å¿—
        self._log_debug(f"ğŸ“Š è¿‡æ»¤ç»Ÿè®¡:")
        self._log_debug(f"  - åŸå§‹æ•°æ®: {len(self.full_dataset)} æ ·æœ¬")
        self._log_debug(f"  - ç­‰çº§è¿‡æ»¤é€šè¿‡: {level_filter_count} æ ·æœ¬")
        self._log_debug(f"  - å¤æ‚åº¦è¿‡æ»¤é€šè¿‡: {complexity_filter_count} æ ·æœ¬")
        self._log_debug(f"  - æœ€ç»ˆé€‰æ‹©: {len(filtered_indices)} æ ·æœ¬")
        
        # ğŸ”§ ç­‰çº§åˆ†å¸ƒç»Ÿè®¡
        self._log_debug(f"ğŸ“ˆ æ•°æ®é›†ç­‰çº§åˆ†å¸ƒ:")
        for level, count in sorted(level_stats.items()):
            is_target = level in [l.lower() for l in stage.dataset_levels]
            marker = "âœ…" if is_target else "âŒ"
            self._log_debug(f"    {marker} {level}: {count} æ ·æœ¬ ({count/len(self.full_dataset)*100:.1f}%)")
        
        # ğŸ”§ å¤æ‚åº¦åˆ†å¸ƒç»Ÿè®¡
        self._log_debug(f"ğŸ“ˆ å¤æ‚åº¦åˆ†å¸ƒç»Ÿè®¡:")
        min_c, max_c = stage.complexity_range
        for comp_range, count in sorted(complexity_stats.items()):
            range_start = int(comp_range.split('-')[0])
            is_in_range = min_c <= range_start <= max_c
            marker = "âœ…" if is_in_range else "âŒ"
            self._log_debug(f"    {marker} {comp_range}: {count} æ ·æœ¬")
        
        if not filtered_indices:
            self._log_debug(f"âŒ é˜¶æ®µ{self.current_stage}æ²¡æœ‰åŒ¹é…çš„æ ·æœ¬ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®é›†")
            self._log_debug("âš ï¸ è¿™å¯èƒ½è¡¨æ˜è¯¾ç¨‹é…ç½®æœ‰é—®é¢˜!")
            return self.full_dataset
        
        stage_dataset = self.full_dataset.select(filtered_indices)
        
        # è®°å½•è¯¦ç»†ç»Ÿè®¡
        stage_stats = {
            'stage_index': self.current_stage,
            'stage_name': stage.name,
            'total_examples': len(self.full_dataset),
            'level_filtered': level_filter_count,
            'complexity_filtered': complexity_filter_count,
            'final_selected': len(stage_dataset),
            'selection_ratio': len(stage_dataset) / len(self.full_dataset),
            'target_levels': stage.dataset_levels,
            'complexity_range': stage.complexity_range,
            'level_distribution': level_stats,
            'complexity_distribution': complexity_stats
        }
        self.stage_statistics.append(stage_stats)
        
        self._log_debug(f"âœ… é˜¶æ®µ{self.current_stage}æ•°æ®é›†è¿‡æ»¤å®Œæˆ")
        self._log_debug(f"  - é€‰æ‹©æ¯”ä¾‹: {stage_stats['selection_ratio']:.1%}")
        self._log_debug(f"  - è¿‡æ»¤æ•ˆç‡: ç­‰çº§{level_filter_count/len(self.full_dataset)*100:.1f}% -> å¤æ‚åº¦{complexity_filter_count/level_filter_count*100:.1f}%")
        
        return stage_dataset

    def get_current_stage_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰é˜¶æ®µä¿¡æ¯ - å¢å¼ºè°ƒè¯•ç‰ˆæœ¬"""
        if self.current_stage >= len(self.curriculum_stages):
            return {
                'stage_index': self.current_stage,
                'stage_name': 'completed',
                'dataset_levels': 'all',
                'complexity_range': 'all',
                'is_completed': True,
                'debug_log_recent': self.debug_log[-10:],
                'advancement_stats': {
                    'total_checks': self.total_advancement_checks,
                    'attempts': self.advancement_attempts,
                    'successful': self.successful_advancements
                }
            }
        
        stage = self.curriculum_stages[self.current_stage]
        current_dataset = self.get_current_stage_dataset()
        
        return {
            'stage_index': self.current_stage,
            'stage_name': stage.name,
            'dataset_levels': stage.dataset_levels,
            'complexity_range': stage.complexity_range,
            'epochs_ratio': stage.epochs_ratio,
            'performance_threshold': stage.performance_threshold,
            'current_evaluations': len(self.stage_performance_history),
            'min_evaluations': stage.min_evaluations,
            'dataset_size': len(current_dataset),
            'dataset_ratio': len(current_dataset) / len(self.full_dataset) if len(self.full_dataset) > 0 else 0,
            'is_completed': False,
            'debug_log_recent': self.debug_log[-10:],
            'advancement_stats': {
                'total_checks': self.total_advancement_checks,
                'attempts': self.advancement_attempts,
                'successful': self.successful_advancements
            }
        }

    def log_to_wandb(self, step: int):
        """è®°å½•åˆ°W&Bï¼ˆä½¿ç”¨æ•°å€¼è€Œéæ–‡å­—ï¼‰- å¢å¼ºè°ƒè¯•ç‰ˆæœ¬"""
        try:
            import wandb
            if not hasattr(wandb, 'run') or wandb.run is None:
                return
            
            current_info = self.get_current_stage_info()
            progress_info = self.get_curriculum_progress()
            
            # ğŸ”§ å¢å¼ºçš„W&Bæ•°æ®
            wandb_data = {
                'curriculum/current_stage_index': current_info['stage_index'],
                'curriculum/total_stages': progress_info['total_stages'],
                'curriculum/progress_ratio': progress_info['progress_ratio'],
                'curriculum/completed_stages_count': progress_info['completed_stages'],
                'curriculum/is_completed': float(current_info['is_completed']),
                'curriculum/debug_log_count': len(self.debug_log),
                'curriculum/advancement_checks': self.total_advancement_checks,
                'curriculum/advancement_attempts': self.advancement_attempts,
                'curriculum/successful_advancements': self.successful_advancements
            }
            
            # å½“å‰é˜¶æ®µè¯¦ç»†ä¿¡æ¯ï¼ˆæ•°å€¼ï¼‰
            if not current_info['is_completed']:
                wandb_data.update({
                    'curriculum/current_evaluations': current_info['current_evaluations'],
                    'curriculum/min_evaluations': current_info['min_evaluations'],
                    'curriculum/performance_threshold': current_info['performance_threshold'],
                    'curriculum/epochs_ratio': current_info['epochs_ratio'],
                    'curriculum/level_count': len(current_info['dataset_levels']),
                    'curriculum/complexity_min': current_info['complexity_range'][0],
                    'curriculum/complexity_max': current_info['complexity_range'][1],
                    'curriculum/dataset_size': current_info['dataset_size'],
                    'curriculum/dataset_ratio': current_info['dataset_ratio']
                })
            
            # æ€§èƒ½å†å²ç»Ÿè®¡
            if self.stage_performance_history:
                wandb_data.update({
                    'curriculum/stage_performance_mean': np.mean(self.stage_performance_history),
                    'curriculum/stage_performance_latest': self.stage_performance_history[-1],
                    'curriculum/stage_performance_std': np.std(self.stage_performance_history),
                    'curriculum/stage_performance_min': np.min(self.stage_performance_history),
                    'curriculum/stage_performance_max': np.max(self.stage_performance_history),
                    'curriculum/stage_performance_trend': np.mean(self.stage_performance_history[-3:]) if len(self.stage_performance_history) >= 3 else self.stage_performance_history[-1]
                })
            
            wandb.log(wandb_data, step=step)
            self._log_debug(f"ğŸ“Š W&BæŒ‡æ ‡å·²è®°å½• (æ­¥æ•°: {step}, æ•°æ®ç‚¹: {len(wandb_data)})")
            
        except ImportError:
            pass  # wandb not available
        except Exception as e:
            self._log_debug(f"âŒ W&Bè®°å½•å¤±è´¥: {e}")
    def get_curriculum_state(self) -> Dict[str, Any]:
        """è·å–è¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨çš„å½“å‰çŠ¶æ€ï¼Œç”¨äºä¿å­˜"""
        return {
            "current_stage": self.current_stage,
            "stage_performance_history": self.stage_performance_history,
            "all_stage_history": self.all_stage_history,
            "debug_log": self.debug_log[-50:],  # ä¿ç•™æœ€è¿‘50æ¡æ—¥å¿—
            "stage_statistics": self.stage_statistics
        }
    def get_curriculum_progress(self) -> Dict[str, Any]:
        """è·å–æ•´ä½“è¯¾ç¨‹è¿›åº¦"""
        total_stages = len(self.curriculum_stages)
        progress_ratio = (self.current_stage + 1) / total_stages if total_stages > 0 else 1.0
        
        return {
            'current_stage': self.current_stage,
            'total_stages': total_stages,
            'progress_ratio': progress_ratio,
            'completed_stages': len(self.all_stage_history),
            'stage_statistics': self.stage_statistics,
            'dataset_distribution': self.dataset_distribution,
            'all_stage_history': self.all_stage_history,
            'debug_summary': {
                'total_debug_entries': len(self.debug_log),
                'recent_entries': self.debug_log[-5:]  # æœ€è¿‘5æ¡
            }
        }
    def save_detailed_log(self, output_dir: str):
        """ä¿å­˜è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—åˆ°æ–‡ä»¶ - å¢å¼ºç‰ˆæœ¬"""
        log_file = os.path.join(output_dir, "curriculum_detailed_debug.json")
        
        detailed_data = {
            "curriculum_state": self.get_curriculum_state(),
            "progress_info": self.get_curriculum_progress(),
            "current_stage_info": self.get_current_stage_info(),
            "export_timestamp": datetime.now().isoformat(),
            "debug_summary": {
                "total_stages": len(self.curriculum_stages),
                "current_stage": self.current_stage,
                "stages_completed": len(self.all_stage_history),
                "total_debug_entries": len(self.debug_log),
                "advancement_stats": {
                    "total_checks": self.total_advancement_checks,
                    "attempts": self.advancement_attempts,
                    "successful": self.successful_advancements,
                    "success_rate": self.successful_advancements / max(1, self.advancement_attempts)
                }
            },
            "recent_debug_log": self.debug_log[-50:] if len(self.debug_log) > 50 else self.debug_log,
            "stage_statistics_detailed": self.stage_statistics
        }
        
        try:
            os.makedirs(output_dir, exist_ok=True)
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(detailed_data, f, indent=2, ensure_ascii=False)
            self._log_debug(f"ğŸ’¾ è¯¦ç»†è°ƒè¯•æ—¥å¿—å·²ä¿å­˜: {log_file}")
            
            # ğŸ”§ é¢å¤–ä¿å­˜ä¸€ä¸ªçº¯æ–‡æœ¬ç‰ˆæœ¬çš„è°ƒè¯•æ—¥å¿—
            text_log_file = os.path.join(output_dir, "curriculum_debug_text.log")
            with open(text_log_file, 'w', encoding='utf-8') as f:
                f.write(f"=== è¯¾ç¨‹å­¦ä¹ è°ƒè¯•æ—¥å¿— - {datetime.now()} ===\n\n")
                f.write(f"æ€»ä½“ç»Ÿè®¡:\n")
                f.write(f"  - å½“å‰é˜¶æ®µ: {self.current_stage}\n")
                f.write(f"  - è¿›é˜¶æ£€æŸ¥æ¬¡æ•°: {self.total_advancement_checks}\n")
                f.write(f"  - è¿›é˜¶å°è¯•æ¬¡æ•°: {self.advancement_attempts}\n")
                f.write(f"  - æˆåŠŸè¿›é˜¶æ¬¡æ•°: {self.successful_advancements}\n")
                f.write(f"  - è°ƒè¯•æ—¥å¿—æ¡æ•°: {len(self.debug_log)}\n\n")
                
                f.write("è¯¦ç»†è°ƒè¯•æ—¥å¿—:\n")
                f.write("="*50 + "\n")
                for entry in self.debug_log:
                    f.write(entry + "\n")
            
            self._log_debug(f"ğŸ“ æ–‡æœ¬è°ƒè¯•æ—¥å¿—å·²ä¿å­˜: {text_log_file}")
            
        except Exception as e:
            self._log_debug(f"âŒ ä¿å­˜è°ƒè¯•æ—¥å¿—å¤±è´¥: {e}")

    # ğŸ”§ æ–°å¢ï¼šå®šæœŸçŠ¶æ€æŠ¥å‘Šæ–¹æ³•
    def log_periodic_status(self, step: int = None):
        """å®šæœŸè®°å½•è¯¾ç¨‹å­¦ä¹ çŠ¶æ€"""
        self._log_debug(f"ğŸ“Š å®šæœŸçŠ¶æ€æŠ¥å‘Š (æ­¥æ•°: {step if step else 'N/A'})")
        
        current_info = self.get_current_stage_info()
        
        self._log_debug(f"  - å½“å‰é˜¶æ®µ: {current_info['stage_index']} ({current_info['stage_name']})")
        if not current_info['is_completed']:
            self._log_debug(f"  - æ•°æ®é›†: {current_info['dataset_size']} æ ·æœ¬ ({current_info['dataset_ratio']:.1%})")
            self._log_debug(f"  - è¯„ä¼°è¿›åº¦: {current_info['current_evaluations']}/{current_info['min_evaluations']}")
            self._log_debug(f"  - æ€§èƒ½é˜ˆå€¼: {current_info['performance_threshold']}")
        
        self._log_debug(f"  - è¿›é˜¶ç»Ÿè®¡: {self.successful_advancements}/{self.advancement_attempts} æˆåŠŸ")
        
        if self.stage_performance_history:
            recent_perf = self.stage_performance_history[-min(3, len(self.stage_performance_history)):]
            self._log_debug(f"  - æœ€è¿‘æ€§èƒ½: {[f'{p:.3f}' for p in recent_perf]}")

    # ğŸ”§ æ–°å¢ï¼šå¼ºåˆ¶è°ƒè¯•è¾“å‡ºæ–¹æ³•
    def force_debug_output(self):
        """å¼ºåˆ¶è¾“å‡ºå½“å‰æ‰€æœ‰è°ƒè¯•ä¿¡æ¯"""
        self._log_debug("ğŸ”§ å¼ºåˆ¶è°ƒè¯•è¾“å‡ºå¼€å§‹")
        self._log_debug(f"ğŸ“Š è°ƒè¯•ç»Ÿè®¡: {len(self.debug_log)} æ¡æ—¥å¿—")
        
        # è¾“å‡ºæœ€è¿‘çš„è°ƒè¯•æ—¥å¿—
        recent_logs = self.debug_log[-20:] if len(self.debug_log) > 20 else self.debug_log
        self._log_debug(f"ğŸ“ æœ€è¿‘{len(recent_logs)}æ¡è°ƒè¯•æ—¥å¿—:")
        for i, entry in enumerate(recent_logs, 1):
            self._log_debug(f"  {i:2d}. {entry}")
        
        # è¾“å‡ºå½“å‰çŠ¶æ€
        self.log_periodic_status()
        
        self._log_debug("ğŸ”§ å¼ºåˆ¶è°ƒè¯•è¾“å‡ºç»“æŸ")


# Moved from train.py (setup_curriculum_manager)
# This function sets up EnhancedCurriculumManager, not FixedEnhancedCurriculumManager.
# We might need to reconcile this with setup_fixed_curriculum_manager.
def setup_enhanced_curriculum_manager(script_cfg: ScriptConfig, dataset: Dataset) -> Optional[EnhancedCurriculumManager]:
    if not script_cfg.enable_curriculum: # type: ignore
        logger.info("Curriculum learning disabled via script_cfg.")
        return None
    # ... (Logic from train.py setup_curriculum_manager, using create_custom_curriculum_stages or create_default_curriculum_stages)
    # This logic needs access to create_custom_curriculum_stages and create_default_curriculum_stages from .stages
    logger.info("Setting up EnhancedCurriculumManager...")
    # Placeholder logic:
    stages = create_default_curriculum_stages() # from .stages
    return EnhancedCurriculumManager(stages, dataset)


# Moved from curriculum_debug_config.py
def setup_fixed_curriculum_manager(script_cfg: ScriptConfig, dataset: Dataset) -> Optional[FixedEnhancedCurriculumManager]:
    if not script_cfg.enable_curriculum: # type: ignore
        logger.info("ğŸ“š Curriculum learning (fixed manager) is disabled.")
        return None
    # ... (Logic from curriculum_debug_config.py setup_fixed_curriculum_manager)
    # This logic needs access to create_fixed_curriculum_stages (if that's also moved/created) or other stage creation logic
    logger.info("Setting up FixedEnhancedCurriculumManager...")
    # Placeholder logic:
    # stages = create_fixed_curriculum_stages() # This function would also need to be defined/moved
    stages = create_default_curriculum_stages() # Using default for now as create_fixed_curriculum_stages is not in scope
    return FixedEnhancedCurriculumManager(stages, dataset)
