import logging
import numpy as np
from typing import List, Dict, Any, Tuple, Optional
from datasets import Dataset
from datetime import datetime
import json
import os
try:
    from grpo_project.configs import ScriptConfig
    from .stages import CurriculumStageConfig, create_default_curriculum_stages, create_custom_curriculum_stages
except ImportError:
    logger_init = logging.getLogger(__name__)
    logger_init.warning("Could not import from grpo_project.configs or .stages. Using placeholders for ScriptConfig/CurriculumStageConfig.")
    class ScriptConfig: pass # type: ignore
    class CurriculumStageConfig: pass # type: ignore
    def create_default_curriculum_stages() -> List[Any]: return []
    def create_custom_curriculum_stages(*args, **kwargs) -> List[Any]: return []


logger = logging.getLogger(__name__)

class EnhancedCurriculumManager:
    """å¢å¼ºçš„åŒå±‚è¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨ (from enhanced_curriculum.py)"""

    def __init__(self, curriculum_stages: List[CurriculumStageConfig], dataset: Dataset):
        self.stage_progression_configs = {
            0: {"performance_threshold": 0.7, "min_evaluations": 8, "stability_window": 4},
            1: {"performance_threshold": 0.65, "min_evaluations": 10, "stability_window": 5},
            2: {"performance_threshold": 0.6, "min_evaluations": 15, "stability_window": 6},
            3: {"performance_threshold": 0.55, "min_evaluations": 20, "stability_window": 8, "max_stay_steps": 200}
        }
        self.curriculum_stages = curriculum_stages
        self.full_dataset = dataset
        self.current_stage = 0
        self.stage_performance_history: List[Dict[str, Any]] = [] # More specific type
        self.stage_statistics: List[Dict[str, Any]] = []
        self.stage_start_steps: Dict[int, int] = {} # To track steps per stage

        self._analyze_dataset_distribution()
        self._validate_curriculum_design()

        logger.info(f"EnhancedCurriculumManager initialized with {len(curriculum_stages)} stages")
        # ... (rest of init logging)

    def should_advance_to_next_stage(self, current_loss: float, training_step: int) -> bool:
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager.should_advance_to_next_stage)
        # This method uses self.stage_progression_configs, self.curriculum_stages, self.current_stage,
        # self.stage_performance_history, self.stage_start_steps
        # For brevity, the full logic is not pasted here again but should be moved.
        logger.debug(f"Placeholder should_advance_to_next_stage called with loss {current_loss} at step {training_step}")
        if self.current_stage >= len(self.curriculum_stages) -1: return False
        # Simplified logic for stub:
        if len(self.stage_performance_history) > self.curriculum_stages[self.current_stage].min_evaluations:
            if np.mean([p['performance'] for p in self.stage_performance_history[-3:]]) > self.curriculum_stages[self.current_stage].performance_threshold:
                return True
        return False


    def get_curriculum_state(self) -> Dict[str, Any]:
        return {
            "current_stage": self.current_stage,
            "stage_performance_history": self.stage_performance_history,
            "stage_start_steps": self.stage_start_steps,
            "stage_statistics": self.stage_statistics
        }

    def load_curriculum_state(self, state_dict: Dict[str, Any]):
        self.current_stage = state_dict.get("current_stage", 0)
        self.stage_performance_history = state_dict.get("stage_performance_history", [])
        self.stage_start_steps = state_dict.get("stage_start_steps", {})
        self.stage_statistics = state_dict.get("stage_statistics", [])
        logger.info(f"EnhancedCurriculumManager state loaded. Current stage: {self.current_stage}")

    def _analyze_dataset_distribution(self):
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager._analyze_dataset_distribution)
        pass

    def _validate_curriculum_design(self):
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager._validate_curriculum_design)
        pass

    def get_current_stage_name(self) -> str:
        """Get the name of the current curriculum stage"""
        if self.current_stage >= len(self.curriculum_stages):
            return "completed"
        return self.curriculum_stages[self.current_stage].name


    def advance_stage(self) -> bool:
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager.advance_stage)
        if self.current_stage < len(self.curriculum_stages) - 1:
            self.current_stage += 1
            self.stage_performance_history = []
            logger.info(f"Advanced to curriculum stage {self.current_stage}")
            return True
        return False

    def get_current_stage_info(self) -> Dict[str, Any]:
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager.get_current_stage_info)
        return {}

    def get_curriculum_progress(self) -> Dict[str, Any]:
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager.get_curriculum_progress)
        return {}

    def log_to_wandb(self, step: int):
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager.log_to_wandb)
        pass


# Moved from curriculum_debug_config.py
class FixedEnhancedCurriculumManager:
    """ä¿®å¤ç‰ˆæœ¬çš„å¢å¼ºè¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨"""
    
    def __init__(self, curriculum_stages: List[CurriculumStageConfig], dataset: Dataset):
        self.curriculum_stages = curriculum_stages
        self.full_dataset = dataset
        self.current_stage = 0
        self.stage_performance_history = []
        self.all_stage_history = []
        self.stage_statistics = []
        self.debug_log = []
        
        self._log_debug(f"FixedEnhancedCurriculumManager initialized - Total Stages: {len(curriculum_stages)}")
        self._analyze_dataset_distribution()
        self._validate_curriculum_design()
        
        # éªŒè¯å½“å‰é˜¶æ®µæ•°æ®é›†
        current_dataset = self.get_current_stage_dataset()
        self._log_debug(f"Current stage ({self.current_stage}) dataset size: {len(current_dataset)}")

    def _log_debug(self, message: str):
        """è®°å½•è°ƒè¯•ä¿¡æ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        debug_entry = f"[{timestamp}] {message}"
        self.debug_log.append(debug_entry)
        logger.info(f"ğŸ“š CURRICULUM (Fixed): {message}")

    def _analyze_dataset_distribution(self):
        """åˆ†ææ•°æ®é›†çš„ç­‰çº§å’Œå¤æ‚åº¦åˆ†å¸ƒ"""
        if len(self.full_dataset) == 0:
            self._log_debug("âŒ ç©ºæ•°æ®é›†")
            return
        
        level_counts = {}
        complexity_by_level = {}
        
        for example in self.full_dataset:
            level = example.get('level', 'unknown').lower()
            complexity = example.get('complexity_score', 5.0)
            
            level_counts[level] = level_counts.get(level, 0) + 1
            
            if level not in complexity_by_level:
                complexity_by_level[level] = []
            complexity_by_level[level].append(complexity)
        
        self.dataset_distribution = {
            'level_counts': level_counts,
            'complexity_by_level': complexity_by_level,
            'total_samples': len(self.full_dataset)
        }
        
        self._log_debug(f"æ•°æ®é›†åˆ†å¸ƒåˆ†æ - æ€»æ ·æœ¬: {len(self.full_dataset)}")
        for level, count in level_counts.items():
            if level in complexity_by_level and complexity_by_level[level]:
                avg_complexity = np.mean(complexity_by_level[level])
                self._log_debug(f"  {level}: {count}æ ·æœ¬, å¹³å‡å¤æ‚åº¦: {avg_complexity:.2f}")

    def _validate_curriculum_design(self):
        """éªŒè¯è¯¾ç¨‹è®¾è®¡çš„åˆç†æ€§"""
        available_levels = set(self.dataset_distribution['level_counts'].keys())
        covered_levels = set()
        
        for stage in self.curriculum_stages:
            covered_levels.update([level.lower() for level in stage.dataset_levels])
        
        uncovered_levels = available_levels - covered_levels
        if uncovered_levels:
            self._log_debug(f"âš ï¸ æœªè¦†ç›–çš„æ•°æ®é›†ç­‰çº§: {uncovered_levels}")

    def get_current_stage_dataset(self) -> Dataset:
        """è·å–å½“å‰é˜¶æ®µçš„æ•°æ®é›†"""
        if self.current_stage >= len(self.curriculum_stages):
            self._log_debug("âœ… è¯¾ç¨‹å­¦ä¹ å®Œæˆï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®é›†")
            return self.full_dataset
        
        stage = self.curriculum_stages[self.current_stage]
        
        # åŒå±‚è¿‡æ»¤ï¼šæ•°æ®é›†ç­‰çº§ + å¤æ‚åº¦èŒƒå›´
        filtered_indices = []
        level_filter_count = 0
        complexity_filter_count = 0
        
        self._log_debug(f"å¼€å§‹è¿‡æ»¤é˜¶æ®µ{self.current_stage}æ•°æ®é›† - ç›®æ ‡ç­‰çº§: {stage.dataset_levels}, å¤æ‚åº¦: {stage.complexity_range}")
        
        for i, example in enumerate(self.full_dataset):
            # ç¬¬ä¸€å±‚è¿‡æ»¤ï¼šæ•°æ®é›†ç­‰çº§
            example_level = example.get('level', 'unknown').lower()
            if example_level not in [level.lower() for level in stage.dataset_levels]:
                continue
            level_filter_count += 1
            
            # ç¬¬äºŒå±‚è¿‡æ»¤ï¼šå¤æ‚åº¦èŒƒå›´
            complexity = example.get('complexity_score', 5.0)
            min_complexity, max_complexity = stage.complexity_range
            if not (min_complexity <= complexity <= max_complexity):
                continue
            complexity_filter_count += 1
            
            filtered_indices.append(i)
        
        if not filtered_indices:
            self._log_debug(f"âŒ é˜¶æ®µ{self.current_stage}æ²¡æœ‰åŒ¹é…çš„æ ·æœ¬ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®é›†")
            return self.full_dataset
        
        stage_dataset = self.full_dataset.select(filtered_indices)
        
        # è®°å½•è¯¦ç»†ç»Ÿè®¡
        stage_stats = {
            'stage_index': self.current_stage,
            'stage_name': stage.name,
            'total_examples': len(self.full_dataset),
            'level_filtered': level_filter_count,
            'complexity_filtered': complexity_filter_count,
            'final_selected': len(stage_dataset),
            'selection_ratio': len(stage_dataset) / len(self.full_dataset),
            'target_levels': stage.dataset_levels,
            'complexity_range': stage.complexity_range
        }
        self.stage_statistics.append(stage_stats)
        
        self._log_debug(f"é˜¶æ®µ{self.current_stage}æ•°æ®é›†è¿‡æ»¤å®Œæˆ:")
        self._log_debug(f"  ç­‰çº§è¿‡æ»¤é€šè¿‡: {level_filter_count}/{len(self.full_dataset)}")
        self._log_debug(f"  å¤æ‚åº¦è¿‡æ»¤é€šè¿‡: {complexity_filter_count}/{level_filter_count}")
        self._log_debug(f"  æœ€ç»ˆé€‰æ‹©: {len(stage_dataset)}æ ·æœ¬ ({stage_stats['selection_ratio']:.1%})")
        
        return stage_dataset

    def get_current_stage_name(self) -> str:
        """Get the name of the current curriculum stage"""
        if self.current_stage >= len(self.curriculum_stages):
            return "completed"
        return self.curriculum_stages[self.current_stage].name

    def should_advance_stage(self, recent_performance: float) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ"""
        if self.current_stage >= len(self.curriculum_stages) - 1:
            self._log_debug("å·²åœ¨æœ€åé˜¶æ®µï¼Œä¸èƒ½ç»§ç»­è¿›é˜¶")
            return False
        
        stage = self.curriculum_stages[self.current_stage]
        self.stage_performance_history.append(recent_performance)
        
        self._log_debug(f"è¿›é˜¶æ£€æŸ¥ - å½“å‰æ€§èƒ½: {recent_performance:.4f}, å†å²é•¿åº¦: {len(self.stage_performance_history)}")
        
        # éœ€è¦è¶³å¤Ÿçš„è¯„ä¼°æ¬¡æ•°
        if len(self.stage_performance_history) < stage.min_evaluations:
            self._log_debug(f"è¯„ä¼°æ¬¡æ•°ä¸è¶³: {len(self.stage_performance_history)}/{stage.min_evaluations}")
            return False
        
        # æ£€æŸ¥æœ€è¿‘çš„æ€§èƒ½è¡¨ç°
        recent_window = min(3, len(self.stage_performance_history))
        recent_avg = np.mean(self.stage_performance_history[-recent_window:])
        
        should_advance = recent_avg >= stage.performance_threshold
        
        self._log_debug(f"æœ€è¿‘{recent_window}æ¬¡å¹³å‡æ€§èƒ½: {recent_avg:.4f}")
        self._log_debug(f"æ€§èƒ½é˜ˆå€¼: {stage.performance_threshold}")
        self._log_debug(f"æ˜¯å¦åº”è¯¥è¿›é˜¶: {should_advance}")
        
        return should_advance

    def advance_stage(self) -> bool:
        """è¿›å…¥ä¸‹ä¸€é˜¶æ®µ"""
        if self.current_stage >= len(self.curriculum_stages) - 1:
            self._log_debug("âŒ å·²åœ¨æœ€åé˜¶æ®µï¼Œæ— æ³•è¿›é˜¶")
            return False
        
        # è®°å½•å½“å‰é˜¶æ®µçš„æœ€ç»ˆç»Ÿè®¡
        old_stage = self.current_stage
        old_stage_name = self.curriculum_stages[old_stage].name
        
        final_stats = {
            'completed_stage': old_stage,
            'stage_name': old_stage_name,
            'total_evaluations': len(self.stage_performance_history),
            'final_performance': self.stage_performance_history[-1] if self.stage_performance_history else 0,
            'average_performance': np.mean(self.stage_performance_history) if self.stage_performance_history else 0,
            'performance_history': self.stage_performance_history.copy(),
            'completion_timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜åˆ°å…¨éƒ¨å†å²
        self.all_stage_history.append(final_stats)
        
        # è¿›é˜¶åˆ°ä¸‹ä¸€é˜¶æ®µ
        self.current_stage += 1
        self.stage_performance_history = []  # é‡ç½®æ€§èƒ½å†å²
        
        new_stage_name = self.curriculum_stages[self.current_stage].name if self.current_stage < len(self.curriculum_stages) else "Final"
        
        self._log_debug(f"ğŸ¯ æˆåŠŸè¿›é˜¶: {old_stage}({old_stage_name}) -> {self.current_stage}({new_stage_name})")
        self._log_debug(f"å‰é˜¶æ®µæœ€ç»ˆæ€§èƒ½: {final_stats['final_performance']:.4f}")
        
        # è·å–æ–°é˜¶æ®µçš„æ•°æ®é›†å¤§å°
        if self.current_stage < len(self.curriculum_stages):
            new_dataset = self.get_current_stage_dataset()
            self._log_debug(f"æ–°é˜¶æ®µæ•°æ®é›†å¤§å°: {len(new_dataset)}")
        
        return True

    def get_current_stage_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰é˜¶æ®µä¿¡æ¯"""
        if self.current_stage >= len(self.curriculum_stages):
            return {
                'stage_index': self.current_stage,
                'stage_name': 'completed',
                'dataset_levels': 'all',
                'complexity_range': 'all',
                'is_completed': True,
                'debug_log_recent': self.debug_log[-10:]
            }
        
        stage = self.curriculum_stages[self.current_stage]
        return {
            'stage_index': self.current_stage,
            'stage_name': stage.name,
            'dataset_levels': stage.dataset_levels,
            'complexity_range': stage.complexity_range,
            'epochs_ratio': stage.epochs_ratio,
            'performance_threshold': stage.performance_threshold,
            'current_evaluations': len(self.stage_performance_history),
            'min_evaluations': stage.min_evaluations,
            'is_completed': False,
            'debug_log_recent': self.debug_log[-10:]
        }

    def get_curriculum_progress(self) -> Dict[str, Any]:
        """è·å–æ•´ä½“è¯¾ç¨‹è¿›åº¦"""
        total_stages = len(self.curriculum_stages)
        progress_ratio = (self.current_stage + 1) / total_stages if total_stages > 0 else 1.0
        
        return {
            'current_stage': self.current_stage,
            'total_stages': total_stages,
            'progress_ratio': progress_ratio,
            'completed_stages': len(self.all_stage_history),
            'stage_statistics': self.stage_statistics,
            'dataset_distribution': getattr(self, 'dataset_distribution', {}),
            'all_stage_history': self.all_stage_history,
            'debug_summary': {
                'total_debug_entries': len(self.debug_log),
                'recent_entries': self.debug_log[-5:]
            }
        }

    def get_curriculum_state(self) -> Dict[str, Any]:
        """è·å–è¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨çš„å½“å‰çŠ¶æ€ï¼Œç”¨äºä¿å­˜"""
        return {
            "current_stage": self.current_stage,
            "stage_performance_history": self.stage_performance_history,
            "all_stage_history": self.all_stage_history,
            "debug_log": self.debug_log[-50:],
            "stage_statistics": self.stage_statistics
        }

    def load_curriculum_state(self, state_dict: Dict[str, Any]):
        """ä»å­—å…¸åŠ è½½è¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨çš„çŠ¶æ€"""
        self.current_stage = state_dict.get("current_stage", 0)
        self.stage_performance_history = state_dict.get("stage_performance_history", [])
        self.all_stage_history = state_dict.get("all_stage_history", [])
        self.debug_log = state_dict.get("debug_log", [])
        self.stage_statistics = state_dict.get("stage_statistics", [])
        
        self._log_debug(f"çŠ¶æ€å·²åŠ è½½ - å½“å‰é˜¶æ®µ: {self.current_stage}")
        if self.current_stage < len(self.curriculum_stages):
            stage_name = self.curriculum_stages[self.current_stage].name
            self._log_debug(f"æ¢å¤åˆ°é˜¶æ®µ: {stage_name}")

    def log_to_wandb(self, step: int):
        """è®°å½•åˆ°W&Bï¼ˆä½¿ç”¨æ•°å€¼è€Œéæ–‡å­—ï¼‰"""
        try:
            import wandb
            if not hasattr(wandb, 'run') or wandb.run is None:
                return
            
            current_info = self.get_current_stage_info()
            progress_info = self.get_curriculum_progress()
            
            # åŸºç¡€æ•°å€¼ä¿¡æ¯
            wandb_data = {
                'curriculum/current_stage_index': current_info['stage_index'],
                'curriculum/total_stages': progress_info['total_stages'],
                'curriculum/progress_ratio': progress_info['progress_ratio'],
                'curriculum/completed_stages_count': progress_info['completed_stages'],
                'curriculum/is_completed': float(current_info['is_completed'])
            }
            
            # å½“å‰é˜¶æ®µè¯¦ç»†ä¿¡æ¯ï¼ˆæ•°å€¼ï¼‰
            if not current_info['is_completed']:
                wandb_data.update({
                    'curriculum/current_evaluations': current_info['current_evaluations'],
                    'curriculum/min_evaluations': current_info['min_evaluations'],
                    'curriculum/performance_threshold': current_info['performance_threshold'],
                    'curriculum/epochs_ratio': current_info['epochs_ratio'],
                    'curriculum/level_count': len(current_info['dataset_levels']),
                    'curriculum/complexity_min': current_info['complexity_range'][0],
                    'curriculum/complexity_max': current_info['complexity_range'][1],
                })
            
            wandb.log(wandb_data, step=step)
            self._log_debug(f"å·²è®°å½•W&BæŒ‡æ ‡ (æ­¥æ•°: {step})")
            
        except ImportError:
            pass  # wandb not available
        except Exception as e:
            self._log_debug(f"W&Bè®°å½•å¤±è´¥: {e}")

    def save_detailed_log(self, output_dir: str):
        """ä¿å­˜è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—åˆ°æ–‡ä»¶"""
        log_file = os.path.join(output_dir, "curriculum_detailed_debug.json")
        
        detailed_data = {
            "curriculum_state": self.get_curriculum_state(),
            "progress_info": self.get_curriculum_progress(),
            "current_stage_info": self.get_current_stage_info(),
            "export_timestamp": datetime.now().isoformat(),
            "debug_summary": {
                "total_stages": len(self.curriculum_stages),
                "current_stage": self.current_stage,
                "stages_completed": len(self.all_stage_history),
                "total_debug_entries": len(self.debug_log)
            }
        }
        
        try:
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(detailed_data, f, indent=2, ensure_ascii=False)
            self._log_debug(f"è¯¦ç»†è°ƒè¯•æ—¥å¿—å·²ä¿å­˜: {log_file}")
        except Exception as e:
            self._log_debug(f"ä¿å­˜è°ƒè¯•æ—¥å¿—å¤±è´¥: {e}")


# Moved from train.py (setup_curriculum_manager)
# This function sets up EnhancedCurriculumManager, not FixedEnhancedCurriculumManager.
# We might need to reconcile this with setup_fixed_curriculum_manager.
def setup_enhanced_curriculum_manager(script_cfg: ScriptConfig, dataset: Dataset) -> Optional[EnhancedCurriculumManager]:
    if not script_cfg.enable_curriculum: # type: ignore
        logger.info("Curriculum learning disabled via script_cfg.")
        return None
    # ... (Logic from train.py setup_curriculum_manager, using create_custom_curriculum_stages or create_default_curriculum_stages)
    # This logic needs access to create_custom_curriculum_stages and create_default_curriculum_stages from .stages
    logger.info("Setting up EnhancedCurriculumManager...")
    # Placeholder logic:
    stages = create_default_curriculum_stages() # from .stages
    return EnhancedCurriculumManager(stages, dataset)


# Moved from curriculum_debug_config.py
def setup_fixed_curriculum_manager(script_cfg: ScriptConfig, dataset: Dataset) -> Optional[FixedEnhancedCurriculumManager]:
    if not script_cfg.enable_curriculum: # type: ignore
        logger.info("ğŸ“š Curriculum learning (fixed manager) is disabled.")
        return None
    # ... (Logic from curriculum_debug_config.py setup_fixed_curriculum_manager)
    # This logic needs access to create_fixed_curriculum_stages (if that's also moved/created) or other stage creation logic
    logger.info("Setting up FixedEnhancedCurriculumManager...")
    # Placeholder logic:
    # stages = create_fixed_curriculum_stages() # This function would also need to be defined/moved
    stages = create_default_curriculum_stages() # Using default for now as create_fixed_curriculum_stages is not in scope
    return FixedEnhancedCurriculumManager(stages, dataset)
