import logging
import numpy as np
from typing import List, Dict, Any, Tuple, Optional
from datasets import Dataset
from datetime import datetime
import json
import os
try:
    from grpo_project.configs import ScriptConfig
    from .stages import CurriculumStageConfig, create_default_curriculum_stages, create_custom_curriculum_stages
except ImportError:
    logger_init = logging.getLogger(__name__)
    logger_init.warning("Could not import from grpo_project.configs or .stages. Using placeholders for ScriptConfig/CurriculumStageConfig.")
    class ScriptConfig: pass # type: ignore
    class CurriculumStageConfig: pass # type: ignore
    def create_default_curriculum_stages() -> List[Any]: return []
    def create_custom_curriculum_stages(*args, **kwargs) -> List[Any]: return []


logger = logging.getLogger(__name__)

class EnhancedCurriculumManager:
    """å¢å¼ºçš„åŒå±‚è¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨ (from enhanced_curriculum.py)"""

    def __init__(self, curriculum_stages: List[CurriculumStageConfig], dataset: Dataset):
        self.stage_progression_configs = {
            0: {"performance_threshold": 0.75, "min_evaluations": 10, "stability_window": 3},
            1: {"performance_threshold": 0.70, "min_evaluations": 20, "stability_window": 3},
            2: {"performance_threshold": 0.65, "min_evaluations": 20, "stability_window": 3},
            3: {"performance_threshold": 0.60, "min_evaluations": 20, "stability_window": 2, "max_stay_steps": 200}
        }
        self.curriculum_stages = curriculum_stages
        self.full_dataset = dataset
        self.current_stage = 0
        self.stage_performance_history: List[Dict[str, Any]] = [] # More specific type
        self.stage_statistics: List[Dict[str, Any]] = []
        self.stage_start_steps: Dict[int, int] = {} # To track steps per stage

        self._analyze_dataset_distribution()
        self._validate_curriculum_design()

        logger.info(f"EnhancedCurriculumManager initialized with {len(curriculum_stages)} stages")
        # ... (rest of init logging)

    def should_advance_to_next_stage(self, current_loss: float, training_step: int) -> bool:
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager.should_advance_to_next_stage)
        # This method uses self.stage_progression_configs, self.curriculum_stages, self.current_stage,
        # self.stage_performance_history, self.stage_start_steps
        # For brevity, the full logic is not pasted here again but should be moved.
        logger.debug(f"Placeholder should_advance_to_next_stage called with loss {current_loss} at step {training_step}")
        if self.current_stage >= len(self.curriculum_stages) -1: return False
        # Simplified logic for stub:
        if len(self.stage_performance_history) > self.curriculum_stages[self.current_stage].min_evaluations:
            if np.mean([p['performance'] for p in self.stage_performance_history[-3:]]) > self.curriculum_stages[self.current_stage].performance_threshold:
                return True
        return False


    def get_curriculum_state(self) -> Dict[str, Any]:
        return {
            "current_stage": self.current_stage,
            "current_round": self.current_round,
            "completed_rounds": self.completed_rounds,
            "stage_performance_history": self.stage_performance_history,
            "all_stage_history": self.all_stage_history,
            "round_history": self.round_history,
            "stage_statistics": self.stage_statistics,
            "threshold_multiplier": self.threshold_multiplier,
            "advancement_attempts": self.advancement_attempts,
            "successful_advancements": self.successful_advancements,
            "total_advancement_checks": self.total_advancement_checks
        }

    def load_curriculum_state(self, state_dict: Dict[str, Any]):
        self.current_stage = state_dict.get("current_stage", 0)
        self.current_round = state_dict.get("current_round", 1)
        self.completed_rounds = state_dict.get("completed_rounds", 0)
        self.stage_performance_history = state_dict.get("stage_performance_history", [])
        self.all_stage_history = state_dict.get("all_stage_history", [])
        self.round_history = state_dict.get("round_history", [])
        self.stage_statistics = state_dict.get("stage_statistics", [])
        self.threshold_multiplier = state_dict.get("threshold_multiplier", 1.0)
        self.advancement_attempts = state_dict.get("advancement_attempts", 0)
        self.successful_advancements = state_dict.get("successful_advancements", 0)
        self.total_advancement_checks = state_dict.get("total_advancement_checks", 0)
        
        self._log_debug(f"ğŸ“š FixedEnhancedCurriculumManager çŠ¶æ€å·²æ¢å¤")
        self._log_debug(f"  - å½“å‰é˜¶æ®µ: {self.current_stage}")
        self._log_debug(f"  - å½“å‰è½®æ¬¡: {self.current_round}")
        self._log_debug(f"  - å·²å®Œæˆè½®æ¬¡: {self.completed_rounds}")
        self._log_debug(f"  - è¿›é˜¶ç»Ÿè®¡: {self.successful_advancements}/{self.advancement_attempts}")
        
        logger.info(f"FixedEnhancedCurriculumManager state loaded. Current stage: {self.current_stage}, Round: {self.current_round}")

    def get_current_stage_name(self) -> str:
        """Get the name of the current curriculum stage"""
        if self.current_stage >= len(self.curriculum_stages):
            return "completed"
        return self.curriculum_stages[self.current_stage].name


    def advance_stage(self) -> bool:
        # ... (Logic from enhanced_curriculum.py EnhancedCurriculumManager.advance_stage)
        if self.current_stage < len(self.curriculum_stages) - 1:
            self.current_stage += 1
            self.stage_performance_history = []
            logger.info(f"Advanced to curriculum stage {self.current_stage}")
            return True
        return False


# Moved from curriculum_debug_config.py
class FixedEnhancedCurriculumManager:
    """ä¿®å¤ç‰ˆæœ¬çš„å¢å¼ºè¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨ - å¢å¼ºè°ƒè¯•æ—¥å¿— + å¾ªç¯è®­ç»ƒåŠŸèƒ½"""
    
    def __init__(self, curriculum_stages: List[CurriculumStageConfig], dataset: Dataset):
        self.curriculum_stages = curriculum_stages
        self.full_dataset = dataset
        self.current_stage = 0
        self.stage_performance_history = []
        self.all_stage_history = []
        self.stage_statistics = []
        self.debug_log = []
        
        # ğŸ”§ å¢å¼ºï¼šæ·»åŠ æ›´å¤šè°ƒè¯•ä¿¡æ¯
        self.last_advancement_check_step = 0
        self.total_advancement_checks = 0
        self.advancement_attempts = 0
        self.successful_advancements = 0
        
        # ğŸ”„ æ–°å¢ï¼šå¾ªç¯è®­ç»ƒç›¸å…³å˜é‡
        self.current_round = 1  # å½“å‰æ˜¯ç¬¬å‡ è½®è®­ç»ƒ
        self.max_rounds = 5     # æœ€å¤§è½®æ¬¡æ•° (å¯é…ç½®)
        self.completed_rounds = 0  # å®Œæˆçš„è½®æ¬¡æ•°
        self.round_history = []    # æ¯è½®çš„å®Œæˆå†å²
        self.threshold_multiplier = 1.0  # é˜ˆå€¼å€æ•°ï¼Œæ¯è½®é€’å¢
        self.threshold_increment = 0.1   # æ¯è½®é˜ˆå€¼å¢åŠ é‡
        
        # ğŸ”§ æ–°å¢ï¼šå®Œæ•´epochè®­ç»ƒè·Ÿè¸ª
        self.stage_training_tracker = {}  # è·Ÿè¸ªæ¯ä¸ªé˜¶æ®µçš„è®­ç»ƒè¿›åº¦
        self.current_stage_start_step = 0  # å½“å‰é˜¶æ®µå¼€å§‹çš„æ­¥æ•°
        self.stage_dataset_size = 0  # å½“å‰é˜¶æ®µæ•°æ®é›†å¤§å°
        self.stage_steps_completed = 0  # å½“å‰é˜¶æ®µå·²å®Œæˆæ­¥æ•°
        self.stage_epochs_completed = 0  # å½“å‰é˜¶æ®µå·²å®Œæˆçš„epochæ•°
        
        self._log_debug("ğŸš€ FixedEnhancedCurriculumManager å¼€å§‹åˆå§‹åŒ– (æ”¯æŒå¾ªç¯è®­ç»ƒ+å®Œæ•´epochè¦æ±‚)")
        self._log_debug(f"ğŸ“Š è¯¾ç¨‹é…ç½®: æ€»é˜¶æ®µæ•°={len(curriculum_stages)}, æ•°æ®é›†å¤§å°={len(dataset)}")
        self._log_debug(f"ğŸ”„ å¾ªç¯è®­ç»ƒé…ç½®: æœ€å¤§è½®æ¬¡={self.max_rounds}, é˜ˆå€¼é€’å¢={self.threshold_increment}")
        
        # è¯¦ç»†è®°å½•æ¯ä¸ªé˜¶æ®µçš„é…ç½®
        for i, stage in enumerate(curriculum_stages):
            self._log_debug(f"  é˜¶æ®µ{i} ({stage.name}):")
            self._log_debug(f"    - ç­‰çº§: {stage.dataset_levels}")
            self._log_debug(f"    - å¤æ‚åº¦: {stage.complexity_range}")
            self._log_debug(f"    - åŸºç¡€æ€§èƒ½é˜ˆå€¼: {stage.performance_threshold}")
            self._log_debug(f"    - æœ€å°è¯„ä¼°: {stage.min_evaluations}")
            self._log_debug(f"    - è¦æ±‚å®Œæ•´epoch: {getattr(stage, 'require_full_epoch', False)}")
            self._log_debug(f"    - æœ€å°æ­¥æ•°/epoch: {getattr(stage, 'min_steps_per_epoch', 10)}")
        
        # Analyze dataset distribution using the static method
        self.dataset_distribution = FixedEnhancedCurriculumManager._calculate_dataset_distribution(self.full_dataset, self._log_debug)
        self._log_detailed_distribution() # New method to keep __init__ cleaner

        self._validate_curriculum_design()
        
        # éªŒè¯å½“å‰é˜¶æ®µæ•°æ®é›†
        current_dataset = self.get_current_stage_dataset()
        self._log_debug(f"âœ… åˆå§‹åŒ–å®Œæˆ: å½“å‰é˜¶æ®µæ•°æ®é›†å¤§å°={len(current_dataset)}")
        self._log_debug(f"ğŸ”„ å‡†å¤‡å¼€å§‹ç¬¬{self.current_round}è½®è®­ç»ƒ")
        
        # ğŸ”§ åˆå§‹åŒ–å½“å‰é˜¶æ®µçš„è®­ç»ƒè·Ÿè¸ª
        self._initialize_stage_tracker()

    def _validate_curriculum_design(self):
        """éªŒè¯è¯¾ç¨‹è®¾è®¡çš„åˆç†æ€§ - å¢å¼ºç‰ˆï¼šæ£€æŸ¥æ•°æ®é›†è¦†ç›–ç‡"""
        available_levels = set(self.dataset_distribution['level_counts'].keys())
        covered_levels = set()
        
        for stage in self.curriculum_stages:
            covered_levels.update([level.lower() for level in stage.dataset_levels])
        
        uncovered_levels = available_levels - covered_levels
        if uncovered_levels:
            self._log_debug(f"âš ï¸ æœªè¦†ç›–çš„æ•°æ®é›†ç­‰çº§: {uncovered_levels}")
            self._log_debug("ğŸ”§ å»ºè®®ï¼šæ·»åŠ comprehensiveé˜¶æ®µæˆ–ä¿®æ”¹ç°æœ‰é˜¶æ®µé…ç½®")
        
        total_ratio = sum(stage.epochs_ratio for stage in self.curriculum_stages)
        # Ensure epochs_ratio exists and is a float, provide default if not
        total_ratio = sum(getattr(stage, 'epochs_ratio', 0.0) for stage in self.curriculum_stages)

        if abs(total_ratio - 1.0) > 0.01: # Assuming a default of 0.0 if attribute missing
            self._log_debug(f"âš ï¸ Epochæ¯”ä¾‹æ€»å’Œ: {total_ratio:.3f} (åº”è¯¥æ¥è¿‘1.0)")
        
        # ğŸ”§ æ–°å¢ï¼šè¯¦ç»†çš„æ•°æ®é›†è¦†ç›–ç‡åˆ†æ
        self._analyze_dataset_coverage()

    def _analyze_dataset_coverage(self):
        """åˆ†ææ•°æ®é›†è¦†ç›–ç‡"""
        self._log_debug("ğŸ” å¼€å§‹æ•°æ®é›†è¦†ç›–ç‡åˆ†æ...")
        
        total_samples = len(self.full_dataset)
        covered_samples = set()
        stage_coverage = {}
        
        for stage_idx, stage in enumerate(self.curriculum_stages):
            stage_indices = []
            
            for i, example in enumerate(self.full_dataset):
                # æ£€æŸ¥æ˜¯å¦ç¬¦åˆå½“å‰é˜¶æ®µæ¡ä»¶
                example_level = example.get('level', 'unknown').lower()
                complexity = example.get('complexity_score', 5.0)
                
                # ç­‰çº§åŒ¹é…
                if example_level in [level.lower() for level in stage.dataset_levels]:
                    # å¤æ‚åº¦åŒ¹é…
                    min_complexity, max_complexity = stage.complexity_range
                    if min_complexity <= complexity <= max_complexity:
                        stage_indices.append(i)
                        covered_samples.add(i)
            
            stage_coverage[stage.name] = {
                'indices': stage_indices,
                'count': len(stage_indices),
                'ratio': len(stage_indices) / total_samples if total_samples > 0 else 0
            }
            
            self._log_debug(f"  é˜¶æ®µ {stage.name}: {len(stage_indices)} æ ·æœ¬ ({len(stage_indices)/total_samples*100:.1f}%)")
        
        # æ€»è¦†ç›–ç‡ç»Ÿè®¡
        total_covered = len(covered_samples)
        uncovered_count = total_samples - total_covered
        coverage_ratio = total_covered / total_samples if total_samples > 0 else 0
        
        self._log_debug(f"ğŸ“Š æ€»ä½“è¦†ç›–ç‡åˆ†æ:")
        self._log_debug(f"  - æ€»æ ·æœ¬æ•°: {total_samples}")
        self._log_debug(f"  - å·²è¦†ç›–æ ·æœ¬: {total_covered} ({coverage_ratio*100:.1f}%)")
        self._log_debug(f"  - æœªè¦†ç›–æ ·æœ¬: {uncovered_count} ({(1-coverage_ratio)*100:.1f}%)")
        
        if uncovered_count > 0:
            self._log_debug(f"âš ï¸ è­¦å‘Šï¼š{uncovered_count} ä¸ªæ ·æœ¬æœªè¢«ä»»ä½•é˜¶æ®µè¦†ç›–!")
            self._analyze_uncovered_samples(covered_samples)
        else:
            self._log_debug("âœ… æ‰€æœ‰æ ·æœ¬éƒ½è¢«è‡³å°‘ä¸€ä¸ªé˜¶æ®µè¦†ç›–")
        
        # ä¿å­˜è¦†ç›–ç‡ä¿¡æ¯
        self.coverage_analysis = {
            'total_samples': total_samples,
            'covered_samples': total_covered,
            'coverage_ratio': coverage_ratio,
            'stage_coverage': stage_coverage,
            'uncovered_count': uncovered_count
        }

    def _analyze_uncovered_samples(self, covered_samples: set):
        """åˆ†ææœªè¦†ç›–çš„æ ·æœ¬"""
        uncovered_indices = []
        uncovered_levels = {}
        uncovered_complexities = []
        
        for i, example in enumerate(self.full_dataset):
            if i not in covered_samples:
                uncovered_indices.append(i)
                
                level = example.get('level', 'unknown').lower()
                complexity = example.get('complexity_score', 5.0)
                
                uncovered_levels[level] = uncovered_levels.get(level, 0) + 1
                uncovered_complexities.append(complexity)
        
        self._log_debug(f"ğŸ” æœªè¦†ç›–æ ·æœ¬åˆ†æ:")
        self._log_debug(f"  - æŒ‰ç­‰çº§åˆ†å¸ƒ:")
        for level, count in uncovered_levels.items():
            self._log_debug(f"    {level}: {count} æ ·æœ¬")
        
        if uncovered_complexities:
            import numpy as np
            self._log_debug(f"  - å¤æ‚åº¦åˆ†å¸ƒ:")
            self._log_debug(f"    æœ€å°: {np.min(uncovered_complexities):.2f}")
            self._log_debug(f"    æœ€å¤§: {np.max(uncovered_complexities):.2f}")
            self._log_debug(f"    å¹³å‡: {np.mean(uncovered_complexities):.2f}")
            self._log_debug(f"    ä¸­ä½æ•°: {np.median(uncovered_complexities):.2f}")
        
        # ä¿å­˜æœªè¦†ç›–æ ·æœ¬ä¿¡æ¯
        self.uncovered_analysis = {
            'indices': uncovered_indices,
            'levels': uncovered_levels,
            'complexities': uncovered_complexities
        }

    def _log_detailed_distribution(self):
        """Logs the detailed dataset distribution after analysis."""
        if not self.dataset_distribution or not self.dataset_distribution.get('total_samples'):
            self._log_debug("Dataset distribution is empty or invalid after calculation.")
            return

        self._log_debug(f"æ•°æ®é›†åˆ†å¸ƒåˆ†æ - æ€»æ ·æœ¬: {self.dataset_distribution['total_samples']}")
        for level, count in self.dataset_distribution['level_counts'].items():
            if level in self.dataset_distribution['complexity_by_level'] and self.dataset_distribution['complexity_by_level'][level]:
                avg_complexity = np.mean(self.dataset_distribution['complexity_by_level'][level])
                complexity_range_actual = (np.min(self.dataset_distribution['complexity_by_level'][level]), np.max(self.dataset_distribution['complexity_by_level'][level]))
                self._log_debug(f"  {level}: {count}æ ·æœ¬, å¹³å‡å¤æ‚åº¦: {avg_complexity:.2f}, èŒƒå›´: {complexity_range_actual}")
            else:
                self._log_debug(f"  {level}: {count}æ ·æœ¬, æ— å¤æ‚åº¦ä¿¡æ¯")


    def _log_debug(self, message: str):
        """è®°å½•è°ƒè¯•ä¿¡æ¯ - å¢å¼ºç‰ˆæœ¬"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        debug_entry = f"[{timestamp}] {message}"
        self.debug_log.append(debug_entry)
        
        # ğŸ”§ ç¡®ä¿è°ƒè¯•ä¿¡æ¯è¾“å‡ºåˆ°æ­£ç¡®çš„ logger
        logger.info(f"ğŸ“š CURRICULUM (Fixed): {message}")
        
        # ğŸ”§ é¢å¤–ï¼šæ¯100æ¡è°ƒè¯•æ—¥å¿—è¾“å‡ºä¸€æ¬¡ç»Ÿè®¡
        if len(self.debug_log) % 100 == 0:
            logger.info(f"ğŸ“Š è¯¾ç¨‹è°ƒè¯•ç»Ÿè®¡: {len(self.debug_log)} æ¡æ—¥å¿—, å½“å‰é˜¶æ®µ={self.current_stage}, å½“å‰è½®æ¬¡={self.current_round}")

    def get_current_threshold(self, stage_index: int = None) -> float:
        """è·å–å½“å‰è½®æ¬¡çš„æœ‰æ•ˆæ€§èƒ½é˜ˆå€¼"""
        if stage_index is None:
            stage_index = self.current_stage
            
        if stage_index >= len(self.curriculum_stages):
            return 0.9  # é»˜è®¤é«˜é˜ˆå€¼
            
        base_threshold = self.curriculum_stages[stage_index].performance_threshold
        # ç¬¬ä¸€è½®ä½¿ç”¨åŸå§‹é˜ˆå€¼ï¼Œåç»­è½®æ¬¡é€’å¢
        current_threshold = base_threshold + (self.current_round - 1) * self.threshold_increment
        
        # ç¡®ä¿é˜ˆå€¼ä¸è¶…è¿‡0.95ï¼ˆé¿å…è¿‡äºè‹›åˆ»ï¼‰
        return min(current_threshold, 0.95)
    
    def start_new_round(self):
        """å¼€å§‹æ–°ä¸€è½®è®­ç»ƒ"""
        self.completed_rounds += 1
        
        # è®°å½•ä¸Šä¸€è½®çš„å®Œæ•´ä¿¡æ¯
        round_summary = {
            'round_number': self.current_round,
            'completed_stages': len(self.all_stage_history),
            'total_evaluations': sum(len(h['performance_history']) for h in self.all_stage_history),
            'completion_timestamp': datetime.now().isoformat(),
            'stage_history': self.all_stage_history.copy()
        }
        self.round_history.append(round_summary)
        
        # å¼€å§‹æ–°è½®æ¬¡
        self.current_round += 1
        self.current_stage = 0
        self.stage_performance_history = []
        
        self._log_debug(f"ğŸ”„ å®Œæˆç¬¬{self.completed_rounds}è½®è®­ç»ƒï¼Œå¼€å§‹ç¬¬{self.current_round}è½®")
        self._log_debug(f"ğŸ“ˆ æ–°è½®æ¬¡é˜ˆå€¼æå‡: åŸºç¡€é˜ˆå€¼ + {(self.current_round - 1) * self.threshold_increment:.2f}")
        
        # è®°å½•æ–°è½®æ¬¡çš„é˜ˆå€¼æƒ…å†µ
        for i, stage in enumerate(self.curriculum_stages):
            new_threshold = self.get_current_threshold(i)
            self._log_debug(f"  é˜¶æ®µ{i} ({stage.name}): {stage.performance_threshold:.2f} -> {new_threshold:.2f}")
    
    def should_continue_curriculum(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»§ç»­è¯¾ç¨‹å­¦ä¹ ï¼ˆæœªè¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼‰"""
        return self.current_round <= self.max_rounds

    @staticmethod
    def _calculate_dataset_distribution(dataset: Dataset, log_fn=None) -> Dict[str, Any]:
        """
        Calculates and returns the dataset distribution.
        Can be used statically. If log_fn is provided, it will log messages.
        """
        if len(dataset) == 0:
            if log_fn: log_fn("âŒ _calculate_dataset_distribution: Empty dataset provided.")
            return {'level_counts': {}, 'complexity_by_level': {}, 'total_samples': 0}
        
        level_counts = {}
        complexity_by_level = {}
        
        for example in dataset:
            level = example.get('level', 'unknown').lower()
            # Ensuring complexity_score is float, default to 5.0 if missing or not convertible
            try:
                complexity = float(example.get('complexity_score', 5.0))
            except (ValueError, TypeError):
                complexity = 5.0

            level_counts[level] = level_counts.get(level, 0) + 1
            
            if level not in complexity_by_level:
                complexity_by_level[level] = []
            complexity_by_level[level].append(complexity)
        
        # The original _analyze_dataset_distribution logged details.
        # This static version returns the raw data. Logging can be done by the caller.

        return {
            'level_counts': level_counts,
            'complexity_by_level': complexity_by_level, # raw lists of complexities per level
            'total_samples': len(dataset)
        }

    def should_advance_stage(self, recent_performance: float, current_step: int = None) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ - å¢å¼ºè°ƒè¯•ç‰ˆæœ¬ + å¾ªç¯è®­ç»ƒæ”¯æŒ + å®Œæ•´epochè¦æ±‚"""
        self.total_advancement_checks += 1
        
        # ğŸ”§ æ›´æ–°è®­ç»ƒè¿›åº¦
        if current_step is not None:
            self.update_training_progress(current_step)
        
        self._log_debug(f"ğŸ” ç¬¬{self.total_advancement_checks}æ¬¡è¿›é˜¶æ£€æŸ¥ (è½®æ¬¡{self.current_round})")
        self._log_debug(f"  - å½“å‰æ€§èƒ½: {recent_performance:.4f}")
        self._log_debug(f"  - å½“å‰é˜¶æ®µ: {self.current_stage}")
        self._log_debug(f"  - å†å²é•¿åº¦: {len(self.stage_performance_history)}")
        self._log_debug(f"  - å†å²å†…å®¹: {[f'{p:.4f}' for p in self.stage_performance_history[-5:]]}")  # æ˜¾ç¤ºæœ€è¿‘5æ¬¡
        
        # ğŸ”„ æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æœ€åé˜¶æ®µ - ä½†ä¸ç›´æ¥è¿”å›Falseï¼Œè€Œæ˜¯è€ƒè™‘å¾ªç¯
        if self.current_stage >= len(self.curriculum_stages) - 1:
            self._log_debug("ğŸ“ å·²åœ¨æœ€åé˜¶æ®µï¼Œæ£€æŸ¥æ˜¯å¦åº”è¯¥å¼€å§‹æ–°è½®æ¬¡")
            # å¦‚æœè¿˜æœ‰å‰©ä½™è½®æ¬¡ï¼Œå°†åœ¨advance_stageä¸­å¤„ç†å¾ªç¯
            # è¿™é‡Œå…ˆè®©æ­£å¸¸çš„é˜ˆå€¼æ£€æŸ¥å†³å®šæ˜¯å¦"è¿›é˜¶"åˆ°æ–°è½®æ¬¡
        
        stage = self.curriculum_stages[self.current_stage]
        self.stage_performance_history.append(recent_performance)
        
        # ğŸ”§ ä½¿ç”¨åŠ¨æ€é˜ˆå€¼
        current_threshold = self.get_current_threshold()
        base_threshold = stage.performance_threshold
        
        self._log_debug(f"  - æ€§èƒ½å·²è®°å½•ï¼Œæ–°å†å²é•¿åº¦: {len(self.stage_performance_history)}")
        self._log_debug(f"  - é˜¶æ®µé…ç½®: {stage.name}, åŸºç¡€é˜ˆå€¼={base_threshold:.3f}, å½“å‰é˜ˆå€¼={current_threshold:.3f}")
        self._log_debug(f"  - é˜ˆå€¼æå‡: +{current_threshold - base_threshold:.3f} (è½®æ¬¡{self.current_round})")
        
        # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥å®Œæ•´epochè®­ç»ƒè¦æ±‚
        is_training_complete = self.is_stage_training_complete()
        training_status = self.get_stage_training_status()
        
        self._log_debug(f"ğŸ“Š å®Œæ•´è®­ç»ƒæ£€æŸ¥:")
        self._log_debug(f"  - è¦æ±‚å®Œæ•´epoch: {training_status.get('require_full_epoch', False)}")
        self._log_debug(f"  - è®­ç»ƒè¿›åº¦: {training_status.get('progress_percent', 0):.1f}%")
        self._log_debug(f"  - å·²å®Œæˆepoch: {training_status.get('epochs_completed', 0):.2f}")
        self._log_debug(f"  - å·²å®Œæˆæ­¥æ•°: {training_status.get('steps_completed', 0)}")
        self._log_debug(f"  - å®Œæ•´è®­ç»ƒè¦æ±‚æ»¡è¶³: {is_training_complete}")
        
        # éœ€è¦è¶³å¤Ÿçš„è¯„ä¼°æ¬¡æ•°
        if len(self.stage_performance_history) < stage.min_evaluations:
            self._log_debug(f"âŒ è¯„ä¼°æ¬¡æ•°ä¸è¶³: {len(self.stage_performance_history)}/{stage.min_evaluations}")
            return False
        
        # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥å®Œæ•´è®­ç»ƒè¦æ±‚
        if not is_training_complete:
            self._log_debug(f"âŒ å®Œæ•´è®­ç»ƒè¦æ±‚æœªæ»¡è¶³")
            self._log_debug(f"  - éœ€è¦å®Œæˆè‡³å°‘1ä¸ªå®Œæ•´epochçš„è®­ç»ƒ")
            self._log_debug(f"  - å½“å‰è¿›åº¦: {training_status.get('epochs_completed', 0):.2f}/1.0 epoch")
            return False
        
        # æ£€æŸ¥æœ€è¿‘çš„æ€§èƒ½è¡¨ç°
        recent_window = min(2, len(self.stage_performance_history))
        recent_performances = self.stage_performance_history[-recent_window:]
        recent_avg = np.mean(recent_performances)
        
        self._log_debug(f"  - æœ€è¿‘{recent_window}æ¬¡æ€§èƒ½: {recent_performances}")
        self._log_debug(f"  - æœ€è¿‘å¹³å‡æ€§èƒ½: {recent_avg:.4f}")
        self._log_debug(f"  - å½“å‰è½®æ¬¡é˜ˆå€¼: {current_threshold:.4f}")
        
        should_advance = recent_avg >= current_threshold
        
        # ğŸ”§ è¯¦ç»†è®°å½•å†³ç­–è¿‡ç¨‹
        if should_advance:
            self._log_debug(f"âœ… æ»¡è¶³è¿›é˜¶æ¡ä»¶!")
            self._log_debug(f"  - æ€§èƒ½æ£€æŸ¥: {recent_avg:.4f} >= {current_threshold:.4f} âœ…")
            self._log_debug(f"  - è¯„ä¼°æ£€æŸ¥: {len(self.stage_performance_history)} >= {stage.min_evaluations} âœ…")
            self._log_debug(f"  - å®Œæ•´è®­ç»ƒæ£€æŸ¥: {is_training_complete} âœ…")
            if self.current_stage >= len(self.curriculum_stages) - 1:
                if self.should_continue_curriculum():
                    self._log_debug(f"  - ğŸ”„ å°†è§¦å‘æ–°è½®æ¬¡ (å½“å‰ç¬¬{self.current_round}è½®)")
                else:
                    self._log_debug(f"  - ğŸ æ‰€æœ‰è½®æ¬¡å·²å®Œæˆ (å…±{self.max_rounds}è½®)")
        else:
            self._log_debug(f"âŒ ä¸æ»¡è¶³è¿›é˜¶æ¡ä»¶")
            if recent_avg < current_threshold:
                improvement_needed = current_threshold - recent_avg
                self._log_debug(f"  - æ€§èƒ½ä¸è¶³: {recent_avg:.4f} < {current_threshold:.4f} (éœ€æå‡{improvement_needed:.4f})")
            
        self._log_debug(f"  - è¿›é˜¶å†³ç­–: {should_advance}")
        return should_advance

    def advance_stage(self) -> bool:
        """è¿›å…¥ä¸‹ä¸€é˜¶æ®µ - å¢å¼ºè°ƒè¯•ç‰ˆæœ¬ + å¾ªç¯è®­ç»ƒæ”¯æŒ + å®Œæ•´epochè·Ÿè¸ª"""
        self.advancement_attempts += 1
        
        self._log_debug(f"ğŸ¯ ç¬¬{self.advancement_attempts}æ¬¡è¿›é˜¶å°è¯• (è½®æ¬¡{self.current_round})")
        
        # è®°å½•å½“å‰é˜¶æ®µçš„æœ€ç»ˆç»Ÿè®¡
        old_stage = self.current_stage
        old_stage_name = self.curriculum_stages[old_stage].name if old_stage < len(self.curriculum_stages) else "Final"
        
        # ğŸ”§ è¯¦ç»†è®°å½•è¿›é˜¶å‰çš„çŠ¶æ€
        self._log_debug(f"ğŸ“Š è¿›é˜¶å‰çŠ¶æ€ç»Ÿè®¡:")
        self._log_debug(f"  - ç¦»å¼€é˜¶æ®µ: {old_stage} ({old_stage_name})")
        self._log_debug(f"  - è¯¥é˜¶æ®µè¯„ä¼°æ¬¡æ•°: {len(self.stage_performance_history)}")
        
        # ğŸ”§ è®°å½•å®Œæ•´è®­ç»ƒçŠ¶æ€
        training_status = self.get_stage_training_status()
        if training_status and training_status.get('status') != 'no_tracker':
            self._log_debug(f"  - å®Œæ•´è®­ç»ƒçŠ¶æ€:")
            self._log_debug(f"    å·²å®Œæˆepoch: {training_status.get('epochs_completed', 0):.2f}")
            self._log_debug(f"    å·²å®Œæˆæ­¥æ•°: {training_status.get('steps_completed', 0)}")
            self._log_debug(f"    è®­ç»ƒè¿›åº¦: {training_status.get('progress_percent', 0):.1f}%")
            self._log_debug(f"    epochè¦æ±‚æ»¡è¶³: {training_status.get('is_epoch_requirement_met', False)}")
        
        if self.stage_performance_history:
            final_performance = self.stage_performance_history[-1]
            avg_performance = np.mean(self.stage_performance_history)
            best_performance = np.max(self.stage_performance_history)
            worst_performance = np.min(self.stage_performance_history)
            
            self._log_debug(f"  - æœ€ç»ˆæ€§èƒ½: {final_performance:.4f}")
            self._log_debug(f"  - å¹³å‡æ€§èƒ½: {avg_performance:.4f}")
            self._log_debug(f"  - æœ€ä½³æ€§èƒ½: {best_performance:.4f}")
            self._log_debug(f"  - æœ€å·®æ€§èƒ½: {worst_performance:.4f}")
        
        final_stats = {
            'completed_stage': old_stage,
            'stage_name': old_stage_name,
            'round_number': self.current_round,
            'total_evaluations': len(self.stage_performance_history),
            'final_performance': self.stage_performance_history[-1] if self.stage_performance_history else 0,
            'average_performance': np.mean(self.stage_performance_history) if self.stage_performance_history else 0,
            'performance_history': self.stage_performance_history.copy(),
            'completion_timestamp': datetime.now().isoformat(),
            'threshold_used': self.get_current_threshold(old_stage),
            'training_status': training_status  # ğŸ”§ æ–°å¢ï¼šä¿å­˜è®­ç»ƒçŠ¶æ€
        }
        
        # ä¿å­˜åˆ°å…¨éƒ¨å†å²
        self.all_stage_history.append(final_stats)
        
        # ğŸ”„ å…³é”®ä¿®æ”¹ï¼šå¤„ç†é˜¶æ®µè¿›é˜¶ vs è½®æ¬¡å¾ªç¯
        if self.current_stage >= len(self.curriculum_stages) - 1:
            # åœ¨æœ€åä¸€ä¸ªé˜¶æ®µï¼Œæ£€æŸ¥æ˜¯å¦å¼€å§‹æ–°è½®æ¬¡
            if self.should_continue_curriculum():
                # å¼€å§‹æ–°è½®æ¬¡
                self._log_debug(f"ğŸ”„ å®Œæˆç¬¬{self.current_round}è½®æœ€åé˜¶æ®µï¼Œå¼€å§‹æ–°è½®æ¬¡")
                self.start_new_round()
                new_stage_name = self.curriculum_stages[0].name
                self.successful_advancements += 1
                
                self._log_debug(f"ğŸ”„ è½®æ¬¡å¾ªç¯æˆåŠŸ!")
                self._log_debug(f"  - è½®æ¬¡è·¯å¾„: ç¬¬{self.current_round-1}è½®é˜¶æ®µ{old_stage} -> ç¬¬{self.current_round}è½®é˜¶æ®µ0")
                self._log_debug(f"  - æˆåŠŸè¿›é˜¶æ¬¡æ•°: {self.successful_advancements}/{self.advancement_attempts}")
                
                # æ˜¾ç¤ºæ–°è½®æ¬¡çš„é˜ˆå€¼æƒ…å†µ
                new_threshold = self.get_current_threshold(0)
                base_threshold = self.curriculum_stages[0].performance_threshold
                self._log_debug(f"ğŸ“ˆ æ–°è½®æ¬¡ç¬¬ä¸€é˜¶æ®µ:")
                self._log_debug(f"  - é˜¶æ®µåç§°: {new_stage_name}")
                self._log_debug(f"  - åŸºç¡€é˜ˆå€¼: {base_threshold:.3f}")
                self._log_debug(f"  - æ–°è½®æ¬¡é˜ˆå€¼: {new_threshold:.3f} (+{new_threshold-base_threshold:.3f})")
                
                # ğŸ”§ é‡æ–°åˆå§‹åŒ–è®­ç»ƒè·Ÿè¸ªå™¨
                self.current_stage_start_step = 0  # è¿™éœ€è¦ä»å¤–éƒ¨æ›´æ–°
                self._initialize_stage_tracker()
                
                return True
            else:
                # æ‰€æœ‰è½®æ¬¡å·²å®Œæˆ
                self._log_debug(f"ğŸ æ‰€æœ‰{self.max_rounds}è½®è®­ç»ƒå·²å®Œæˆï¼Œè¯¾ç¨‹å­¦ä¹ ç»“æŸ")
                return False
        else:
            # æ­£å¸¸é˜¶æ®µè¿›é˜¶
            self.current_stage += 1
            self.stage_performance_history = []  # é‡ç½®æ€§èƒ½å†å²
            
            new_stage_name = self.curriculum_stages[self.current_stage].name
            self.successful_advancements += 1
            
            self._log_debug(f"ğŸ‰ æˆåŠŸè¿›é˜¶!")
            self._log_debug(f"  - è¿›é˜¶è·¯å¾„: ç¬¬{self.current_round}è½®é˜¶æ®µ{old_stage}({old_stage_name}) -> ç¬¬{self.current_round}è½®é˜¶æ®µ{self.current_stage}({new_stage_name})")
            self._log_debug(f"  - æˆåŠŸè¿›é˜¶æ¬¡æ•°: {self.successful_advancements}/{self.advancement_attempts}")
            self._log_debug(f"  - å‰é˜¶æ®µæœ€ç»ˆæ€§èƒ½: {final_stats['final_performance']:.4f}")
            
            # ğŸ”§ è¯¦ç»†è®°å½•æ–°é˜¶æ®µä¿¡æ¯
            new_stage = self.curriculum_stages[self.current_stage]
            new_dataset = self.get_current_stage_dataset()
            new_threshold = self.get_current_threshold()
            
            self._log_debug(f"ğŸ“ˆ æ–°é˜¶æ®µè¯¦æƒ…:")
            self._log_debug(f"  - é˜¶æ®µåç§°: {new_stage.name}")
            self._log_debug(f"  - ç›®æ ‡ç­‰çº§: {new_stage.dataset_levels}")
            self._log_debug(f"  - å¤æ‚åº¦èŒƒå›´: {new_stage.complexity_range}")
            self._log_debug(f"  - åŸºç¡€é˜ˆå€¼: {new_stage.performance_threshold:.3f}")
            self._log_debug(f"  - å½“å‰è½®æ¬¡é˜ˆå€¼: {new_threshold:.3f}")
            self._log_debug(f"  - æ•°æ®é›†å¤§å°: {len(new_dataset)}")
            self._log_debug(f"  - æ•°æ®é›†æ¯”ä¾‹: {len(new_dataset)/len(self.full_dataset)*100:.1f}%")
            self._log_debug(f"  - è¦æ±‚å®Œæ•´epoch: {getattr(new_stage, 'require_full_epoch', True)}")
            
            # ğŸ”§ é‡æ–°åˆå§‹åŒ–è®­ç»ƒè·Ÿè¸ªå™¨
            self.current_stage_start_step = 0  # è¿™éœ€è¦ä»å¤–éƒ¨æ›´æ–°
            self._initialize_stage_tracker()
            
            return True

    def get_current_stage_dataset(self) -> Dataset:
        """è·å–å½“å‰é˜¶æ®µçš„æ•°æ®é›† - å¢å¼ºè°ƒè¯•ç‰ˆæœ¬"""
        if self.current_stage >= len(self.curriculum_stages):
            self._log_debug("âœ… è¯¾ç¨‹å­¦ä¹ å®Œæˆï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®é›†")
            return self.full_dataset
        
        stage = self.curriculum_stages[self.current_stage]
        
        # ğŸ”§ è¯¦ç»†çš„è¿‡æ»¤è¿‡ç¨‹æ—¥å¿—
        self._log_debug(f"ğŸ” å¼€å§‹è¿‡æ»¤é˜¶æ®µ{self.current_stage}æ•°æ®é›†")
        self._log_debug(f"  - é˜¶æ®µåç§°: {stage.name}")
        self._log_debug(f"  - ç›®æ ‡ç­‰çº§: {stage.dataset_levels}")
        self._log_debug(f"  - å¤æ‚åº¦èŒƒå›´: {stage.complexity_range}")
        self._log_debug(f"  - åŸå§‹æ•°æ®é›†å¤§å°: {len(self.full_dataset)}")
        
        # åŒå±‚è¿‡æ»¤ï¼šæ•°æ®é›†ç­‰çº§ + å¤æ‚åº¦èŒƒå›´
        filtered_indices = []
        level_filter_count = 0
        complexity_filter_count = 0
        
        # ğŸ”§ æŒ‰ç­‰çº§åˆ†ç±»ç»Ÿè®¡
        level_stats = {}
        complexity_stats = {}
        
        for i, example in enumerate(self.full_dataset):
            # ç¬¬ä¸€å±‚è¿‡æ»¤ï¼šæ•°æ®é›†ç­‰çº§
            example_level = example.get('level', 'unknown').lower()
            level_stats[example_level] = level_stats.get(example_level, 0) + 1
            
            if example_level not in [level.lower() for level in stage.dataset_levels]:
                continue
            level_filter_count += 1
            
            # ç¬¬äºŒå±‚è¿‡æ»¤ï¼šå¤æ‚åº¦èŒƒå›´
            complexity = example.get('complexity_score', 5.0)
            complexity_key = f"{int(complexity)}-{int(complexity)+1}"
            complexity_stats[complexity_key] = complexity_stats.get(complexity_key, 0) + 1
            
            min_complexity, max_complexity = stage.complexity_range
            if not (min_complexity <= complexity <= max_complexity):
                continue
            complexity_filter_count += 1
            
            filtered_indices.append(i)
        
        # ğŸ”§ è¯¦ç»†çš„è¿‡æ»¤ç»Ÿè®¡æ—¥å¿—
        self._log_debug(f"ğŸ“Š è¿‡æ»¤ç»Ÿè®¡:")
        self._log_debug(f"  - åŸå§‹æ•°æ®: {len(self.full_dataset)} æ ·æœ¬")
        self._log_debug(f"  - ç­‰çº§è¿‡æ»¤é€šè¿‡: {level_filter_count} æ ·æœ¬")
        self._log_debug(f"  - å¤æ‚åº¦è¿‡æ»¤é€šè¿‡: {complexity_filter_count} æ ·æœ¬")
        self._log_debug(f"  - æœ€ç»ˆé€‰æ‹©: {len(filtered_indices)} æ ·æœ¬")
        
        # ğŸ”§ ç­‰çº§åˆ†å¸ƒç»Ÿè®¡
        self._log_debug(f"ğŸ“ˆ æ•°æ®é›†ç­‰çº§åˆ†å¸ƒ:")
        for level, count in sorted(level_stats.items()):
            is_target = level in [l.lower() for l in stage.dataset_levels]
            marker = "âœ…" if is_target else "âŒ"
            self._log_debug(f"    {marker} {level}: {count} æ ·æœ¬ ({count/len(self.full_dataset)*100:.1f}%)")
        
        # ğŸ”§ å¤æ‚åº¦åˆ†å¸ƒç»Ÿè®¡
        self._log_debug(f"ğŸ“ˆ å¤æ‚åº¦åˆ†å¸ƒç»Ÿè®¡:")
        min_c, max_c = stage.complexity_range
        for comp_range, count in sorted(complexity_stats.items()):
            range_start = int(comp_range.split('-')[0])
            is_in_range = min_c <= range_start <= max_c
            marker = "âœ…" if is_in_range else "âŒ"
            self._log_debug(f"    {marker} {comp_range}: {count} æ ·æœ¬")
        
        if not filtered_indices:
            self._log_debug(f"âŒ é˜¶æ®µ{self.current_stage}æ²¡æœ‰åŒ¹é…çš„æ ·æœ¬ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®é›†")
            self._log_debug("âš ï¸ è¿™å¯èƒ½è¡¨æ˜è¯¾ç¨‹é…ç½®æœ‰é—®é¢˜!")
            return self.full_dataset
        
        stage_dataset = self.full_dataset.select(filtered_indices)
        
        # è®°å½•è¯¦ç»†ç»Ÿè®¡
        stage_stats = {
            'stage_index': self.current_stage,
            'stage_name': stage.name,
            'total_examples': len(self.full_dataset),
            'level_filtered': level_filter_count,
            'complexity_filtered': complexity_filter_count,
            'final_selected': len(stage_dataset),
            'selection_ratio': len(stage_dataset) / len(self.full_dataset),
            'target_levels': stage.dataset_levels,
            'complexity_range': stage.complexity_range,
            'level_distribution': level_stats,
            'complexity_distribution': complexity_stats
        }
        self.stage_statistics.append(stage_stats)
        
        self._log_debug(f"âœ… é˜¶æ®µ{self.current_stage}æ•°æ®é›†è¿‡æ»¤å®Œæˆ")
        self._log_debug(f"  - é€‰æ‹©æ¯”ä¾‹: {stage_stats['selection_ratio']:.1%}")
        self._log_debug(f"  - è¿‡æ»¤æ•ˆç‡: ç­‰çº§{level_filter_count/len(self.full_dataset)*100:.1f}% -> å¤æ‚åº¦{complexity_filter_count/level_filter_count*100:.1f}%")
        
        return stage_dataset

    def get_current_stage_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰é˜¶æ®µä¿¡æ¯ - å¢å¼ºè°ƒè¯•ç‰ˆæœ¬"""
        if self.current_stage >= len(self.curriculum_stages):
            return {
                'stage_index': self.current_stage,
                'stage_name': 'completed',
                'dataset_levels': 'all',
                'complexity_range': 'all',
                'is_completed': True,
                'debug_log_recent': self.debug_log[-10:],
                'advancement_stats': {
                    'total_checks': self.total_advancement_checks,
                    'attempts': self.advancement_attempts,
                    'successful': self.successful_advancements
                }
            }
        
        stage = self.curriculum_stages[self.current_stage]
        current_dataset = self.get_current_stage_dataset()
        
        return {
            'stage_index': self.current_stage,
            'stage_name': stage.name,
            'dataset_levels': stage.dataset_levels,
            'complexity_range': stage.complexity_range,
            'epochs_ratio': stage.epochs_ratio,
            'current_round': self.current_round,
            'completed_rounds': self.completed_rounds,
            'base_threshold': stage.performance_threshold,
            'current_threshold': self.get_current_threshold(),
            'performance_threshold': stage.performance_threshold,
            'current_evaluations': len(self.stage_performance_history),
            'min_evaluations': stage.min_evaluations,
            'dataset_size': len(current_dataset),
            'dataset_ratio': len(current_dataset) / len(self.full_dataset) if len(self.full_dataset) > 0 else 0,
            'is_completed': False,
            'debug_log_recent': self.debug_log[-10:],
            'advancement_stats': {
                'total_checks': self.total_advancement_checks,
                'attempts': self.advancement_attempts,
                'successful': self.successful_advancements
            }
        }

    def log_to_wandb(self, step: int):
        """è®°å½•åˆ°W&Bï¼ˆä½¿ç”¨æ•°å€¼è€Œéæ–‡å­—ï¼‰- å¢å¼ºè°ƒè¯•ç‰ˆæœ¬"""
        try:
            import wandb
            if not hasattr(wandb, 'run') or wandb.run is None:
                return
            
            current_info = self.get_current_stage_info()
            progress_info = self.get_curriculum_progress()
            
            # ğŸ”§ å¢å¼ºçš„W&Bæ•°æ®
            wandb_data = {
                'curriculum/current_stage_index': current_info['stage_index'],
                'curriculum/total_stages': progress_info['total_stages'],
                'curriculum/progress_ratio': progress_info['progress_ratio'],
                'curriculum/completed_stages_count': progress_info['completed_stages'],
                'curriculum/is_completed': float(current_info['is_completed']),
                'curriculum/debug_log_count': len(self.debug_log),
                'curriculum/advancement_checks': self.total_advancement_checks,
                'curriculum/advancement_attempts': self.advancement_attempts,
                'curriculum/successful_advancements': self.successful_advancements
            }
            
            # å½“å‰é˜¶æ®µè¯¦ç»†ä¿¡æ¯ï¼ˆæ•°å€¼ï¼‰
            if not current_info['is_completed']:
                wandb_data.update({
                    'curriculum/current_evaluations': current_info['current_evaluations'],
                    'curriculum/min_evaluations': current_info['min_evaluations'],
                    'curriculum/performance_threshold': current_info['performance_threshold'],
                    'curriculum/epochs_ratio': current_info['epochs_ratio'],
                    'curriculum/level_count': len(current_info['dataset_levels']),
                    'curriculum/complexity_min': current_info['complexity_range'][0],
                    'curriculum/complexity_max': current_info['complexity_range'][1],
                    'curriculum/dataset_size': current_info['dataset_size'],
                    'curriculum/dataset_ratio': current_info['dataset_ratio']
                })
            
            # æ€§èƒ½å†å²ç»Ÿè®¡
            if self.stage_performance_history:
                wandb_data.update({
                    'curriculum/stage_performance_mean': np.mean(self.stage_performance_history),
                    'curriculum/stage_performance_latest': self.stage_performance_history[-1],
                    'curriculum/stage_performance_std': np.std(self.stage_performance_history),
                    'curriculum/stage_performance_min': np.min(self.stage_performance_history),
                    'curriculum/stage_performance_max': np.max(self.stage_performance_history),
                    'curriculum/stage_performance_trend': np.mean(self.stage_performance_history[-3:]) if len(self.stage_performance_history) >= 3 else self.stage_performance_history[-1]
                })
            
            wandb.log(wandb_data, step=step)
            self._log_debug(f"ğŸ“Š W&BæŒ‡æ ‡å·²è®°å½• (æ­¥æ•°: {step}, æ•°æ®ç‚¹: {len(wandb_data)})")
            
        except ImportError:
            pass  # wandb not available
        except Exception as e:
            self._log_debug(f"âŒ W&Bè®°å½•å¤±è´¥: {e}")
    def get_curriculum_state(self) -> Dict[str, Any]:
        """è·å–è¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨çš„å½“å‰çŠ¶æ€ï¼Œç”¨äºä¿å­˜"""
        return {
            "current_stage": self.current_stage,
            "stage_performance_history": self.stage_performance_history,
            "all_stage_history": self.all_stage_history,
            "debug_log": self.debug_log[-50:],  # ä¿ç•™æœ€è¿‘50æ¡æ—¥å¿—
            "stage_statistics": self.stage_statistics
        }
    def get_curriculum_progress(self) -> Dict[str, Any]:
        """è·å–æ•´ä½“è¯¾ç¨‹è¿›åº¦"""
        total_stages = len(self.curriculum_stages)
        progress_ratio = (self.current_stage + 1) / total_stages if total_stages > 0 else 1.0
        
        return {
            'current_stage': self.current_stage,
            'total_stages': total_stages,
            'progress_ratio': progress_ratio,
            'completed_stages': len(self.all_stage_history),
            'stage_statistics': self.stage_statistics,
            'dataset_distribution': self.dataset_distribution,
            'all_stage_history': self.all_stage_history,
            'debug_summary': {
                'total_debug_entries': len(self.debug_log),
                'recent_entries': self.debug_log[-5:]  # æœ€è¿‘5æ¡
            }
        }
    def save_detailed_log(self, output_dir: str):
        """ä¿å­˜è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—åˆ°æ–‡ä»¶ - å¢å¼ºç‰ˆæœ¬"""
        log_file = os.path.join(output_dir, "curriculum_detailed_debug.json")
        
        detailed_data = {
            "curriculum_state": self.get_curriculum_state(),
            "progress_info": self.get_curriculum_progress(),
            "current_stage_info": self.get_current_stage_info(),
            "export_timestamp": datetime.now().isoformat(),
            "debug_summary": {
                "total_stages": len(self.curriculum_stages),
                "current_stage": self.current_stage,
                "stages_completed": len(self.all_stage_history),
                "total_debug_entries": len(self.debug_log),
                "advancement_stats": {
                    "total_checks": self.total_advancement_checks,
                    "attempts": self.advancement_attempts,
                    "successful": self.successful_advancements,
                    "success_rate": self.successful_advancements / max(1, self.advancement_attempts)
                }
            },
            "recent_debug_log": self.debug_log[-50:] if len(self.debug_log) > 50 else self.debug_log,
            "stage_statistics_detailed": self.stage_statistics
        }
        
        try:
            os.makedirs(output_dir, exist_ok=True)
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(detailed_data, f, indent=2, ensure_ascii=False)
            self._log_debug(f"ğŸ’¾ è¯¦ç»†è°ƒè¯•æ—¥å¿—å·²ä¿å­˜: {log_file}")
            
            # ğŸ”§ é¢å¤–ä¿å­˜ä¸€ä¸ªçº¯æ–‡æœ¬ç‰ˆæœ¬çš„è°ƒè¯•æ—¥å¿—
            text_log_file = os.path.join(output_dir, "curriculum_debug_text.log")
            with open(text_log_file, 'w', encoding='utf-8') as f:
                f.write(f"=== è¯¾ç¨‹å­¦ä¹ è°ƒè¯•æ—¥å¿— - {datetime.now()} ===\n\n")
                f.write(f"æ€»ä½“ç»Ÿè®¡:\n")
                f.write(f"  - å½“å‰é˜¶æ®µ: {self.current_stage}\n")
                f.write(f"  - è¿›é˜¶æ£€æŸ¥æ¬¡æ•°: {self.total_advancement_checks}\n")
                f.write(f"  - è¿›é˜¶å°è¯•æ¬¡æ•°: {self.advancement_attempts}\n")
                f.write(f"  - æˆåŠŸè¿›é˜¶æ¬¡æ•°: {self.successful_advancements}\n")
                f.write(f"  - è°ƒè¯•æ—¥å¿—æ¡æ•°: {len(self.debug_log)}\n\n")
                
                f.write("è¯¦ç»†è°ƒè¯•æ—¥å¿—:\n")
                f.write("="*50 + "\n")
                for entry in self.debug_log:
                    f.write(entry + "\n")
            
            self._log_debug(f"ğŸ“ æ–‡æœ¬è°ƒè¯•æ—¥å¿—å·²ä¿å­˜: {text_log_file}")
            
        except Exception as e:
            self._log_debug(f"âŒ ä¿å­˜è°ƒè¯•æ—¥å¿—å¤±è´¥: {e}")

    # ğŸ”§ æ–°å¢ï¼šå®šæœŸçŠ¶æ€æŠ¥å‘Šæ–¹æ³•
    def log_periodic_status(self, step: int = None):
        """å®šæœŸè®°å½•è¯¾ç¨‹å­¦ä¹ çŠ¶æ€"""
        self._log_debug(f"ğŸ“Š å®šæœŸçŠ¶æ€æŠ¥å‘Š (æ­¥æ•°: {step if step else 'N/A'})")
        
        current_info = self.get_current_stage_info()
        
        self._log_debug(f"  - å½“å‰é˜¶æ®µ: {current_info['stage_index']} ({current_info['stage_name']})")
        if not current_info['is_completed']:
            self._log_debug(f"  - æ•°æ®é›†: {current_info['dataset_size']} æ ·æœ¬ ({current_info['dataset_ratio']:.1%})")
            self._log_debug(f"  - è¯„ä¼°è¿›åº¦: {current_info['current_evaluations']}/{current_info['min_evaluations']}")
            self._log_debug(f"  - æ€§èƒ½é˜ˆå€¼: {current_info['performance_threshold']}")
        
        self._log_debug(f"  - è¿›é˜¶ç»Ÿè®¡: {self.successful_advancements}/{self.advancement_attempts} æˆåŠŸ")
        
        if self.stage_performance_history:
            recent_perf = self.stage_performance_history[-min(3, len(self.stage_performance_history)):]
            self._log_debug(f"  - æœ€è¿‘æ€§èƒ½: {[f'{p:.3f}' for p in recent_perf]}")

    # ğŸ”§ æ–°å¢ï¼šå¼ºåˆ¶è°ƒè¯•è¾“å‡ºæ–¹æ³•
    def force_debug_output(self):
        """å¼ºåˆ¶è¾“å‡ºå½“å‰æ‰€æœ‰è°ƒè¯•ä¿¡æ¯"""
        self._log_debug("ğŸ”§ å¼ºåˆ¶è°ƒè¯•è¾“å‡ºå¼€å§‹")
        self._log_debug(f"ğŸ“Š è°ƒè¯•ç»Ÿè®¡: {len(self.debug_log)} æ¡æ—¥å¿—")
        
        # è¾“å‡ºæœ€è¿‘çš„è°ƒè¯•æ—¥å¿—
        recent_logs = self.debug_log[-20:] if len(self.debug_log) > 20 else self.debug_log
        self._log_debug(f"ğŸ“ æœ€è¿‘{len(recent_logs)}æ¡è°ƒè¯•æ—¥å¿—:")
        for i, entry in enumerate(recent_logs, 1):
            self._log_debug(f"  {i:2d}. {entry}")
        
        # è¾“å‡ºå½“å‰çŠ¶æ€
        self.log_periodic_status()
        
        self._log_debug("ğŸ”§ å¼ºåˆ¶è°ƒè¯•è¾“å‡ºç»“æŸ")

    def _initialize_stage_tracker(self):
        """åˆå§‹åŒ–é˜¶æ®µè®­ç»ƒè·Ÿè¸ª"""
        if self.current_stage < len(self.curriculum_stages):
            stage = self.curriculum_stages[self.current_stage]
            current_dataset = self.get_current_stage_dataset()
            self.stage_dataset_size = len(current_dataset)
            
            # è®¡ç®—è¯¥é˜¶æ®µéœ€è¦çš„æœ€å°‘æ­¥æ•°
            min_steps = getattr(stage, 'min_steps_per_epoch', 10)
            require_full_epoch = getattr(stage, 'require_full_epoch', True)
            
            if require_full_epoch:
                # è®¡ç®—å®Œæ•´è®­ç»ƒä¸€ééœ€è¦çš„æ­¥æ•°ï¼ˆå‡è®¾batch_size=1ï¼‰
                estimated_steps_per_epoch = max(self.stage_dataset_size, min_steps)
            else:
                estimated_steps_per_epoch = min_steps
            
            self.stage_training_tracker = {
                'stage_name': stage.name,
                'stage_index': self.current_stage,
                'dataset_size': self.stage_dataset_size,
                'require_full_epoch': require_full_epoch,
                'min_steps_per_epoch': min_steps,
                'estimated_steps_per_epoch': estimated_steps_per_epoch,
                'target_epochs': 1 if require_full_epoch else 0,
                'steps_completed': 0,
                'epochs_completed': 0,
                'start_step': self.current_stage_start_step,
                'is_epoch_requirement_met': False
            }
            
            self._log_debug(f"ğŸ”§ åˆå§‹åŒ–é˜¶æ®µ{self.current_stage}è®­ç»ƒè·Ÿè¸ª:")
            self._log_debug(f"  - é˜¶æ®µåç§°: {stage.name}")
            self._log_debug(f"  - æ•°æ®é›†å¤§å°: {self.stage_dataset_size}")
            self._log_debug(f"  - è¦æ±‚å®Œæ•´epoch: {require_full_epoch}")
            self._log_debug(f"  - é¢„ä¼°æ¯epochæ­¥æ•°: {estimated_steps_per_epoch}")
            self._log_debug(f"  - æœ€å°æ­¥æ•°è¦æ±‚: {min_steps}")
        else:
            self.stage_training_tracker = {}

    def update_training_progress(self, current_step: int):
        """æ›´æ–°è®­ç»ƒè¿›åº¦"""
        if not self.stage_training_tracker:
            return
            
        # è®¡ç®—å½“å‰é˜¶æ®µå·²å®Œæˆçš„æ­¥æ•°
        steps_in_stage = current_step - self.stage_training_tracker['start_step']
        self.stage_training_tracker['steps_completed'] = steps_in_stage
        
        # è®¡ç®—å®Œæˆçš„epochæ•°
        estimated_steps_per_epoch = self.stage_training_tracker['estimated_steps_per_epoch']
        if estimated_steps_per_epoch > 0:
            epochs_completed = steps_in_stage / estimated_steps_per_epoch
            self.stage_training_tracker['epochs_completed'] = epochs_completed
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³å®Œæ•´epochè¦æ±‚
            require_full_epoch = self.stage_training_tracker['require_full_epoch']
            target_epochs = self.stage_training_tracker['target_epochs']
            
            if require_full_epoch:
                self.stage_training_tracker['is_epoch_requirement_met'] = epochs_completed >= target_epochs
            else:
                # å¦‚æœä¸è¦æ±‚å®Œæ•´epochï¼Œåªè¦è¾¾åˆ°æœ€å°æ­¥æ•°å³å¯
                min_steps = self.stage_training_tracker['min_steps_per_epoch']
                self.stage_training_tracker['is_epoch_requirement_met'] = steps_in_stage >= min_steps
        
        # æ¯50æ­¥è®°å½•ä¸€æ¬¡è¿›åº¦
        if steps_in_stage % 50 == 0 and steps_in_stage > 0:
            self._log_training_progress()

    def _log_training_progress(self):
        """è®°å½•è®­ç»ƒè¿›åº¦"""
        if not self.stage_training_tracker:
            return
            
        tracker = self.stage_training_tracker
        stage_name = tracker['stage_name']
        steps_completed = tracker['steps_completed']
        epochs_completed = tracker['epochs_completed']
        is_met = tracker['is_epoch_requirement_met']
        
        self._log_debug(f"ğŸ“ˆ é˜¶æ®µ{stage_name}è®­ç»ƒè¿›åº¦:")
        self._log_debug(f"  - å·²å®Œæˆæ­¥æ•°: {steps_completed}")
        self._log_debug(f"  - å·²å®Œæˆepoch: {epochs_completed:.2f}")
        self._log_debug(f"  - epochè¦æ±‚æ»¡è¶³: {is_met}")
        
        if tracker['require_full_epoch']:
            progress_percent = min(100, epochs_completed * 100)
            self._log_debug(f"  - å®Œæ•´è®­ç»ƒè¿›åº¦: {progress_percent:.1f}%")

    def is_stage_training_complete(self) -> bool:
        """æ£€æŸ¥å½“å‰é˜¶æ®µæ˜¯å¦å®Œæˆäº†å®Œæ•´è®­ç»ƒè¦æ±‚"""
        if not self.stage_training_tracker:
            return True  # å¦‚æœæ²¡æœ‰è·Ÿè¸ªå™¨ï¼Œè®¤ä¸ºå·²å®Œæˆ
            
        return self.stage_training_tracker.get('is_epoch_requirement_met', False)

    def get_stage_training_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰é˜¶æ®µè®­ç»ƒçŠ¶æ€"""
        if not self.stage_training_tracker:
            return {'status': 'no_tracker', 'complete': True}
            
        tracker = self.stage_training_tracker
        return {
            'stage_name': tracker['stage_name'],
            'stage_index': tracker['stage_index'],
            'dataset_size': tracker['dataset_size'],
            'steps_completed': tracker['steps_completed'],
            'epochs_completed': tracker['epochs_completed'],
            'require_full_epoch': tracker['require_full_epoch'],
            'is_epoch_requirement_met': tracker['is_epoch_requirement_met'],
            'estimated_steps_per_epoch': tracker['estimated_steps_per_epoch'],
            'progress_percent': min(100, tracker['epochs_completed'] * 100) if tracker['require_full_epoch'] else 100
        }

    def update_stage_start_step(self, current_step: int):
        """æ›´æ–°å½“å‰é˜¶æ®µå¼€å§‹æ­¥æ•° - ç”¨äºé˜¶æ®µè¿›é˜¶æ—¶é‡ç½®æ­¥æ•°è®¡æ•°"""
        self.current_stage_start_step = current_step
        if self.stage_training_tracker:
            self.stage_training_tracker['start_step'] = current_step
            # é‡ç½®æ­¥æ•°å’Œepochè®¡æ•°
            self.stage_training_tracker['steps_completed'] = 0
            self.stage_training_tracker['epochs_completed'] = 0
            self.stage_training_tracker['is_epoch_requirement_met'] = False
            
        self._log_debug(f"ğŸ”§ æ›´æ–°é˜¶æ®µå¼€å§‹æ­¥æ•°: {current_step}")
        self._log_debug(f"  - é‡ç½®è®­ç»ƒè¿›åº¦è·Ÿè¸ªå™¨")

    def get_stage_advancement_requirements(self) -> Dict[str, Any]:
        """è·å–å½“å‰é˜¶æ®µçš„è¿›é˜¶è¦æ±‚"""
        if self.current_stage >= len(self.curriculum_stages):
            return {'stage_completed': True, 'requirements': []}
            
        stage = self.curriculum_stages[self.current_stage]
        training_status = self.get_stage_training_status()
        current_threshold = self.get_current_threshold()
        
        requirements = []
        
        # æ€§èƒ½è¦æ±‚
        recent_performance = np.mean(self.stage_performance_history[-2:]) if len(self.stage_performance_history) >= 2 else 0
        performance_met = recent_performance >= current_threshold
        requirements.append({
            'type': 'performance',
            'description': f'å¹³å‡æ€§èƒ½è¾¾åˆ° {current_threshold:.3f}',
            'current': recent_performance,
            'target': current_threshold,
            'met': performance_met
        })
        
        # è¯„ä¼°æ¬¡æ•°è¦æ±‚
        eval_count_met = len(self.stage_performance_history) >= stage.min_evaluations
        requirements.append({
            'type': 'evaluations',
            'description': f'å®Œæˆè‡³å°‘ {stage.min_evaluations} æ¬¡è¯„ä¼°',
            'current': len(self.stage_performance_history),
            'target': stage.min_evaluations,
            'met': eval_count_met
        })
        
        # å®Œæ•´è®­ç»ƒè¦æ±‚
        training_complete = self.is_stage_training_complete()
        if training_status.get('require_full_epoch', False):
            requirements.append({
                'type': 'full_training',
                'description': 'å®Œæˆè‡³å°‘1ä¸ªå®Œæ•´epochçš„è®­ç»ƒ',
                'current': training_status.get('epochs_completed', 0),
                'target': 1.0,
                'met': training_complete,
                'progress_percent': training_status.get('progress_percent', 0)
            })
        
        all_met = all(req['met'] for req in requirements)
        
        return {
            'stage_name': stage.name,
            'stage_index': self.current_stage,
            'can_advance': all_met,
            'requirements': requirements,
            'training_status': training_status
        }


# Moved from train.py (setup_curriculum_manager)
# This function sets up EnhancedCurriculumManager, not FixedEnhancedCurriculumManager.
# We might need to reconcile this with setup_fixed_curriculum_manager.
def setup_enhanced_curriculum_manager(script_cfg: ScriptConfig, dataset: Dataset) -> Optional[EnhancedCurriculumManager]:
    if not script_cfg.enable_curriculum: # type: ignore
        logger.info("Curriculum learning disabled via script_cfg.")
        return None
    # ... (Logic from train.py setup_curriculum_manager, using create_custom_curriculum_stages or create_default_curriculum_stages)
    # This logic needs access to create_custom_curriculum_stages and create_default_curriculum_stages from .stages
    logger.info("Setting up EnhancedCurriculumManager...")
    # Placeholder logic:
    stages = create_default_curriculum_stages() # from .stages
    return EnhancedCurriculumManager(stages, dataset)


# Moved from curriculum_debug_config.py
def setup_fixed_curriculum_manager(script_cfg: ScriptConfig, dataset: Dataset) -> Optional[FixedEnhancedCurriculumManager]:
    if not script_cfg.enable_curriculum: # type: ignore
        logger.info("ğŸ“š Curriculum learning (fixed manager) is disabled.")
        return None
    # ... (Logic from curriculum_debug_config.py setup_fixed_curriculum_manager)
    # This logic needs access to create_fixed_curriculum_stages (if that's also moved/created) or other stage creation logic
    # logger.info("Setting up FixedEnhancedCurriculumManager...") # Original log
    # Placeholder logic:
    # stages = create_fixed_curriculum_stages() # This function would also need to be defined/moved
    # stages = create_default_curriculum_stages() # Using default for now as create_fixed_curriculum_stages is not in scope
    # return FixedEnhancedCurriculumManager(stages, dataset) # Original return

    # MODIFIED function:
    if not script_cfg.enable_curriculum:  # type: ignore
        logger.info("ğŸ“š Curriculum learning (fixed manager) is disabled by script_cfg.")
        return None

    logger.info("âš™ï¸ Setting up FixedEnhancedCurriculumManager...")
    stages: List[CurriculumStageConfig] = []

    # Priority 1: Use script_cfg.curriculum_stages if provided
    if hasattr(script_cfg, 'curriculum_stages') and script_cfg.curriculum_stages: # type: ignore
        logger.info("Found curriculum_stages in script_cfg. Attempting to use them.")
        try:
            for stage_dict in script_cfg.curriculum_stages: # type: ignore
                # Ensure all required fields for CurriculumStageConfig are present or have defaults
                config = CurriculumStageConfig(
                    name=stage_dict.get('name', 'Unnamed Stage'),
                    dataset_levels=stage_dict.get('dataset_levels', []),
                    complexity_range=tuple(stage_dict.get('complexity_range', (0.0, 10.0))), # Ensure it's a tuple
                    epochs_ratio=stage_dict.get('epochs_ratio', 0.1), # Default ratio if missing
                    performance_threshold=stage_dict.get('performance_threshold', 0.6),
                    min_evaluations=stage_dict.get('min_evaluations', 5),
                    description=stage_dict.get('description', '')
                )
                stages.append(config)
            if stages:
                 logger.info(f"âœ… Successfully loaded {len(stages)} stages from script_cfg.curriculum_stages.")
            else:
                logger.warning("âš ï¸ script_cfg.curriculum_stages was provided but resulted in zero stages. Check configuration.")
        except Exception as e:
            logger.error(f"âŒ Error processing script_cfg.curriculum_stages: {e}. Falling back.")
            stages = [] # Reset stages if parsing failed

    # Priority 2: Use create_custom_curriculum_stages
    if not stages: # If stages were not loaded from script_cfg.curriculum_stages
        logger.info("No stages from script_cfg.curriculum_stages or loading failed. Trying create_custom_curriculum_stages...")
        try:
            # Calculate dataset_distribution - using the static helper method
            # Pass logger.info for optional logging within the method if needed, or handle logging outside.
            dataset_dist = FixedEnhancedCurriculumManager._calculate_dataset_distribution(dataset, logger.info)

            if not dataset_dist or not dataset_dist.get('total_samples'):
                logger.warning("âš ï¸ Dataset distribution analysis resulted in no samples. Cannot create custom stages effectively.")
            else:
                # Ensure all expected attributes exist on script_cfg or provide defaults
                custom_stages_params = {
                    "dataset_distribution": dataset_dist,
                    "focus_levels": getattr(script_cfg, 'curriculum_focus_levels', None), # type: ignore
                    "complexity_emphasis": getattr(script_cfg, 'curriculum_complexity_emphasis', None) # type: ignore
                }
                logger.info(f"Parameters for create_custom_curriculum_stages: focus_levels={custom_stages_params['focus_levels']}, emphasis={custom_stages_params['complexity_emphasis']}")
                stages = create_custom_curriculum_stages(**custom_stages_params) # from .stages

            if stages:
                logger.info(f"âœ… Successfully created {len(stages)} custom stages.")
            else:
                logger.warning("âš ï¸ create_custom_curriculum_stages resulted in zero stages.")
        except Exception as e:
            logger.error(f"âŒ Error calling create_custom_curriculum_stages: {e}. Falling back to default.")
            stages = [] # Reset stages

    # Priority 3: Fallback to create_default_curriculum_stages
    if not stages:
        logger.info("No stages from custom creation or it failed. Falling back to create_default_curriculum_stages.")
        try:
            # ğŸ”§ NEW: ä¼ é€’ScriptConfigä¸­çš„é˜ˆå€¼å‚æ•°åˆ°create_default_curriculum_stages
            performance_thresholds = []
            for i in range(1, 6):
                threshold_attr = f"curriculum_performance_threshold_{i}"
                if hasattr(script_cfg, threshold_attr):
                    threshold_value = getattr(script_cfg, threshold_attr)
                    if threshold_value is not None:
                        performance_thresholds.append(threshold_value)
                        logger.info(f"ğŸ“Š ä»ScriptConfigè¯»å–é˜ˆå€¼: {threshold_attr}={threshold_value}")
            
            min_evaluations = 5  # é»˜è®¤å€¼
            if hasattr(script_cfg, 'curriculum_min_evaluations') and script_cfg.curriculum_min_evaluations is not None:
                min_evaluations = script_cfg.curriculum_min_evaluations
                logger.info(f"ğŸ“Š ä»ScriptConfigè¯»å–æœ€å°è¯„ä¼°æ¬¡æ•°: curriculum_min_evaluations={min_evaluations}")
            
            # å¦‚æœä»ScriptConfigä¸­è·å–äº†å®Œæ•´çš„é˜ˆå€¼ï¼Œå°±ä½¿ç”¨å®ƒä»¬
            if len(performance_thresholds) >= 5:
                stages = create_default_curriculum_stages(
                    performance_thresholds=performance_thresholds[:5],
                    min_evaluations=min_evaluations
                )
                logger.info(f"âœ… ä½¿ç”¨ScriptConfigä¸­çš„é˜ˆå€¼åˆ›å»ºè¯¾ç¨‹é˜¶æ®µ: {performance_thresholds[:5]}")
            else:
                # å¦åˆ™ä½¿ç”¨é»˜è®¤çš„ï¼Œä½†ä»ç„¶ä¼ é€’ç¯å¢ƒå˜é‡æˆ–å…¶ä»–å¯ç”¨çš„å‚æ•°
                stages = create_default_curriculum_stages(min_evaluations=min_evaluations)
                logger.info(f"âœ… ä½¿ç”¨é»˜è®¤é˜ˆå€¼åˆ›å»ºè¯¾ç¨‹é˜¶æ®µï¼ˆæœ€å°è¯„ä¼°æ¬¡æ•°: {min_evaluations}ï¼‰")
            
            if stages:
                logger.info(f"âœ… Successfully created {len(stages)} default stages.")
            else:
                logger.error("âŒ create_default_curriculum_stages also resulted in zero stages! This is problematic.")
                return None # Cannot proceed without stages
        except Exception as e:
            logger.error(f"âŒ Error calling create_default_curriculum_stages: {e}.")
            return None # Cannot proceed if default stage creation fails

    if not stages:
        logger.error("ğŸš« Failed to create or load any curriculum stages. Cannot initialize FixedEnhancedCurriculumManager.")
        return None

    # Apply environment variable overrides
    # For these environment variables to take effect, ensure they are `export`ed in your shell script (e.g., `export CURRICULUM_PERFORMANCE_THRESHOLD_1=0.75`).
    if stages: # Ensure there are stages to process
        logger.info(f"âš™ï¸ Checking for environment variable overrides for {len(stages)} stages...")
        for i, stage_config in enumerate(stages):
            stage_index = i + 1 # Environment variables are 1-indexed

            # Check for performance_threshold override
            env_threshold_str = os.environ.get(f"CURRICULUM_PERFORMANCE_THRESHOLD_{stage_index}")
            if env_threshold_str:
                try:
                    env_threshold_val = float(env_threshold_str)
                    original_threshold = stage_config.performance_threshold
                    if abs(original_threshold - env_threshold_val) > 1e-6: # Check if different to avoid unnecessary logs
                        logger.info(f"Applying ENV override for STAGE {stage_index} ('{stage_config.name}'): " \
                                     f"CURRICULUM_PERFORMANCE_THRESHOLD_{stage_index}='{env_threshold_str}'. " \
                                     f"Changing performance_threshold from {original_threshold:.4f} to {env_threshold_val:.4f}.")
                        stage_config.performance_threshold = env_threshold_val
                    else:
                        logger.info(f"ENV CURRICULUM_PERFORMANCE_THRESHOLD_{stage_index} ('{env_threshold_str}') matches existing threshold for STAGE {stage_index} ('{stage_config.name}'). No change.")
                except ValueError:
                    logger.warning(f"Invalid value for CURRICULUM_PERFORMANCE_THRESHOLD_{stage_index}: '{env_threshold_str}'. Must be a float. Ignoring.")

            # Check for min_evaluations override
            env_min_eval_str = os.environ.get(f"CURRICULUM_MIN_EVALUATIONS_{stage_index}") # Corrected typo
            if env_min_eval_str: # Check if not None and not empty
                try:
                    env_min_eval_val = int(env_min_eval_str)
                    original_min_eval = stage_config.min_evaluations
                    if original_min_eval != env_min_eval_val:
                        logger.info(f"Applying ENV override for STAGE {stage_index} ('{stage_config.name}'): " \
                                     f"CURRICULUM_MIN_EVALUATIONS_{stage_index}='{env_min_eval_str}'. " \
                                     f"Changing min_evaluations from {original_min_eval} to {env_min_eval_val}.")
                        stage_config.min_evaluations = env_min_eval_val
                    else:
                        logger.info(f"ENV CURRICULUM_MIN_EVALUATIONS_{stage_index} ('{env_min_eval_str}') matches existing min_evaluations for STAGE {stage_index} ('{stage_config.name}'). No change.")
                except ValueError:
                    logger.warning(f"Invalid value for CURRICULUM_MIN_EVALUATIONS_{stage_index}: '{env_min_eval_str}'. Must be an integer. Ignoring.")
    else:
        logger.info("No stages were populated, skipping environment variable override check.")

    logger.info(f"ğŸ Initializing FixedEnhancedCurriculumManager with {len(stages)} stages.")
    # Note: The user should be informed that for these environment variables to take effect,
    # they must be `export`ed in their shell script (e.g., `export CURRICULUM_PERFORMANCE_THRESHOLD_1=0.75`).
    # This guidance is included as a comment above and should be part of the commit message or user documentation.
    return FixedEnhancedCurriculumManager(stages, dataset)
