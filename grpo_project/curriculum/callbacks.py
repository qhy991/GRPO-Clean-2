# grpo_project/curriculum/callbacks.py - ä¿®å¤ç‰ˆæœ¬
import logging
import os
import json
from datetime import datetime
from typing import Optional, Dict, Any, TYPE_CHECKING, List
import numpy as np

from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl, DefaultFlowCallback

# Attempt to import from grpo_project
try:
    from grpo_project.callbacks.base import BaseCallback
    from .manager import EnhancedCurriculumManager, FixedEnhancedCurriculumManager
except ImportError:
    logger_init = logging.getLogger(__name__)
    logger_init.warning("Callbacks.curriculum: Could not import from grpo_project. Using placeholders.")
    from transformers import TrainerCallback as BaseCallback
    class EnhancedCurriculumManager: pass
    class FixedEnhancedCurriculumManager: pass

if TYPE_CHECKING:
    from transformers import Trainer

logger = logging.getLogger(__name__)

class CurriculumProgressCallback(TrainerCallback):
    """å¢å¼ºçš„è¯¾ç¨‹å­¦ä¹ è¿›åº¦å›è°ƒï¼Œäº§ç”Ÿè¯¦ç»†çš„è°ƒè¯•æ—¥å¿—"""
    
    def __init__(self, curriculum_manager, trainer_ref: Optional['Trainer'] = None, output_dir: Optional[str] = None, 
                 performance_check_interval: int = 25):
        self.curriculum_manager = curriculum_manager
        self.trainer_ref = trainer_ref
        self.output_dir = output_dir
        self.performance_check_interval = performance_check_interval  # æ–°å¢ï¼šå¯é…ç½®çš„æ£€æŸ¥é—´éš”
        self.debug_log_path = os.path.join(output_dir, "curriculum_progress_debug.txt") if output_dir else "curriculum_progress_debug.txt"
        self.last_locally_logged_stage_idx: int = -1
        self.evaluation_count = 0
        self.last_performance_check_step = 0
        self.performance_history = []  # å­˜å‚¨æ€§èƒ½å†å²
        self.step_count_in_current_stage = 0  # å½“å‰é˜¶æ®µçš„æ­¥æ•°è®¡æ•°
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if self.output_dir:
            os.makedirs(self.output_dir, exist_ok=True)
            with open(self.debug_log_path, 'w', encoding='utf-8') as f:
                f.write(f"=== CurriculumProgressCallback Debug Log - {datetime.now()} ===\n")
                f.write(f"åˆå§‹åŒ–è¯¾ç¨‹å­¦ä¹ è°ƒè¯•å›è°ƒ\n")
                f.write(f"è°ƒè¯•æ—¥å¿—è·¯å¾„: {self.debug_log_path}\n")
                f.write(f"è¾“å‡ºç›®å½•: {self.output_dir}\n")
                f.write(f"æ€§èƒ½æ£€æŸ¥é—´éš”: æ¯{self.performance_check_interval}æ­¥\n")  # æ–°å¢æ—¥å¿—
                f.write("="*80 + "\n")
        
        logger.info(f"âœ… CurriculumProgressCallback initialized. Debug log: {self.debug_log_path}, Check interval: {self.performance_check_interval} steps")

    def _write_debug(self, message: str):
        """å†™å…¥è°ƒè¯•ä¿¡æ¯åˆ°ä¸“ç”¨æ–‡ä»¶å’Œæ§åˆ¶å°"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        debug_msg = f"[{timestamp}] CURRICULUM: {message}"
        
        # æ§åˆ¶å°è¾“å‡º
        logger.info(debug_msg)
        
        # å†™å…¥è°ƒè¯•æ–‡ä»¶
        try:
            with open(self.debug_log_path, 'a', encoding='utf-8') as f:
                f.write(debug_msg + "\n")
        except Exception as e:
            logger.warning(f"Failed to write debug log: {e}")

    def _calculate_performance_from_logs(self, logs: Optional[Dict[str, float]]) -> float:
        """ä»æ—¥å¿—ä¸­è®¡ç®—æ€§èƒ½æŒ‡æ ‡ - ä¿®å¤ç‰ˆæœ¬"""
        if not logs:
            return 0.0
            
        # 1. ä¼˜å…ˆä½¿ç”¨è¯„ä¼°æŒ‡æ ‡
        if 'eval_avg_test_pass_rate' in logs:
            performance = logs['eval_avg_test_pass_rate']
            self._write_debug(f"ğŸ“Š ä½¿ç”¨è¯„ä¼°æŒ‡æ ‡ eval_avg_test_pass_rate: {performance:.4f}")
            return performance
            
        # 2. ä½¿ç”¨rewardæŒ‡æ ‡ (GRPOè®­ç»ƒçš„æ ¸å¿ƒæŒ‡æ ‡)
        if 'reward' in logs:
            reward = logs['reward']
            # å°†rewardè½¬æ¢ä¸ºæ€§èƒ½åˆ†æ•° (å‡è®¾reward > 0 è¡¨ç¤ºå¥½çš„æ€§èƒ½)
            # ä½¿ç”¨sigmoidå‡½æ•°å°†rewardæ˜ å°„åˆ°[0,1]èŒƒå›´
            performance = 1.0 / (1.0 + np.exp(-max(0, reward / 5.0)))  # ç¼“å’Œçš„sigmoid
            self._write_debug(f"ğŸ“Š ä½¿ç”¨rewardæŒ‡æ ‡è½¬æ¢: reward={reward:.4f} -> performance={performance:.4f}")
            return performance
            
        # 3. ä½¿ç”¨æŸå¤±æŒ‡æ ‡è½¬æ¢
        if 'loss' in logs:
            loss = logs['loss']
            # å°†lossè½¬æ¢ä¸ºæ€§èƒ½åˆ†æ•° (lossè¶Šå°ï¼Œæ€§èƒ½è¶Šå¥½)
            performance = max(0.0, 1.0 - min(loss, 1.0))
            self._write_debug(f"ğŸ“Š ä½¿ç”¨lossæŒ‡æ ‡è½¬æ¢: loss={loss:.4f} -> performance={performance:.4f}")
            return performance
            
        if 'train_loss' in logs:
            loss = logs['train_loss']
            performance = max(0.0, 1.0 - min(loss, 1.0))
            self._write_debug(f"ğŸ“Š ä½¿ç”¨train_lossæŒ‡æ ‡è½¬æ¢: loss={loss:.4f} -> performance={performance:.4f}")
            return performance
            
        self._write_debug("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„æ€§èƒ½æŒ‡æ ‡ï¼Œè¿”å›é»˜è®¤å€¼ 0.0")
        return 0.0

    def on_train_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """è®­ç»ƒå¼€å§‹æ—¶çš„è¯¦ç»†æ—¥å¿—"""
        if not self.curriculum_manager:
            return
            
        self._write_debug("ğŸš€ è®­ç»ƒå¼€å§‹ - è¯¾ç¨‹å­¦ä¹ çŠ¶æ€åˆå§‹åŒ–")
        
        current_stage_idx = self.curriculum_manager.current_stage
        total_stages = len(self.curriculum_manager.curriculum_stages)
        
        self._write_debug(f"ğŸ“Š è¯¾ç¨‹å­¦ä¹ æ€»è§ˆ:")
        self._write_debug(f"  - æ€»é˜¶æ®µæ•°: {total_stages}")
        self._write_debug(f"  - å½“å‰é˜¶æ®µç´¢å¼•: {current_stage_idx}")
        
        # è¯¦ç»†è®°å½•æ¯ä¸ªé˜¶æ®µä¿¡æ¯
        for i, stage in enumerate(self.curriculum_manager.curriculum_stages):
            status = "ğŸ”„ å½“å‰" if i == current_stage_idx else "â³ å¾…è¿›å…¥" if i > current_stage_idx else "âœ… å·²å®Œæˆ"
            self._write_debug(f"  é˜¶æ®µ{i}: {stage.name} | {status}")
            self._write_debug(f"    - ç­‰çº§: {stage.dataset_levels}")
            self._write_debug(f"    - å¤æ‚åº¦èŒƒå›´: {stage.complexity_range}")
            self._write_debug(f"    - æ€§èƒ½é˜ˆå€¼: {stage.performance_threshold}")
            self._write_debug(f"    - æœ€å°è¯„ä¼°æ¬¡æ•°: {stage.min_evaluations}")
        
        # å½“å‰é˜¶æ®µè¯¦ç»†ä¿¡æ¯
        if current_stage_idx < total_stages:
            current_stage = self.curriculum_manager.curriculum_stages[current_stage_idx]
            current_dataset = self.curriculum_manager.get_current_stage_dataset()
            
            self._write_debug(f"ğŸ¯ å½“å‰é˜¶æ®µè¯¦æƒ…:")
            self._write_debug(f"  - é˜¶æ®µåç§°: {current_stage.name}")
            self._write_debug(f"  - æ•°æ®é›†å¤§å°: {len(current_dataset)}")
            self._write_debug(f"  - ç›®æ ‡ç­‰çº§: {current_stage.dataset_levels}")
            self._write_debug(f"  - å¤æ‚åº¦èŒƒå›´: {current_stage.complexity_range}")
            self._write_debug(f"  - éœ€è¦è¾¾åˆ°æ€§èƒ½: {current_stage.performance_threshold}")

    def on_step_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """æ¯æ­¥å¼€å§‹æ—¶çš„ç›‘æ§"""
        if not self.curriculum_manager:
            return
            
        current_step = getattr(state, 'global_step', 0) or 0
        
        # æ¯50æ­¥è¯¦ç»†è®°å½•ä¸€æ¬¡çŠ¶æ€
        if current_step % 50 == 0 and current_step > 0:
            self._detailed_status_log(current_step, state)

    def on_step_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """æ¯æ­¥ç»“æŸæ—¶çš„ç›‘æ§"""
        if not self.curriculum_manager:
            return
            
        current_step = getattr(state, 'global_step', 0) or 0
        
        # æ¯10æ­¥æ£€æŸ¥ä¸€æ¬¡åŸºæœ¬çŠ¶æ€
        if current_step % 10 == 0:
            self._basic_status_check(current_step, state)

    def on_evaluate(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """è¯„ä¼°æ—¶çš„è¯¦ç»†å¤„ç† - ä¿®å¤ç‰ˆæœ¬"""
        if not self.curriculum_manager or args.local_rank > 0:
            return
            
        current_step = getattr(state, 'global_step', 0) or 0
        self.evaluation_count += 1
        current_stage_idx = self.curriculum_manager.current_stage
        
        self._write_debug(f"ğŸ“ˆ ç¬¬{self.evaluation_count}æ¬¡è¯„ä¼° (æ­¥æ•°: {current_step})")
        
        # ä»æœ€æ–°çš„æ—¥å¿—æ¡ç›®ä¸­è·å–æ€§èƒ½
        performance_estimate = 0.0
        if state.log_history:
            latest_logs = state.log_history[-1]
            performance_estimate = self._calculate_performance_from_logs(latest_logs)
        
        # è®°å½•åˆ°æ€§èƒ½å†å² - ä¿®å¤ï¼šç¡®ä¿åŒ…å«stageä¿¡æ¯
        self.performance_history.append({
            'step': current_step,
            'performance': performance_estimate,
            'stage': current_stage_idx,  # ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šstage
            'timestamp': datetime.now().isoformat()
        })
        
        self._write_debug(f"ğŸ“Š è¯„ä¼°è¯¦æƒ…:")
        self._write_debug(f"  - å½“å‰é˜¶æ®µ: {current_stage_idx}")
        self._write_debug(f"  - æ€§èƒ½ä¼°è®¡: {performance_estimate:.4f}")
        
        if current_stage_idx < len(self.curriculum_manager.curriculum_stages):
            stage_config = self.curriculum_manager.curriculum_stages[current_stage_idx]
            threshold = stage_config.performance_threshold
            min_evals = stage_config.min_evaluations
            
            self._write_debug(f"  - é˜¶æ®µåç§°: {stage_config.name}")
            self._write_debug(f"  - æ€§èƒ½é˜ˆå€¼: {threshold}")
            self._write_debug(f"  - æœ€å°è¯„ä¼°æ¬¡æ•°è¦æ±‚: {min_evals}")
            self._write_debug(f"  - å½“å‰é˜¶æ®µè¯„ä¼°å†å²é•¿åº¦: {len(self.performance_history)}")
            
            # æ£€æŸ¥è¿›é˜¶æ¡ä»¶
            self._check_and_advance_stage(performance_estimate, current_step)

    def _check_and_advance_stage(self, current_performance: float, current_step: int):
        """æ£€æŸ¥å¹¶æ‰§è¡Œé˜¶æ®µè¿›é˜¶ - ä¿®å¤ç‰ˆæœ¬"""
        current_stage_idx = self.curriculum_manager.current_stage
        
        if current_stage_idx >= len(self.curriculum_manager.curriculum_stages):
            return  # å·²å®Œæˆæ‰€æœ‰é˜¶æ®µ
            
        stage_config = self.curriculum_manager.curriculum_stages[current_stage_idx]
        
        # è·å–å½“å‰é˜¶æ®µçš„æ€§èƒ½å†å² - ä¿®å¤ï¼šæ­£ç¡®è¿‡æ»¤stage
        stage_performances = [p['performance'] for p in self.performance_history 
                            if p.get('stage') == current_stage_idx]  # ä¿®å¤ï¼šä½¿ç”¨ == è€Œä¸æ˜¯é»˜è®¤å€¼
        
        self._write_debug(f"ğŸ“Š å½“å‰é˜¶æ®µæ€§èƒ½å†å²: {len(stage_performances)} æ¡è®°å½•")
        
        if len(stage_performances) >= stage_config.min_evaluations:
            recent_performances = stage_performances[-min(3, len(stage_performances)):]
            avg_recent_performance = np.mean(recent_performances)
            
            self._write_debug(f"ğŸ“Š è¿›é˜¶æ¡ä»¶æ£€æŸ¥:")
            self._write_debug(f"  - å½“å‰æ€§èƒ½: {current_performance:.4f}")
            self._write_debug(f"  - æœ€è¿‘å¹³å‡æ€§èƒ½: {avg_recent_performance:.4f}")
            self._write_debug(f"  - æ€§èƒ½é˜ˆå€¼: {stage_config.performance_threshold}")
            self._write_debug(f"  - è¯„ä¼°æ¬¡æ•°: {len(stage_performances)}/{stage_config.min_evaluations}")
            
            if avg_recent_performance >= stage_config.performance_threshold:
                self._write_debug("âœ… æ»¡è¶³è¿›é˜¶æ¡ä»¶ï¼Œæ‰§è¡Œé˜¶æ®µè¿›é˜¶...")
                
                old_stage = current_stage_idx
                try:
                    # ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨è¯¾ç¨‹ç®¡ç†å™¨è‡ªå¸¦çš„should_advance_stageæ–¹æ³•
                    if hasattr(self.curriculum_manager, 'should_advance_stage'):
                        should_advance = self.curriculum_manager.should_advance_stage(current_performance)
                        if should_advance:
                            success = self.curriculum_manager.advance_stage()
                        else:
                            success = False
                            self._write_debug("â³ è¯¾ç¨‹ç®¡ç†å™¨åˆ¤æ–­æš‚ä¸è¿›é˜¶")
                    elif hasattr(self.curriculum_manager, 'advance_stage'):
                        success = self.curriculum_manager.advance_stage()
                    else:
                        # æ‰‹åŠ¨è¿›é˜¶ - ä½œä¸ºæœ€åçš„åå¤‡æ–¹æ¡ˆ
                        self.curriculum_manager.current_stage += 1
                        success = True
                    
                    if success:
                        new_stage = self.curriculum_manager.current_stage
                        self._write_debug(f"ğŸ¯ æˆåŠŸè¿›é˜¶: é˜¶æ®µ{old_stage} -> é˜¶æ®µ{new_stage}")
                        
                        # é‡ç½®é˜¶æ®µè®¡æ•°å™¨
                        self.step_count_in_current_stage = 0
                        
                        if new_stage < len(self.curriculum_manager.curriculum_stages):
                            new_stage_info = self.curriculum_manager.curriculum_stages[new_stage]
                            try:
                                new_dataset = self.curriculum_manager.get_current_stage_dataset()
                                self._write_debug(f"  - æ–°é˜¶æ®µåç§°: {new_stage_info.name}")
                                self._write_debug(f"  - æ–°é˜¶æ®µæ•°æ®é›†å¤§å°: {len(new_dataset)}")
                                self._write_debug(f"  - æ–°é˜¶æ®µç›®æ ‡ç­‰çº§: {new_stage_info.dataset_levels}")
                            except Exception as e:
                                self._write_debug(f"  - æ–°é˜¶æ®µä¿¡æ¯è·å–éƒ¨åˆ†å¤±è´¥: {e}")
                        else:
                            self._write_debug("ğŸ† å·²å®Œæˆæ‰€æœ‰è¯¾ç¨‹é˜¶æ®µï¼")
                            
                except Exception as e:
                    self._write_debug(f"âŒ é˜¶æ®µè¿›é˜¶å¤±è´¥: {e}")
            else:
                self._write_debug(f"â³ æœªæ»¡è¶³è¿›é˜¶æ¡ä»¶ (éœ€è¦æ€§èƒ½ >= {stage_config.performance_threshold:.4f})")
        else:
            self._write_debug(f"â³ è¯„ä¼°æ¬¡æ•°ä¸è¶³ ({len(stage_performances)}/{stage_config.min_evaluations})")

    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs: Optional[Dict[str, float]] = None, **kwargs):
        """æ—¥å¿—è®°å½•æ—¶çš„å¤„ç† - ä¿®å¤ç‰ˆæœ¬"""
        if not self.curriculum_manager or args.local_rank > 0:
            return

        current_step = getattr(state, 'global_step', 0) or 0
        self.step_count_in_current_stage += 1
        current_stage_idx = self.curriculum_manager.current_stage
        
        # æ£€æŸ¥é˜¶æ®µæ˜¯å¦å‘ç”Ÿå˜åŒ–
        if not hasattr(self, 'last_locally_logged_stage_idx') or self.last_locally_logged_stage_idx != current_stage_idx:
            self._stage_change_log(current_step, current_stage_idx)
            self.last_locally_logged_stage_idx = current_stage_idx

        # æ¯Næ­¥è®°å½•ä¸€æ¬¡è¯¦ç»†çŠ¶æ€ï¼Œå¹¶æ£€æŸ¥æ€§èƒ½ï¼ˆNå¯é…ç½®ï¼‰
        if current_step % self.performance_check_interval == 0 and current_step > 0:
            self._log_curriculum_status(current_step, logs)
            
            # åŸºäºè®­ç»ƒæ—¥å¿—è¿›è¡Œæ€§èƒ½è¯„ä¼°å’Œå¯èƒ½çš„é˜¶æ®µè¿›é˜¶
            if logs:
                performance = self._calculate_performance_from_logs(logs)
                if performance > 0:
                    # è®°å½•æ€§èƒ½å†å² - ä¿®å¤ï¼šç¡®ä¿åŒ…å«æ­£ç¡®çš„stageä¿¡æ¯
                    self.performance_history.append({
                        'step': current_step,
                        'performance': performance,
                        'stage': current_stage_idx,  # ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šå½“å‰stage
                        'timestamp': datetime.now().isoformat()
                    })
                    
                    # æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›é˜¶
                    self._check_and_advance_stage(performance, current_step)

        # W&B è®°å½•
        self._wandb_log(current_step, logs)

    def _detailed_status_log(self, current_step: int, state: TrainerState):
        """è¯¦ç»†çŠ¶æ€æ—¥å¿—"""
        current_stage_idx = self.curriculum_manager.current_stage
        
        self._write_debug(f"ğŸ“Š è¯¦ç»†çŠ¶æ€æŠ¥å‘Š (æ­¥æ•°: {current_step})")
        self._write_debug(f"  - å½“å‰é˜¶æ®µ: {current_stage_idx}")
        
        if current_stage_idx < len(self.curriculum_manager.curriculum_stages):
            stage = self.curriculum_manager.curriculum_stages[current_stage_idx]
            dataset = self.curriculum_manager.get_current_stage_dataset()
            
            self._write_debug(f"  - é˜¶æ®µåç§°: {stage.name}")
            self._write_debug(f"  - æ•°æ®é›†å¤§å°: {len(dataset)}")
            self._write_debug(f"  - æ€§èƒ½é˜ˆå€¼: {stage.performance_threshold}")
            
            # è·å–æœ€è¿‘çš„æŸå¤±
            if state.log_history:
                recent_loss = state.log_history[-1].get('train_loss', 'N/A')
                self._write_debug(f"  - æœ€è¿‘è®­ç»ƒæŸå¤±: {recent_loss}")

    def _basic_status_check(self, current_step: int, state: TrainerState):
        """åŸºæœ¬çŠ¶æ€æ£€æŸ¥"""
        current_stage_idx = self.curriculum_manager.current_stage
        
        if current_step - self.last_performance_check_step >= 100:  # æ¯100æ­¥è¯¦ç»†æ£€æŸ¥ä¸€æ¬¡
            self._write_debug(f"ğŸ” åŸºæœ¬çŠ¶æ€æ£€æŸ¥ (æ­¥æ•°: {current_step})")
            self._write_debug(f"  å½“å‰é˜¶æ®µ: {current_stage_idx}")
            
            if current_stage_idx < len(self.curriculum_manager.curriculum_stages):
                stage_name = self.curriculum_manager.curriculum_stages[current_stage_idx].name
                dataset_size = len(self.curriculum_manager.get_current_stage_dataset())
                self._write_debug(f"  é˜¶æ®µåç§°: {stage_name}")
                self._write_debug(f"  æ•°æ®é›†å¤§å°: {dataset_size}")
            
            self.last_performance_check_step = current_step

    def _stage_change_log(self, current_step: int, new_stage_idx: int):
        """é˜¶æ®µå˜æ›´æ—¥å¿—"""
        self._write_debug(f"ğŸ”„ é˜¶æ®µå˜æ›´æ£€æµ‹ (æ­¥æ•°: {current_step})")
        
        if new_stage_idx < len(self.curriculum_manager.curriculum_stages):
            stage_name = self.curriculum_manager.curriculum_stages[new_stage_idx].name
            dataset_size = len(self.curriculum_manager.get_current_stage_dataset())
            self._write_debug(f"  æ–°é˜¶æ®µ: {new_stage_idx} ({stage_name})")
            self._write_debug(f"  æ•°æ®é›†å¤§å°: {dataset_size}")
        else:
            self._write_debug(f"  é˜¶æ®µ: {new_stage_idx} (å·²å®Œæˆæ‰€æœ‰é˜¶æ®µ)")

    def _log_curriculum_status(self, current_step: int, logs: Optional[Dict[str, float]]):
        """è®°å½•è¯¾ç¨‹çŠ¶æ€"""
        current_stage_idx = self.curriculum_manager.current_stage
        
        self._write_debug(f"ğŸ“ˆ è¯¾ç¨‹çŠ¶æ€æ›´æ–° (æ­¥æ•°: {current_step})")
        
        if logs:
            train_loss = logs.get('train_loss', 'N/A')
            learning_rate = logs.get('learning_rate', 'N/A')
            self._write_debug(f"  - è®­ç»ƒæŸå¤±: {train_loss}")
            self._write_debug(f"  - å­¦ä¹ ç‡: {learning_rate}")

    def _wandb_log(self, current_step: int, logs: Optional[Dict[str, float]]):
        """W&B è®°å½• - ä¿®å¤ç‰ˆæœ¬"""
        try:
            import wandb
            if wandb.run is None:
                return
                
            current_stage_idx = self.curriculum_manager.current_stage
            stage_name = "completed"
            dataset_size = 0
            performance_threshold = 0.0
            
            if current_stage_idx < len(self.curriculum_manager.curriculum_stages):
                stage = self.curriculum_manager.curriculum_stages[current_stage_idx]
                stage_name = stage.name
                dataset_size = len(self.curriculum_manager.get_current_stage_dataset())
                performance_threshold = stage.performance_threshold
            
            # è·å–æœ€æ–°çš„æ€§èƒ½ä¼°è®¡
            latest_performance = self._calculate_performance_from_logs(logs) if logs else 0.0
            
            # è®¡ç®—å½“å‰é˜¶æ®µçš„å¹³å‡æ€§èƒ½
            stage_performances = [p['performance'] for p in self.performance_history 
                                if p.get('stage', current_stage_idx) == current_stage_idx]
            avg_stage_performance = np.mean(stage_performances) if stage_performances else 0.0
            
            wandb_data = {
                "curriculum/current_stage_idx": current_stage_idx,
                "curriculum/current_stage_name_numeric": current_stage_idx,
                "curriculum/dataset_size": dataset_size,
                "curriculum/performance_threshold": performance_threshold,
                "curriculum/latest_performance": latest_performance,
                "curriculum/evaluation_count": len(self.performance_history),
                "curriculum/stage_step_count": self.step_count_in_current_stage,
                "curriculum/avg_stage_performance": avg_stage_performance
            }
            
            # æ·»åŠ æ›´å¤šè°ƒè¯•ä¿¡æ¯
            if logs:
                if 'loss' in logs:
                    wandb_data["curriculum/current_loss"] = logs['loss']
                if 'reward' in logs:
                    wandb_data["curriculum/current_reward"] = logs['reward']
                if 'learning_rate' in logs:
                    wandb_data["curriculum/learning_rate"] = logs['learning_rate']
            
            wandb.log(wandb_data, step=current_step)
            
        except ImportError:
            pass
        except Exception as e:
            self._write_debug(f"âš ï¸ W&B è®°å½•å¼‚å¸¸: {e}")


class EnhancedCurriculumDebugCallback(TrainerCallback):
    """å¢å¼ºçš„è¯¾ç¨‹å­¦ä¹ è°ƒè¯•å›è°ƒ - æä¾›æ›´æ·±å…¥çš„è°ƒè¯•ä¿¡æ¯"""
    
    def __init__(self, curriculum_manager, trainer_ref: Optional['Trainer'] = None, output_dir: Optional[str] = None):
        self.curriculum_manager = curriculum_manager
        self.trainer_ref = trainer_ref
        self.output_dir = output_dir
        self.last_logged_stage: int = -1
        self.stage_change_history: List[Dict[str, Any]] = []
        self.curriculum_log_file: Optional[str] = None
        self.performance_history: List[Dict[str, Any]] = []
        
        if self.output_dir:
            os.makedirs(self.output_dir, exist_ok=True)
            self.curriculum_log_file = os.path.join(self.output_dir, "enhanced_curriculum_debug_log.txt")
            
            # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
            with open(self.curriculum_log_file, 'w', encoding='utf-8') as f:
                f.write(f"=== Enhanced Curriculum Debug Log - {datetime.now()} ===\n")
                f.write("è¯¦ç»†çš„è¯¾ç¨‹å­¦ä¹ è°ƒè¯•ä¿¡æ¯\n")
                f.write("="*80 + "\n")
        
        logger.info(f"âœ… EnhancedCurriculumDebugCallback initialized. Log: {self.curriculum_log_file}")

    def _write_curriculum_log(self, message: str):
        """å†™å…¥è¯¾ç¨‹è°ƒè¯•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        log_message = f"[{timestamp}] ENHANCED_CURRICULUM: {message}"
        
        # æ§åˆ¶å°è¾“å‡º
        logger.info(log_message)
        
        # æ–‡ä»¶è¾“å‡º
        if self.curriculum_log_file:
            try:
                with open(self.curriculum_log_file, 'a', encoding='utf-8') as f:
                    f.write(log_message + "\n")
            except Exception as e:
                logger.warning(f"Failed to write curriculum log: {e}")

    def on_train_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """è®­ç»ƒå¼€å§‹æ—¶çš„å¢å¼ºæ—¥å¿—"""
        if not self.curriculum_manager:
            return
            
        self._write_curriculum_log("ğŸš€ Enhanced curriculum debugging started")
        
        # è®°å½•è¯¾ç¨‹ç®¡ç†å™¨çš„è¯¦ç»†ä¿¡æ¯
        if hasattr(self.curriculum_manager, 'debug_log'):
            recent_debug = self.curriculum_manager.debug_log[-10:] if self.curriculum_manager.debug_log else []
            self._write_curriculum_log(f"ğŸ“‹ Curriculum manager debug log entries: {len(self.curriculum_manager.debug_log)}")
            for entry in recent_debug:
                self._write_curriculum_log(f"  - {entry}")

    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs: Optional[Dict[str, float]] = None, **kwargs):
        """è¯¦ç»†çš„æ—¥å¿—å¤„ç†"""
        if not self.curriculum_manager or args.local_rank > 0:
            return

        current_step = getattr(state, 'global_step', 0) or 0
        current_stage = self.curriculum_manager.current_stage
        
        # æ£€æŸ¥é˜¶æ®µå˜åŒ–
        if self.last_logged_stage != current_stage:
            self._log_stage_change(current_step, current_stage)
            self.last_logged_stage = current_stage

        # æ¯20æ­¥è®°å½•è¯¦ç»†çŠ¶æ€
        if current_step % 20 == 0 and current_step > 0:
            self._log_detailed_status(current_step, logs)

        # è®°å½•æ€§èƒ½å†å²
        if logs:
            performance_data = {
                'step': current_step,
                'stage': current_stage,
                'timestamp': datetime.now().isoformat()
            }
            
            # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„æ€§èƒ½æŒ‡æ ‡
            performance_keys = ['train_loss', 'eval_loss', 'eval_avg_test_pass_rate', 'learning_rate']
            for key in performance_keys:
                if key in logs:
                    performance_data[key] = logs[key]
            
            self.performance_history.append(performance_data)
            
            # åªä¿ç•™æœ€è¿‘1000æ¡è®°å½•
            if len(self.performance_history) > 1000:
                self.performance_history = self.performance_history[-1000:]

        # æ£€æŸ¥è¿›é˜¶æ¡ä»¶
        if current_step % 10 == 0:  # æ¯10æ­¥æ£€æŸ¥ä¸€æ¬¡
            self._check_advancement_conditions(current_step, logs)

    def _log_stage_change(self, step: int, new_stage: int):
        """è®°å½•é˜¶æ®µå˜åŒ–"""
        self._write_curriculum_log(f"ğŸ”„ Stage change detected at step {step}")
        self._write_curriculum_log(f"  Old stage: {self.last_logged_stage}")
        self._write_curriculum_log(f"  New stage: {new_stage}")
        
        if new_stage < len(self.curriculum_manager.curriculum_stages):
            stage_info = self.curriculum_manager.curriculum_stages[new_stage]
            dataset = self.curriculum_manager.get_current_stage_dataset()
            
            self._write_curriculum_log(f"  Stage name: {stage_info.name}")
            self._write_curriculum_log(f"  Dataset size: {len(dataset)}")
            self._write_curriculum_log(f"  Target levels: {stage_info.dataset_levels}")
            self._write_curriculum_log(f"  Complexity range: {stage_info.complexity_range}")
            self._write_curriculum_log(f"  Performance threshold: {stage_info.performance_threshold}")
        
        # è®°å½•å˜åŒ–å†å²
        change_record = {
            'step': step,
            'old_stage': self.last_logged_stage,
            'new_stage': new_stage,
            'timestamp': datetime.now().isoformat()
        }
        self.stage_change_history.append(change_record)

    def _log_detailed_status(self, step: int, logs: Dict[str, Any]):
        """è®°å½•è¯¦ç»†çŠ¶æ€"""
        self._write_curriculum_log(f"ğŸ“Š Detailed status at step {step}")
        
        current_stage = self.curriculum_manager.current_stage
        self._write_curriculum_log(f"  Current stage: {current_stage}")
        
        if current_stage < len(self.curriculum_manager.curriculum_stages):
            stage = self.curriculum_manager.curriculum_stages[current_stage]
            
            # é˜¶æ®µä¿¡æ¯
            self._write_curriculum_log(f"  Stage info:")
            self._write_curriculum_log(f"    - Name: {stage.name}")
            self._write_curriculum_log(f"    - Performance threshold: {stage.performance_threshold}")
            self._write_curriculum_log(f"    - Min evaluations: {stage.min_evaluations}")
            
            # å½“å‰æ€§èƒ½å†å²
            if hasattr(self.curriculum_manager, 'stage_performance_history'):
                history = self.curriculum_manager.stage_performance_history
                self._write_curriculum_log(f"    - Current stage evaluations: {len(history)}")
                if history:
                    recent = history[-3:]
                    avg_recent = np.mean(recent) if recent else 0
                    self._write_curriculum_log(f"    - Recent performance avg: {avg_recent:.4f}")
            
            # æ•°æ®é›†ä¿¡æ¯
            dataset = self.curriculum_manager.get_current_stage_dataset()
            self._write_curriculum_log(f"  Dataset size: {len(dataset)}")
        
        # è®­ç»ƒæŒ‡æ ‡
        if logs:
            self._write_curriculum_log(f"  Training metrics:")
            for key, value in logs.items():
                if isinstance(value, (int, float)):
                    self._write_curriculum_log(f"    - {key}: {value:.6f}")

    def _check_advancement_conditions(self, step: int, logs: Dict[str, Any]):
        """æ£€æŸ¥è¿›é˜¶æ¡ä»¶"""
        if not logs:
            return
            
        current_stage = self.curriculum_manager.current_stage
        if current_stage >= len(self.curriculum_manager.curriculum_stages) - 1:
            return  # å·²ç»æ˜¯æœ€åé˜¶æ®µ
        
        # å°è¯•è·å–æ€§èƒ½æŒ‡æ ‡
        performance_metrics = ['eval_avg_test_pass_rate', 'eval_loss', 'train_loss']
        performance_value = None
        performance_key = None
        
        for key in performance_metrics:
            if key in logs:
                performance_value = logs[key]
                performance_key = key
                break
        
        if performance_value is not None:
            # è½¬æ¢æ€§èƒ½å€¼
            if performance_key == 'eval_loss' or performance_key == 'train_loss':
                performance_estimate = max(0, 1.0 - min(performance_value, 1.0))
            else:
                performance_estimate = performance_value
            
            stage = self.curriculum_manager.curriculum_stages[current_stage]
            threshold = stage.performance_threshold
            
            # è·å–å†å²
            history = getattr(self.curriculum_manager, 'stage_performance_history', [])
            
            self._write_curriculum_log(f"ğŸ” Advancement check at step {step}")
            self._write_curriculum_log(f"  Performance metric: {performance_key} = {performance_value:.4f}")
            self._write_curriculum_log(f"  Performance estimate: {performance_estimate:.4f}")
            self._write_curriculum_log(f"  Threshold: {threshold:.4f}")
            self._write_curriculum_log(f"  Stage evaluations: {len(history)}/{stage.min_evaluations}")
            
            if len(history) >= 3:  # è‡³å°‘æœ‰3æ¬¡è¯„ä¼°æ‰åˆ†æè¶‹åŠ¿
                recent_trend = history[-3:]
                trend_direction = "improving" if len(recent_trend) > 1 and recent_trend[-1] > recent_trend[0] else "stable/declining"
                self._write_curriculum_log(f"  Recent trend: {trend_direction}")
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³è¿›é˜¶æ¡ä»¶
            meets_threshold = performance_estimate >= threshold
            meets_min_eval = len(history) >= stage.min_evaluations
            
            self._write_curriculum_log(f"  Meets threshold: {meets_threshold}")
            self._write_curriculum_log(f"  Meets min evaluations: {meets_min_eval}")
            
            if meets_threshold and meets_min_eval:
                self._write_curriculum_log("âœ… Ready for advancement!")
            else:
                missing = []
                if not meets_threshold:
                    missing.append(f"performance ({performance_estimate:.4f} < {threshold:.4f})")
                if not meets_min_eval:
                    missing.append(f"evaluations ({len(history)} < {stage.min_evaluations})")
                self._write_curriculum_log(f"â³ Not ready: {', '.join(missing)}")


class OptimizedCurriculumCallback(DefaultFlowCallback):
    """ä¼˜åŒ–çš„è¯¾ç¨‹å­¦ä¹ å›è°ƒ"""
    
    def __init__(self, curriculum_manager, trainer_ref: Optional['Trainer'] = None, output_dir: Optional[str] = None):
        super().__init__()
        self.curriculum_manager = curriculum_manager
        self.trainer_ref = trainer_ref
        self.output_dir = output_dir
        # Note: DynamicDifficultyAdjuster is not implemented yet
        # self.difficulty_adjuster = DynamicDifficultyAdjuster(curriculum_manager)
        self.performance_history: List[Dict[str, Any]] = []
        logger.info("OptimizedCurriculumCallback initialized (DynamicDifficultyAdjuster not implemented).")

    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs: Optional[Dict[str, float]] = None, **kwargs):
        """å¤„ç†æ—¥å¿—å¹¶æ£€æŸ¥è¯¾ç¨‹è¿›å±•"""
        if logs is None or not self.curriculum_manager:
            return
            
        current_loss = logs.get('train_loss', float('inf'))
        training_step = getattr(state, 'global_step', 0) or 0
        
        # è®°å½•æ€§èƒ½
        performance = 1.0 - min(current_loss, 1.0)
        self.performance_history.append({
            'step': training_step,
            'performance': performance,
            'loss': current_loss,
            'stage': self.curriculum_manager.current_stage
        })
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é˜¶æ®µè¿›é˜¶
        if hasattr(self.curriculum_manager, 'should_advance_to_next_stage'):
            should_advance = self.curriculum_manager.should_advance_to_next_stage(current_loss, training_step)
        else:
            # å›é€€åˆ°ç®€å•çš„è¿›é˜¶æ£€æŸ¥
            should_advance = (performance > 0.7 and 
                            len(self.performance_history) > 10 and
                            training_step % 100 == 0)
        
        if should_advance:
            old_stage = self.curriculum_manager.current_stage
            
            if hasattr(self.curriculum_manager, 'advance_to_next_stage'):
                success = self.curriculum_manager.advance_to_next_stage()
            elif hasattr(self.curriculum_manager, 'advance_stage'):
                success = self.curriculum_manager.advance_stage()
            else:
                success = False
                logger.warning("Curriculum manager lacks advancement method")
            
            if success:
                logger.info(f"ğŸ¯ è¯¾ç¨‹è¿›é˜¶: {old_stage} â†’ {self.curriculum_manager.current_stage}")
                if hasattr(self.curriculum_manager, 'get_current_stage_dataset'):
                    new_dataset = self.curriculum_manager.get_current_stage_dataset()
                    logger.info(f"ğŸ“Š æ–°æ•°æ®é›†å¤§å°: {len(new_dataset)}")
        
        # æ¯50æ­¥ä¿å­˜è¯¾ç¨‹çŠ¶æ€
        if training_step % 50 == 0:
            self._save_curriculum_state()
    
    def _save_curriculum_state(self):
        """ä¿å­˜è¯¾ç¨‹å­¦ä¹ çŠ¶æ€"""
        if not self.output_dir:
            return
            
        state_data = {
            'current_stage': self.curriculum_manager.current_stage,
            'performance_history': self.performance_history[-100:],  # ä¿å­˜æœ€è¿‘100æ¡
            'timestamp': datetime.now().isoformat()
        }
        
        state_file = os.path.join(self.output_dir, 'curriculum_state_detailed.json')
        try:
            with open(state_file, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.warning(f"ä¿å­˜è¯¾ç¨‹çŠ¶æ€å¤±è´¥: {e}")