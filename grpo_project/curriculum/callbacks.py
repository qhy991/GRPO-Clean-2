# grpo_project/curriculum/callbacks.py - ä¿®å¤ç‰ˆæœ¬
import logging
import os
import json
from datetime import datetime
from typing import Optional, Dict, Any, TYPE_CHECKING, List
import numpy as np

from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl, DefaultFlowCallback

# Attempt to import from grpo_project
try:
    from grpo_project.callbacks.base import BaseCallback
    from .manager import EnhancedCurriculumManager, FixedEnhancedCurriculumManager
except ImportError:
    logger_init = logging.getLogger(__name__)
    logger_init.warning("Callbacks.curriculum: Could not import from grpo_project. Using placeholders.")
    from transformers import TrainerCallback as BaseCallback
    class EnhancedCurriculumManager: pass
    class FixedEnhancedCurriculumManager: pass

if TYPE_CHECKING:
    from transformers import Trainer

logger = logging.getLogger(__name__)

class CurriculumProgressCallback(TrainerCallback):
    """å¢å¼ºçš„è¯¾ç¨‹å­¦ä¹ è¿›åº¦å›è°ƒï¼Œäº§ç”Ÿè¯¦ç»†çš„è°ƒè¯•æ—¥å¿—"""
    
    def __init__(self, curriculum_manager, trainer_ref: Optional['Trainer'] = None, output_dir: Optional[str] = None, 
                 performance_check_interval: int = 5):
        """
        å¢å¼ºçš„è¯¾ç¨‹å­¦ä¹ è¿›åº¦å›è°ƒ
        
        Args:
            curriculum_manager: è¯¾ç¨‹ç®¡ç†å™¨å®ä¾‹
            trainer_ref: è®­ç»ƒå™¨å¼•ç”¨ï¼ˆå¯é€‰ï¼‰
            output_dir: è¾“å‡ºç›®å½•
            performance_check_interval: æ€§èƒ½æ£€æŸ¥é—´éš”æ­¥æ•°
        """
        self.curriculum_manager = curriculum_manager
        self.trainer_ref = trainer_ref
        self.output_dir = output_dir
        self.performance_check_interval = performance_check_interval  # æ–°å¢ï¼šå¯é…ç½®çš„æ£€æŸ¥é—´éš”
        self.debug_log_path = os.path.join(output_dir, "curriculum_progress_debug.txt") if output_dir else "curriculum_progress_debug.txt"
        self.last_locally_logged_stage_idx: int = -1
        self.evaluation_count = 0
        self.last_performance_check_step = 0
        self.step_count_in_current_stage = 0  # å½“å‰é˜¶æ®µçš„æ­¥æ•°è®¡æ•°
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if self.output_dir:
            os.makedirs(self.output_dir, exist_ok=True)
            with open(self.debug_log_path, 'w', encoding='utf-8') as f:
                f.write(f"=== CurriculumProgressCallback Debug Log - {datetime.now()} ===\n")
                f.write(f"åˆå§‹åŒ–è¯¾ç¨‹å­¦ä¹ è°ƒè¯•å›è°ƒ\n")
                f.write(f"è°ƒè¯•æ—¥å¿—è·¯å¾„: {self.debug_log_path}\n")
                f.write(f"è¾“å‡ºç›®å½•: {self.output_dir}\n")
                f.write(f"æ€§èƒ½æ£€æŸ¥é—´éš”: æ¯{self.performance_check_interval}æ­¥\n")  # æ–°å¢æ—¥å¿—
                f.write("="*80 + "\n")
        
        logger.info(f"âœ… CurriculumProgressCallback initialized. Debug log: {self.debug_log_path}, Check interval: {self.performance_check_interval} steps")

    def _write_debug(self, message: str):
        """å†™å…¥è°ƒè¯•ä¿¡æ¯åˆ°ä¸“ç”¨æ–‡ä»¶å’Œæ§åˆ¶å°"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        debug_msg = f"[{timestamp}] CURRICULUM: {message}"
        
        # æ§åˆ¶å°è¾“å‡º
        logger.info(debug_msg)
        
        # å†™å…¥è°ƒè¯•æ–‡ä»¶
        try:
            with open(self.debug_log_path, 'a', encoding='utf-8') as f:
                f.write(debug_msg + "\n")
        except Exception as e:
            logger.warning(f"Failed to write debug log: {e}")

    def _calculate_performance_from_logs(self, logs: Optional[Dict[str, float]]) -> float:
        """ä»æ—¥å¿—ä¸­è®¡ç®—æ€§èƒ½æŒ‡æ ‡ - ä¿®å¤ç‰ˆæœ¬"""
        if not logs:
            return 0.0
            
        # 1. ä¼˜å…ˆä½¿ç”¨è¯„ä¼°æŒ‡æ ‡
        if 'eval_avg_test_pass_rate' in logs:
            performance = logs['eval_avg_test_pass_rate']
            self._write_debug(f"ğŸ“Š ä½¿ç”¨è¯„ä¼°æŒ‡æ ‡ eval_avg_test_pass_rate: {performance:.4f}")
            return performance
            
        # 2. ä½¿ç”¨rewardæŒ‡æ ‡ (GRPOè®­ç»ƒçš„æ ¸å¿ƒæŒ‡æ ‡)
        if 'reward' in logs:
            reward = logs['reward']
            # å°†rewardè½¬æ¢ä¸ºæ€§èƒ½åˆ†æ•° (å‡è®¾reward > 0 è¡¨ç¤ºå¥½çš„æ€§èƒ½)
            # ä½¿ç”¨sigmoidå‡½æ•°å°†rewardæ˜ å°„åˆ°[0,1]èŒƒå›´
            performance = 1.0 / (1.0 + np.exp(-max(0, reward / 5.0)))  # ç¼“å’Œçš„sigmoid
            self._write_debug(f"ğŸ“Š ä½¿ç”¨rewardæŒ‡æ ‡è½¬æ¢: reward={reward:.4f} -> performance={performance:.4f}")
            return performance
            
        # 3. ä½¿ç”¨æŸå¤±æŒ‡æ ‡è½¬æ¢
        if 'loss' in logs:
            loss = logs['loss']
            # å°†lossè½¬æ¢ä¸ºæ€§èƒ½åˆ†æ•° (lossè¶Šå°ï¼Œæ€§èƒ½è¶Šå¥½)
            performance = max(0.0, 1.0 - min(loss, 1.0))
            self._write_debug(f"ğŸ“Š ä½¿ç”¨lossæŒ‡æ ‡è½¬æ¢: loss={loss:.4f} -> performance={performance:.4f}")
            return performance
            
        if 'train_loss' in logs:
            loss = logs['train_loss']
            performance = max(0.0, 1.0 - min(loss, 1.0))
            self._write_debug(f"ğŸ“Š ä½¿ç”¨train_lossæŒ‡æ ‡è½¬æ¢: loss={loss:.4f} -> performance={performance:.4f}")
            return performance
            
        self._write_debug("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„æ€§èƒ½æŒ‡æ ‡ï¼Œè¿”å›é»˜è®¤å€¼ 0.0")
        return 0.0

    def on_train_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """è®­ç»ƒå¼€å§‹æ—¶çš„è¯¦ç»†æ—¥å¿—"""
        if not self.curriculum_manager:
            return
            
        self._write_debug("ğŸš€ è®­ç»ƒå¼€å§‹ - è¯¾ç¨‹å­¦ä¹ çŠ¶æ€åˆå§‹åŒ–")
        
        current_stage_idx = self.curriculum_manager.current_stage
        total_stages = len(self.curriculum_manager.curriculum_stages)
        
        self._write_debug(f"ğŸ“Š è¯¾ç¨‹å­¦ä¹ æ€»è§ˆ:")
        self._write_debug(f"  - æ€»é˜¶æ®µæ•°: {total_stages}")
        self._write_debug(f"  - å½“å‰é˜¶æ®µç´¢å¼•: {current_stage_idx}")
        
        # è¯¦ç»†è®°å½•æ¯ä¸ªé˜¶æ®µä¿¡æ¯
        for i, stage in enumerate(self.curriculum_manager.curriculum_stages):
            status = "ğŸ”„ å½“å‰" if i == current_stage_idx else "â³ å¾…è¿›å…¥" if i > current_stage_idx else "âœ… å·²å®Œæˆ"
            self._write_debug(f"  é˜¶æ®µ{i}: {stage.name} | {status}")
            self._write_debug(f"    - ç­‰çº§: {stage.dataset_levels}")
            self._write_debug(f"    - å¤æ‚åº¦èŒƒå›´: {stage.complexity_range}")
            self._write_debug(f"    - æ€§èƒ½é˜ˆå€¼: {stage.performance_threshold}")
            self._write_debug(f"    - æœ€å°è¯„ä¼°æ¬¡æ•°: {stage.min_evaluations}")
        
        # å½“å‰é˜¶æ®µè¯¦ç»†ä¿¡æ¯
        if current_stage_idx < total_stages:
            current_stage = self.curriculum_manager.curriculum_stages[current_stage_idx]
            current_dataset = self.curriculum_manager.get_current_stage_dataset()
            
            self._write_debug(f"ğŸ¯ å½“å‰é˜¶æ®µè¯¦æƒ…:")
            self._write_debug(f"  - é˜¶æ®µåç§°: {current_stage.name}")
            self._write_debug(f"  - æ•°æ®é›†å¤§å°: {len(current_dataset)}")
            self._write_debug(f"  - ç›®æ ‡ç­‰çº§: {current_stage.dataset_levels}")
            self._write_debug(f"  - å¤æ‚åº¦èŒƒå›´: {current_stage.complexity_range}")
            self._write_debug(f"  - éœ€è¦è¾¾åˆ°æ€§èƒ½: {current_stage.performance_threshold}")

    def on_step_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """æ¯æ­¥å¼€å§‹æ—¶çš„ç›‘æ§"""
        if not self.curriculum_manager:
            return
            
        current_step = getattr(state, 'global_step', 0) or 0
        
        # æ¯50æ­¥è¯¦ç»†è®°å½•ä¸€æ¬¡çŠ¶æ€
        if current_step % 50 == 0 and current_step > 0:
            self._detailed_status_log(current_step, state)

    def on_step_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """æ¯æ­¥ç»“æŸæ—¶çš„ç›‘æ§"""
        if not self.curriculum_manager:
            return
            
        current_step = getattr(state, 'global_step', 0) or 0
        
        # æ¯10æ­¥æ£€æŸ¥ä¸€æ¬¡åŸºæœ¬çŠ¶æ€
        if current_step % 10 == 0:
            self._basic_status_check(current_step, state)

    def on_evaluate(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """è¯„ä¼°æ—¶çš„è¯¦ç»†å¤„ç† - ç®€åŒ–ç‰ˆæœ¬"""
        if not self.curriculum_manager or args.local_rank > 0:
            return
            
        current_step = getattr(state, 'global_step', 0) or 0
        self.evaluation_count += 1
        current_stage_idx = self.curriculum_manager.current_stage
        
        self._write_debug(f"ğŸ“ˆ ç¬¬{self.evaluation_count}æ¬¡è¯„ä¼° (æ­¥æ•°: {current_step})")
        
        # ä»æœ€æ–°çš„æ—¥å¿—æ¡ç›®ä¸­è·å–æ€§èƒ½
        performance_estimate = 0.0
        if state.log_history:
            latest_logs = state.log_history[-1]
            performance_estimate = self._calculate_performance_from_logs(latest_logs)
        
        self._write_debug(f"ğŸ“Š è¯„ä¼°è¯¦æƒ…:")
        self._write_debug(f"  - å½“å‰é˜¶æ®µ: {current_stage_idx}")
        self._write_debug(f"  - æ€§èƒ½ä¼°è®¡: {performance_estimate:.4f}")
        
        if current_stage_idx < len(self.curriculum_manager.curriculum_stages):
            stage_config = self.curriculum_manager.curriculum_stages[current_stage_idx]
            threshold = stage_config.performance_threshold
            min_evals = stage_config.min_evaluations
            
            self._write_debug(f"  - é˜¶æ®µåç§°: {stage_config.name}")
            self._write_debug(f"  - æ€§èƒ½é˜ˆå€¼: {threshold}")
            self._write_debug(f"  - æœ€å°è¯„ä¼°æ¬¡æ•°: {min_evals}")
            
            # ğŸ”§ ç®€åŒ–ï¼šè®©è¯¾ç¨‹ç®¡ç†å™¨å¤„ç†è¯„ä¼°é€»è¾‘
            if performance_estimate > 0:
                self._check_and_advance_stage(performance_estimate, current_step)

    def _check_and_advance_stage(self, current_performance: float, current_step: int):
        """æ£€æŸ¥å¹¶æ‰§è¡Œé˜¶æ®µè¿›é˜¶ - ç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…åŒé‡åˆ¤æ–­ + å®Œæ•´epochæ”¯æŒ"""
        current_stage_idx = self.curriculum_manager.current_stage
        
        if current_stage_idx >= len(self.curriculum_manager.curriculum_stages):
            return  # å·²å®Œæˆæ‰€æœ‰é˜¶æ®µ
            
        stage_config = self.curriculum_manager.curriculum_stages[current_stage_idx]
        
        self._write_debug(f"ğŸ“Š é˜¶æ®µè¿›é˜¶æ£€æŸ¥ (æ­¥æ•°: {current_step})")
        self._write_debug(f"  - å½“å‰é˜¶æ®µ: {current_stage_idx} ({stage_config.name})")
        self._write_debug(f"  - å½“å‰æ€§èƒ½: {current_performance:.4f}")
        self._write_debug(f"  - æ€§èƒ½é˜ˆå€¼: {stage_config.performance_threshold}")
        
        # ğŸ”§ æ–°å¢ï¼šè·å–å®Œæ•´çš„è¿›é˜¶è¦æ±‚æ£€æŸ¥
        advancement_reqs = self.curriculum_manager.get_stage_advancement_requirements()
        
        self._write_debug(f"ğŸ“‹ è¿›é˜¶è¦æ±‚æ£€æŸ¥:")
        for req in advancement_reqs['requirements']:
            status = "âœ…" if req['met'] else "âŒ"
            self._write_debug(f"  {status} {req['description']}")
            current_val = req['current']
            target_val = req['target']
            if isinstance(current_val, float):
                current_str = f"{current_val:.4f}"
            else:
                current_str = str(current_val)
            if isinstance(target_val, float):
                target_str = f"{target_val:.4f}"
            else:
                target_str = str(target_val)
            self._write_debug(f"    å½“å‰: {current_str}")
            self._write_debug(f"    ç›®æ ‡: {target_str}")
            if req['type'] == 'full_training' and 'progress_percent' in req:
                self._write_debug(f"    è®­ç»ƒè¿›åº¦: {req['progress_percent']:.1f}%")
        
        can_advance = advancement_reqs['can_advance']
        self._write_debug(f"ğŸ“Š ç»¼åˆè¿›é˜¶åˆ¤æ–­: {can_advance}")
        
        # ğŸ”§ ä¿®å¤ï¼šç»Ÿä¸€ç”±è¯¾ç¨‹ç®¡ç†å™¨åˆ¤æ–­ï¼Œé¿å…åŒé‡é€»è¾‘
        try:
            old_stage = current_stage_idx
            
            # è®©è¯¾ç¨‹ç®¡ç†å™¨åšå”¯ä¸€çš„åˆ¤æ–­ - ä¼ é€’å½“å‰æ­¥æ•°ç”¨äºè®­ç»ƒè¿›åº¦æ›´æ–°
            if self.curriculum_manager.should_advance_stage(current_performance, current_step):
                success = self.curriculum_manager.advance_stage()
                
                if success:
                    new_stage = self.curriculum_manager.current_stage
                    self._write_debug(f"ğŸ¯ æˆåŠŸè¿›é˜¶: é˜¶æ®µ{old_stage} -> é˜¶æ®µ{new_stage}")
                    
                    # ğŸ”§ é‡è¦ï¼šæ›´æ–°æ–°é˜¶æ®µçš„å¼€å§‹æ­¥æ•°
                    self.curriculum_manager.update_stage_start_step(current_step)
                    
                    # é‡ç½®é˜¶æ®µè®¡æ•°å™¨
                    self.step_count_in_current_stage = 0
                    
                    if new_stage < len(self.curriculum_manager.curriculum_stages):
                        new_stage_info = self.curriculum_manager.curriculum_stages[new_stage]
                        try:
                            new_dataset = self.curriculum_manager.get_current_stage_dataset()
                            self._write_debug(f"  - æ–°é˜¶æ®µåç§°: {new_stage_info.name}")
                            self._write_debug(f"  - æ–°é˜¶æ®µæ•°æ®é›†å¤§å°: {len(new_dataset)}")
                            self._write_debug(f"  - æ–°é˜¶æ®µç›®æ ‡ç­‰çº§: {new_stage_info.dataset_levels}")
                            self._write_debug(f"  - æ–°é˜¶æ®µè¦æ±‚å®Œæ•´epoch: {getattr(new_stage_info, 'require_full_epoch', True)}")
                        except Exception as e:
                            self._write_debug(f"  - æ–°é˜¶æ®µä¿¡æ¯è·å–éƒ¨åˆ†å¤±è´¥: {e}")
                    else:
                        self._write_debug("ğŸ† å·²å®Œæˆæ‰€æœ‰è¯¾ç¨‹é˜¶æ®µï¼")
                else:
                    self._write_debug("âŒ è¯¾ç¨‹ç®¡ç†å™¨è¿›é˜¶æ“ä½œå¤±è´¥")
            else:
                # è¯¦ç»†è¯´æ˜ä¸ºä»€ä¹ˆä¸èƒ½è¿›é˜¶
                unmet_reqs = [req for req in advancement_reqs['requirements'] if not req['met']]
                if unmet_reqs:
                    self._write_debug("â³ æœªæ»¡è¶³çš„è¿›é˜¶æ¡ä»¶:")
                    for req in unmet_reqs:
                        if req['type'] == 'performance':
                            gap = req['target'] - req['current']
                            self._write_debug(f"  - æ€§èƒ½å·®è·: éœ€æå‡ {gap:.4f}")
                        elif req['type'] == 'evaluations':
                            remaining = req['target'] - req['current']
                            self._write_debug(f"  - è¯„ä¼°æ¬¡æ•°: è¿˜éœ€ {remaining} æ¬¡")
                        elif req['type'] == 'full_training':
                            remaining_epochs = req['target'] - req['current']
                            self._write_debug(f"  - è®­ç»ƒè¿›åº¦: è¿˜éœ€ {remaining_epochs:.2f} epoch ({req.get('progress_percent', 0):.1f}%)")
                else:
                    self._write_debug("â³ è¯¾ç¨‹ç®¡ç†å™¨åˆ¤æ–­æš‚ä¸æ»¡è¶³è¿›é˜¶æ¡ä»¶")
                
        except Exception as e:
            self._write_debug(f"âŒ é˜¶æ®µè¿›é˜¶æ£€æŸ¥å¤±è´¥: {e}")

    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs: Optional[Dict[str, float]] = None, **kwargs):
        """æ—¥å¿—è®°å½•æ—¶çš„å¤„ç† - ç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…é‡å¤çš„æ€§èƒ½ç®¡ç†"""
        if not self.curriculum_manager or args.local_rank > 0:
            return

        current_step = getattr(state, 'global_step', 0) or 0
        self.step_count_in_current_stage += 1
        current_stage_idx = self.curriculum_manager.current_stage
        
        # æ£€æŸ¥é˜¶æ®µæ˜¯å¦å‘ç”Ÿå˜åŒ–
        if not hasattr(self, 'last_locally_logged_stage_idx') or self.last_locally_logged_stage_idx != current_stage_idx:
            self._stage_change_log(current_step, current_stage_idx)
            self.last_locally_logged_stage_idx = current_stage_idx

        # æ¯Næ­¥è®°å½•ä¸€æ¬¡è¯¦ç»†çŠ¶æ€ï¼Œå¹¶æ£€æŸ¥æ€§èƒ½ï¼ˆNå¯é…ç½®ï¼‰
        if current_step % self.performance_check_interval == 0 and current_step > 0:
            self._log_curriculum_status(current_step, logs)
            
            # ğŸ”§ ç®€åŒ–ï¼šç›´æ¥åŸºäºå½“å‰æ€§èƒ½è¿›è¡Œæ£€æŸ¥ï¼Œä¸ç»´æŠ¤é‡å¤çš„å†å²
            if logs:
                performance = self._calculate_performance_from_logs(logs)
                if performance > 0:
                    # ç›´æ¥æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›é˜¶ï¼Œè®©è¯¾ç¨‹ç®¡ç†å™¨ç®¡ç†æ‰€æœ‰æ•°æ®
                    self._check_and_advance_stage(performance, current_step)

        # W&B è®°å½•
        self._wandb_log(current_step, logs)

    def _detailed_status_log(self, current_step: int, state: TrainerState):
        """è¯¦ç»†çŠ¶æ€æ—¥å¿—"""
        current_stage_idx = self.curriculum_manager.current_stage
        
        self._write_debug(f"ğŸ“Š è¯¦ç»†çŠ¶æ€æŠ¥å‘Š (æ­¥æ•°: {current_step})")
        self._write_debug(f"  - å½“å‰é˜¶æ®µ: {current_stage_idx}")
        
        if current_stage_idx < len(self.curriculum_manager.curriculum_stages):
            stage = self.curriculum_manager.curriculum_stages[current_stage_idx]
            dataset = self.curriculum_manager.get_current_stage_dataset()
            
            self._write_debug(f"  - é˜¶æ®µåç§°: {stage.name}")
            self._write_debug(f"  - æ•°æ®é›†å¤§å°: {len(dataset)}")
            self._write_debug(f"  - æ€§èƒ½é˜ˆå€¼: {stage.performance_threshold}")
            
            # è·å–æœ€è¿‘çš„æŸå¤±
            if state.log_history:
                recent_loss = state.log_history[-1].get('train_loss', 'N/A')
                self._write_debug(f"  - æœ€è¿‘è®­ç»ƒæŸå¤±: {recent_loss}")

    def _basic_status_check(self, current_step: int, state: TrainerState):
        """åŸºæœ¬çŠ¶æ€æ£€æŸ¥"""
        current_stage_idx = self.curriculum_manager.current_stage
        
        if current_step - self.last_performance_check_step >= 100:  # æ¯100æ­¥è¯¦ç»†æ£€æŸ¥ä¸€æ¬¡
            self._write_debug(f"ğŸ” åŸºæœ¬çŠ¶æ€æ£€æŸ¥ (æ­¥æ•°: {current_step})")
            self._write_debug(f"  å½“å‰é˜¶æ®µ: {current_stage_idx}")
            
            if current_stage_idx < len(self.curriculum_manager.curriculum_stages):
                stage_name = self.curriculum_manager.curriculum_stages[current_stage_idx].name
                dataset_size = len(self.curriculum_manager.get_current_stage_dataset())
                self._write_debug(f"  é˜¶æ®µåç§°: {stage_name}")
                self._write_debug(f"  æ•°æ®é›†å¤§å°: {dataset_size}")
            
            self.last_performance_check_step = current_step

    def _stage_change_log(self, current_step: int, new_stage_idx: int):
        """é˜¶æ®µå˜æ›´æ—¥å¿—"""
        self._write_debug(f"ğŸ”„ é˜¶æ®µå˜æ›´æ£€æµ‹ (æ­¥æ•°: {current_step})")
        
        if new_stage_idx < len(self.curriculum_manager.curriculum_stages):
            stage_name = self.curriculum_manager.curriculum_stages[new_stage_idx].name
            dataset_size = len(self.curriculum_manager.get_current_stage_dataset())
            self._write_debug(f"  æ–°é˜¶æ®µ: {new_stage_idx} ({stage_name})")
            self._write_debug(f"  æ•°æ®é›†å¤§å°: {dataset_size}")
        else:
            self._write_debug(f"  é˜¶æ®µ: {new_stage_idx} (å·²å®Œæˆæ‰€æœ‰é˜¶æ®µ)")

    def _log_curriculum_status(self, current_step: int, logs: Optional[Dict[str, float]]):
        """è®°å½•è¯¾ç¨‹çŠ¶æ€"""
        current_stage_idx = self.curriculum_manager.current_stage
        
        self._write_debug(f"ğŸ“ˆ è¯¾ç¨‹çŠ¶æ€æ›´æ–° (æ­¥æ•°: {current_step})")
        
        if logs:
            # æ”¹å–„lossæ˜¾ç¤ºé€»è¾‘
            train_loss = logs.get('loss') or logs.get('train_loss')
            if train_loss is not None:
                self._write_debug(f"  - è®­ç»ƒæŸå¤±: {train_loss:.4f}")
            else:
                self._write_debug(f"  - è®­ç»ƒæŸå¤±: N/A (æœªåœ¨å½“å‰æ—¥å¿—ä¸­)")
            
            learning_rate = logs.get('learning_rate', 'N/A')
            self._write_debug(f"  - å­¦ä¹ ç‡: {learning_rate}")
            
            # æ·»åŠ rewardæ˜¾ç¤º
            reward = logs.get('reward')
            if reward is not None:
                self._write_debug(f"  - å½“å‰å¥–åŠ±: {reward:.4f}")

    def _wandb_log(self, current_step: int, logs: Optional[Dict[str, float]]):
        """W&B è®°å½• - ç®€åŒ–ç‰ˆæœ¬ + å®Œæ•´epochè®­ç»ƒè¿›åº¦ + è¯¦ç»†æ•°æ®é›†ä½¿ç”¨ç›‘æ§"""
        try:
            import wandb
            if wandb.run is None:
                return
                
            current_stage_idx = self.curriculum_manager.current_stage
            stage_name = "completed"
            dataset_size = 0
            performance_threshold = 0.0
            
            if current_stage_idx < len(self.curriculum_manager.curriculum_stages):
                stage = self.curriculum_manager.curriculum_stages[current_stage_idx]
                stage_name = stage.name
                dataset_size = len(self.curriculum_manager.get_current_stage_dataset())
                performance_threshold = stage.performance_threshold
            
            # è·å–æœ€æ–°çš„æ€§èƒ½ä¼°è®¡
            latest_performance = self._calculate_performance_from_logs(logs) if logs else 0.0
            
            # ğŸ”§ ä¿®å¤ï¼šä»è¯¾ç¨‹ç®¡ç†å™¨è·å–æ€§èƒ½æ•°æ®
            stage_evaluation_count = 0
            avg_stage_performance = 0.0
            
            if hasattr(self.curriculum_manager, 'stage_performance_history'):
                stage_performances = self.curriculum_manager.stage_performance_history
                stage_evaluation_count = len(stage_performances)
                avg_stage_performance = np.mean(stage_performances) if stage_performances else 0.0
            
            # ğŸ”§ æ–°å¢ï¼šè·å–å®Œæ•´è®­ç»ƒè¿›åº¦ä¿¡æ¯
            training_status = self.curriculum_manager.get_stage_training_status()
            advancement_reqs = self.curriculum_manager.get_stage_advancement_requirements()
            
            # ğŸ”§ æ–°å¢ï¼šè®¡ç®—æ•°æ®é›†ä½¿ç”¨ç»Ÿè®¡
            full_dataset_size = len(self.curriculum_manager.full_dataset)
            stage_dataset_coverage = (dataset_size / full_dataset_size * 100) if full_dataset_size > 0 else 0
            
            # ğŸ”§ æ–°å¢ï¼šè®¡ç®—ç´¯ç§¯æ•°æ®ä½¿ç”¨æƒ…å†µ
            cumulative_samples_trained = 0
            cumulative_coverage_percent = 0
            
            if training_status and training_status.get('status') != 'no_tracker':
                steps_completed = training_status.get('steps_completed', 0)
                estimated_steps_per_epoch = training_status.get('estimated_steps_per_epoch', 1)
                
                # å‡è®¾æ¯æ­¥å¤„ç†1ä¸ªæ ·æœ¬ï¼ˆå®é™…å¯èƒ½ä¸åŒï¼Œä½†ç”¨äºä¼°ç®—ï¼‰
                cumulative_samples_trained = steps_completed
                cumulative_coverage_percent = min(100, (steps_completed / estimated_steps_per_epoch) * 100)
            
            wandb_data = {
                "curriculum/current_stage_idx": int(current_stage_idx),
                "curriculum/current_stage_name_numeric": int(current_stage_idx),
                "curriculum/dataset_size": int(dataset_size),
                "curriculum/performance_threshold": float(performance_threshold),
                "curriculum/latest_performance": float(latest_performance),
                "curriculum/evaluation_count": int(stage_evaluation_count),
                "curriculum/stage_step_count": int(self.step_count_in_current_stage),
                "curriculum/avg_stage_performance": float(avg_stage_performance),
                
                # ğŸ”§ æ–°å¢ï¼šæ•°æ®é›†ä½¿ç”¨æƒ…å†µç›‘æ§
                "curriculum/full_dataset_size": int(full_dataset_size),
                "curriculum/stage_dataset_coverage_percent": float(stage_dataset_coverage),
                "curriculum/cumulative_samples_trained": int(cumulative_samples_trained),
                "curriculum/cumulative_coverage_percent": float(cumulative_coverage_percent),
            }
            
            # ğŸ”§ æ–°å¢ï¼šå®Œæ•´è®­ç»ƒè¿›åº¦æŒ‡æ ‡
            if training_status and training_status.get('status') != 'no_tracker':
                epochs_completed = training_status.get('epochs_completed', 0)
                steps_completed = training_status.get('steps_completed', 0)
                progress_percent = training_status.get('progress_percent', 0)
                estimated_steps_per_epoch = training_status.get('estimated_steps_per_epoch', 0)
                
                wandb_data.update({
                    "curriculum/epochs_completed": float(epochs_completed),
                    "curriculum/steps_completed": int(steps_completed),
                    "curriculum/training_progress_percent": float(progress_percent),
                    "curriculum/require_full_epoch": float(training_status.get('require_full_epoch', False)),
                    "curriculum/epoch_requirement_met": float(training_status.get('is_epoch_requirement_met', False)),
                    "curriculum/estimated_steps_per_epoch": int(estimated_steps_per_epoch),
                    
                    # ğŸ”§ æ–°å¢ï¼šè¯¦ç»†çš„æ•°æ®ä½¿ç”¨ç‡æŒ‡æ ‡
                    "curriculum/samples_per_step": 1.0,  # å‡è®¾æ¯æ­¥1ä¸ªæ ·æœ¬
                    "curriculum/estimated_total_samples": int(estimated_steps_per_epoch),
                    "curriculum/samples_remaining": int(max(0, estimated_steps_per_epoch - steps_completed)),
                    "curriculum/epoch_completion_ratio": float(min(1.0, epochs_completed)),
                    
                    # ğŸ”§ æ–°å¢ï¼šé˜¶æ®µæ•°æ®ä½¿ç”¨æ•ˆç‡
                    "curriculum/stage_data_efficiency": float(steps_completed / dataset_size) if dataset_size > 0 else 0.0,
                    "curriculum/data_reuse_count": float(epochs_completed),
                })
                
                # ğŸ”§ æ–°å¢ï¼šé¢„æµ‹å‰©ä½™è®­ç»ƒæ—¶é—´ï¼ˆåŸºäºå½“å‰è¿›åº¦ï¼‰
                if epochs_completed > 0 and progress_percent > 0:
                    estimated_remaining_steps = int(max(0, estimated_steps_per_epoch - steps_completed))
                    wandb_data["curriculum/estimated_remaining_steps"] = estimated_remaining_steps
                    
                    # å¦‚æœæœ‰æ­¥æ•°å†å²ï¼Œå¯ä»¥ä¼°ç®—å‰©ä½™æ—¶é—´
                    if hasattr(self, 'step_count_in_current_stage') and self.step_count_in_current_stage > 0:
                        steps_per_training_step = float(steps_completed / self.step_count_in_current_stage) if self.step_count_in_current_stage > 0 else 1.0
                        estimated_remaining_training_steps = float(estimated_remaining_steps / steps_per_training_step) if steps_per_training_step > 0 else 0.0
                        wandb_data["curriculum/estimated_remaining_training_steps"] = estimated_remaining_training_steps
            
            # ğŸ”§ æ–°å¢ï¼šè¿›é˜¶è¦æ±‚æ»¡è¶³æƒ…å†µ
            if advancement_reqs and 'requirements' in advancement_reqs:
                wandb_data["curriculum/can_advance"] = float(advancement_reqs['can_advance'])
                
                # åˆ†åˆ«è®°å½•å„é¡¹è¦æ±‚çš„æ»¡è¶³æƒ…å†µ
                for req in advancement_reqs['requirements']:
                    req_type = req['type']
                    wandb_data[f"curriculum/{req_type}_requirement_met"] = float(req['met'])
                    wandb_data[f"curriculum/{req_type}_current"] = req['current']
                    wandb_data[f"curriculum/{req_type}_target"] = req['target']
                    
                    # ğŸ”§ æ–°å¢ï¼šè®¡ç®—æ¯é¡¹è¦æ±‚çš„å®Œæˆåº¦
                    if req['target'] > 0:
                        completion_ratio = min(1.0, req['current'] / req['target'])
                        wandb_data[f"curriculum/{req_type}_completion_ratio"] = completion_ratio
            
            # ğŸ”§ æ–°å¢ï¼šé˜¶æ®µçº§åˆ«çš„æ•°æ®åˆ†å¸ƒä¿¡æ¯
            if current_stage_idx < len(self.curriculum_manager.curriculum_stages):
                stage_config = self.curriculum_manager.curriculum_stages[current_stage_idx]
                
                # è®°å½•é˜¶æ®µé…ç½®ä¿¡æ¯
                wandb_data.update({
                    "curriculum/stage_complexity_min": float(stage_config.complexity_range[0]),
                    "curriculum/stage_complexity_max": float(stage_config.complexity_range[1]),
                    "curriculum/stage_complexity_span": float(stage_config.complexity_range[1] - stage_config.complexity_range[0]),
                    "curriculum/stage_levels_count": int(len(stage_config.dataset_levels)),
                    "curriculum/stage_min_evaluations": int(stage_config.min_evaluations),
                    "curriculum/stage_require_full_epoch": float(getattr(stage_config, 'require_full_epoch', True)),
                    "curriculum/stage_min_steps_per_epoch": int(getattr(stage_config, 'min_steps_per_epoch', 10)),
                })
                
                # ğŸ”§ ä¿®å¤ï¼šå°†æ•°æ®çº§åˆ«è½¬æ¢ä¸ºæ•°å€¼ç¼–ç ï¼Œé¿å…æ–‡å­—æ˜¾ç¤º
                level_mapping = {
                    'basic': 1.0,
                    'intermediate': 2.0, 
                    'advanced': 3.0,
                    'expert': 4.0,
                    'master': 5.0
                }
                
                # è®°å½•å½“å‰é˜¶æ®µåŒ…å«çš„çº§åˆ«ï¼ˆæ•°å€¼å½¢å¼ï¼‰
                stage_levels_encoded = []
                for level in stage_config.dataset_levels:
                    level_encoded = level_mapping.get(level.lower(), 0.0)
                    stage_levels_encoded.append(level_encoded)
                
                # è®°å½•çº§åˆ«ç»Ÿè®¡
                wandb_data.update({
                    "curriculum/stage_has_basic": float('basic' in [l.lower() for l in stage_config.dataset_levels]),
                    "curriculum/stage_has_intermediate": float('intermediate' in [l.lower() for l in stage_config.dataset_levels]),
                    "curriculum/stage_has_advanced": float('advanced' in [l.lower() for l in stage_config.dataset_levels]),
                    "curriculum/stage_has_expert": float('expert' in [l.lower() for l in stage_config.dataset_levels]),
                    "curriculum/stage_has_master": float('master' in [l.lower() for l in stage_config.dataset_levels]),
                    "curriculum/stage_level_diversity": float(len(set(stage_config.dataset_levels))),
                    "curriculum/stage_min_level": float(min(stage_levels_encoded) if stage_levels_encoded else 0),
                    "curriculum/stage_max_level": float(max(stage_levels_encoded) if stage_levels_encoded else 0),
                })
            
            # æ·»åŠ æ›´å¤šè°ƒè¯•ä¿¡æ¯ - ç¡®ä¿éƒ½æ˜¯æ•°å€¼ç±»å‹
            if logs:
                if 'loss' in logs:
                    wandb_data["curriculum/current_loss"] = float(logs['loss'])
                if 'reward' in logs:
                    wandb_data["curriculum/current_reward"] = float(logs['reward'])
                if 'learning_rate' in logs:
                    wandb_data["curriculum/learning_rate"] = float(logs['learning_rate'])
            
            # ğŸ”§ æ–°å¢ï¼šé˜¶æ®µæ€§èƒ½è¶‹åŠ¿ - ç¡®ä¿éƒ½æ˜¯æ•°å€¼ç±»å‹
            if hasattr(self.curriculum_manager, 'stage_performance_history') and self.curriculum_manager.stage_performance_history:
                history = self.curriculum_manager.stage_performance_history
                if len(history) >= 2:
                    recent_trend = float(history[-1] - history[-2])
                    wandb_data["curriculum/performance_trend"] = recent_trend
                    
                if len(history) >= 3:
                    recent_avg = float(np.mean(history[-3:]))
                    wandb_data["curriculum/recent_3_avg_performance"] = recent_avg
                    
                    # æ€§èƒ½ç¨³å®šæ€§ï¼ˆæœ€è¿‘3æ¬¡çš„æ ‡å‡†å·®ï¼‰
                    recent_std = float(np.std(history[-3:]))
                    wandb_data["curriculum/performance_stability"] = recent_std
                    
                # ğŸ”§ æ–°å¢ï¼šæ›´å¤šæ€§èƒ½ç»Ÿè®¡
                wandb_data.update({
                    "curriculum/performance_history_length": int(len(history)),
                    "curriculum/performance_min": float(min(history)),
                    "curriculum/performance_max": float(max(history)),
                    "curriculum/performance_range": float(max(history) - min(history)),
                    "curriculum/performance_latest": float(history[-1]),
                })
                
                # è®¡ç®—æ€§èƒ½æ”¹å–„è¶‹åŠ¿ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿæ•°æ®ï¼‰
                if len(history) >= 5:
                    early_avg = float(np.mean(history[:2]))
                    recent_avg = float(np.mean(history[-2:]))
                    improvement = recent_avg - early_avg
                    wandb_data["curriculum/performance_improvement"] = improvement
            
            # ğŸ”§ æ–°å¢ï¼šé˜¶æ®µåç§°çš„æ•°å€¼ç¼–ç ï¼ˆç”¨äºå›¾è¡¨æ˜¾ç¤ºï¼‰
            stage_name_mapping = {
                'foundation': 0.0,
                'elementary': 1.0,
                'intermediate': 2.0,
                'advanced': 3.0,
                'expert': 4.0,
                'comprehensive': 5.0
            }
            
            if current_stage_idx < len(self.curriculum_manager.curriculum_stages):
                stage_name = self.curriculum_manager.curriculum_stages[current_stage_idx].name
                stage_name_encoded = stage_name_mapping.get(stage_name.lower(), current_stage_idx)
                wandb_data["curriculum/stage_name_encoded"] = float(stage_name_encoded)
            else:
                wandb_data["curriculum/stage_name_encoded"] = 6.0  # completed
            
            # ğŸ”§ ç¡®ä¿æ‰€æœ‰æ ¸å¿ƒæŒ‡æ ‡éƒ½æ˜¯æ•°å€¼ç±»å‹
            wandb_data.update({
                "curriculum/current_stage_idx": int(current_stage_idx),
                "curriculum/current_stage_name_numeric": int(current_stage_idx),
                "curriculum/dataset_size": int(dataset_size),
                "curriculum/performance_threshold": float(performance_threshold),
                "curriculum/latest_performance": float(latest_performance),
                "curriculum/evaluation_count": int(stage_evaluation_count),
                "curriculum/stage_step_count": int(self.step_count_in_current_stage),
                "curriculum/avg_stage_performance": float(avg_stage_performance),
                "curriculum/full_dataset_size": int(full_dataset_size),
                "curriculum/stage_dataset_coverage_percent": float(stage_dataset_coverage),
                "curriculum/cumulative_samples_trained": int(cumulative_samples_trained),
                "curriculum/cumulative_coverage_percent": float(cumulative_coverage_percent),
            })
            
            wandb.log(wandb_data, step=current_step)
            
        except ImportError:
            pass
        except Exception as e:
            self._write_debug(f"âš ï¸ W&B è®°å½•å¼‚å¸¸: {e}")


class EnhancedCurriculumDebugCallback(TrainerCallback):
    """å¢å¼ºçš„è¯¾ç¨‹å­¦ä¹ è°ƒè¯•å›è°ƒ - æä¾›æ›´æ·±å…¥çš„è°ƒè¯•ä¿¡æ¯"""
    
    def __init__(self, curriculum_manager, trainer_ref: Optional['Trainer'] = None, output_dir: Optional[str] = None):
        self.curriculum_manager = curriculum_manager
        self.trainer_ref = trainer_ref
        self.output_dir = output_dir
        self.last_logged_stage: int = -1
        self.stage_change_history: List[Dict[str, Any]] = []
        self.curriculum_log_file: Optional[str] = None
        self.performance_history: List[Dict[str, Any]] = []
        
        if self.output_dir:
            os.makedirs(self.output_dir, exist_ok=True)
            self.curriculum_log_file = os.path.join(self.output_dir, "enhanced_curriculum_debug_log.txt")
            
            # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
            with open(self.curriculum_log_file, 'w', encoding='utf-8') as f:
                f.write(f"=== Enhanced Curriculum Debug Log - {datetime.now()} ===\n")
                f.write("è¯¦ç»†çš„è¯¾ç¨‹å­¦ä¹ è°ƒè¯•ä¿¡æ¯\n")
                f.write("="*80 + "\n")
        
        logger.info(f"âœ… EnhancedCurriculumDebugCallback initialized. Log: {self.curriculum_log_file}")

    def _write_curriculum_log(self, message: str):
        """å†™å…¥è¯¾ç¨‹è°ƒè¯•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        log_message = f"[{timestamp}] ENHANCED_CURRICULUM: {message}"
        
        # æ§åˆ¶å°è¾“å‡º
        logger.info(log_message)
        
        # æ–‡ä»¶è¾“å‡º
        if self.curriculum_log_file:
            try:
                with open(self.curriculum_log_file, 'a', encoding='utf-8') as f:
                    f.write(log_message + "\n")
            except Exception as e:
                logger.warning(f"Failed to write curriculum log: {e}")

    def on_train_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """è®­ç»ƒå¼€å§‹æ—¶çš„å¢å¼ºæ—¥å¿—"""
        if not self.curriculum_manager:
            return
            
        self._write_curriculum_log("ğŸš€ Enhanced curriculum debugging started")
        
        # è®°å½•è¯¾ç¨‹ç®¡ç†å™¨çš„è¯¦ç»†ä¿¡æ¯
        if hasattr(self.curriculum_manager, 'debug_log'):
            recent_debug = self.curriculum_manager.debug_log[-10:] if self.curriculum_manager.debug_log else []
            self._write_curriculum_log(f"ğŸ“‹ Curriculum manager debug log entries: {len(self.curriculum_manager.debug_log)}")
            for entry in recent_debug:
                self._write_curriculum_log(f"  - {entry}")

    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs: Optional[Dict[str, float]] = None, **kwargs):
        """è¯¦ç»†çš„æ—¥å¿—å¤„ç†"""
        if not self.curriculum_manager or args.local_rank > 0:
            return

        current_step = getattr(state, 'global_step', 0) or 0
        current_stage = self.curriculum_manager.current_stage
        
        # æ£€æŸ¥é˜¶æ®µå˜åŒ–
        if self.last_logged_stage != current_stage:
            self._log_stage_change(current_step, current_stage)
            self.last_logged_stage = current_stage

        # æ¯20æ­¥è®°å½•è¯¦ç»†çŠ¶æ€
        if current_step % 20 == 0 and current_step > 0:
            self._log_detailed_status(current_step, logs)

        # è®°å½•æ€§èƒ½å†å²
        if logs:
            performance_data = {
                'step': current_step,
                'stage': current_stage,
                'timestamp': datetime.now().isoformat()
            }
            
            # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„æ€§èƒ½æŒ‡æ ‡
            performance_keys = ['train_loss', 'eval_loss', 'eval_avg_test_pass_rate', 'learning_rate']
            for key in performance_keys:
                if key in logs:
                    performance_data[key] = logs[key]
            
            self.performance_history.append(performance_data)
            
            # åªä¿ç•™æœ€è¿‘1000æ¡è®°å½•
            if len(self.performance_history) > 1000:
                self.performance_history = self.performance_history[-1000:]

        # æ£€æŸ¥è¿›é˜¶æ¡ä»¶
        if current_step % 10 == 0:  # æ¯10æ­¥æ£€æŸ¥ä¸€æ¬¡
            self._check_advancement_conditions(current_step, logs)

    def _log_stage_change(self, step: int, new_stage: int):
        """è®°å½•é˜¶æ®µå˜åŒ–"""
        self._write_curriculum_log(f"ğŸ”„ Stage change detected at step {step}")
        self._write_curriculum_log(f"  Old stage: {self.last_logged_stage}")
        self._write_curriculum_log(f"  New stage: {new_stage}")
        
        if new_stage < len(self.curriculum_manager.curriculum_stages):
            stage_info = self.curriculum_manager.curriculum_stages[new_stage]
            dataset = self.curriculum_manager.get_current_stage_dataset()
            
            self._write_curriculum_log(f"  Stage name: {stage_info.name}")
            self._write_curriculum_log(f"  Dataset size: {len(dataset)}")
            self._write_curriculum_log(f"  Target levels: {stage_info.dataset_levels}")
            self._write_curriculum_log(f"  Complexity range: {stage_info.complexity_range}")
            self._write_curriculum_log(f"  Performance threshold: {stage_info.performance_threshold}")
        
        # è®°å½•å˜åŒ–å†å²
        change_record = {
            'step': step,
            'old_stage': self.last_logged_stage,
            'new_stage': new_stage,
            'timestamp': datetime.now().isoformat()
        }
        self.stage_change_history.append(change_record)

    def _log_detailed_status(self, step: int, logs: Dict[str, Any]):
        """è®°å½•è¯¦ç»†çŠ¶æ€"""
        self._write_curriculum_log(f"ğŸ“Š Detailed status at step {step}")
        
        current_stage = self.curriculum_manager.current_stage
        self._write_curriculum_log(f"  Current stage: {current_stage}")
        
        if current_stage < len(self.curriculum_manager.curriculum_stages):
            stage = self.curriculum_manager.curriculum_stages[current_stage]
            
            # é˜¶æ®µä¿¡æ¯
            self._write_curriculum_log(f"  Stage info:")
            self._write_curriculum_log(f"    - Name: {stage.name}")
            self._write_curriculum_log(f"    - Performance threshold: {stage.performance_threshold}")
            self._write_curriculum_log(f"    - Min evaluations: {stage.min_evaluations}")
            
            # å½“å‰æ€§èƒ½å†å²
            if hasattr(self.curriculum_manager, 'stage_performance_history'):
                history = self.curriculum_manager.stage_performance_history
                self._write_curriculum_log(f"    - Current stage evaluations: {len(history)}")
                if history:
                    recent = history[-3:]
                    avg_recent = np.mean(recent) if recent else 0
                    self._write_curriculum_log(f"    - Recent performance avg: {avg_recent:.4f}")
            
            # æ•°æ®é›†ä¿¡æ¯
            dataset = self.curriculum_manager.get_current_stage_dataset()
            self._write_curriculum_log(f"  Dataset size: {len(dataset)}")
        
        # è®­ç»ƒæŒ‡æ ‡
        if logs:
            self._write_curriculum_log(f"  Training metrics:")
            for key, value in logs.items():
                if isinstance(value, (int, float)):
                    self._write_curriculum_log(f"    - {key}: {value:.6f}")

    def _check_advancement_conditions(self, step: int, logs: Dict[str, Any]):
        """æ£€æŸ¥è¿›é˜¶æ¡ä»¶"""
        if not logs:
            return
            
        current_stage = self.curriculum_manager.current_stage
        if current_stage >= len(self.curriculum_manager.curriculum_stages) - 1:
            return  # å·²ç»æ˜¯æœ€åé˜¶æ®µ
        
        # å°è¯•è·å–æ€§èƒ½æŒ‡æ ‡
        performance_metrics = ['eval_avg_test_pass_rate', 'eval_loss', 'train_loss']
        performance_value = None
        performance_key = None
        
        for key in performance_metrics:
            if key in logs:
                performance_value = logs[key]
                performance_key = key
                break
        
        if performance_value is not None:
            # è½¬æ¢æ€§èƒ½å€¼
            if performance_key == 'eval_loss' or performance_key == 'train_loss':
                performance_estimate = max(0, 1.0 - min(performance_value, 1.0))
            else:
                performance_estimate = performance_value
            
            stage = self.curriculum_manager.curriculum_stages[current_stage]
            threshold = stage.performance_threshold
            
            # è·å–å†å²
            history = getattr(self.curriculum_manager, 'stage_performance_history', [])
            
            self._write_curriculum_log(f"ğŸ” Advancement check at step {step}")
            self._write_curriculum_log(f"  Performance metric: {performance_key} = {performance_value:.4f}")
            self._write_curriculum_log(f"  Performance estimate: {performance_estimate:.4f}")
            self._write_curriculum_log(f"  Threshold: {threshold:.4f}")
            self._write_curriculum_log(f"  Stage evaluations: {len(history)}/{stage.min_evaluations}")
            
            if len(history) >= 3:  # è‡³å°‘æœ‰3æ¬¡è¯„ä¼°æ‰åˆ†æè¶‹åŠ¿
                recent_trend = history[-3:]
                trend_direction = "improving" if len(recent_trend) > 1 and recent_trend[-1] > recent_trend[0] else "stable/declining"
                self._write_curriculum_log(f"  Recent trend: {trend_direction}")
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³è¿›é˜¶æ¡ä»¶
            meets_threshold = performance_estimate >= threshold
            meets_min_eval = len(history) >= stage.min_evaluations
            
            self._write_curriculum_log(f"  Meets threshold: {meets_threshold}")
            self._write_curriculum_log(f"  Meets min evaluations: {meets_min_eval}")
            
            if meets_threshold and meets_min_eval:
                self._write_curriculum_log("âœ… Ready for advancement!")
            else:
                missing = []
                if not meets_threshold:
                    missing.append(f"performance ({performance_estimate:.4f} < {threshold:.4f})")
                if not meets_min_eval:
                    missing.append(f"evaluations ({len(history)} < {stage.min_evaluations})")
                self._write_curriculum_log(f"â³ Not ready: {', '.join(missing)}")


class OptimizedCurriculumCallback(DefaultFlowCallback):
    """ä¼˜åŒ–çš„è¯¾ç¨‹å­¦ä¹ å›è°ƒ"""
    
    def __init__(self, curriculum_manager, trainer_ref: Optional['Trainer'] = None, output_dir: Optional[str] = None):
        super().__init__()
        self.curriculum_manager = curriculum_manager
        self.trainer_ref = trainer_ref
        self.output_dir = output_dir
        # Note: DynamicDifficultyAdjuster is not implemented yet
        # self.difficulty_adjuster = DynamicDifficultyAdjuster(curriculum_manager)
        self.performance_history: List[Dict[str, Any]] = []
        logger.info("OptimizedCurriculumCallback initialized (DynamicDifficultyAdjuster not implemented).")

    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs: Optional[Dict[str, float]] = None, **kwargs):
        """å¤„ç†æ—¥å¿—å¹¶æ£€æŸ¥è¯¾ç¨‹è¿›å±•"""
        if logs is None or not self.curriculum_manager:
            return
            
        # ä¿®å¤ï¼šæ­£ç¡®è·å–losså€¼ï¼Œé¿å…æ— ç©·å¤§
        current_loss = None
        if 'loss' in logs:
            current_loss = logs['loss']
        elif 'train_loss' in logs:
            current_loss = logs['train_loss']
        else:
            current_loss = 0.0  # ä½¿ç”¨0.0è€Œä¸æ˜¯æ— ç©·å¤§ä½œä¸ºé»˜è®¤å€¼
            
        training_step = getattr(state, 'global_step', 0) or 0
        
        # è®°å½•æ€§èƒ½ - ä¿®å¤ï¼šå¤„ç†lossä¸ºè´Ÿæ•°çš„æƒ…å†µ
        if current_loss is not None and current_loss != float('inf'):
            # å¯¹äºGRPOï¼Œlosså¯èƒ½ä¸ºè´Ÿæ•°ï¼Œä½¿ç”¨sigmoidè½¬æ¢
            performance = 1.0 / (1.0 + np.exp(-max(0, -current_loss)))
        else:
            performance = 0.0
        self.performance_history.append({
            'step': training_step,
            'performance': performance,
            'loss': current_loss,
            'stage': self.curriculum_manager.current_stage
        })
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é˜¶æ®µè¿›é˜¶
        if hasattr(self.curriculum_manager, 'should_advance_to_next_stage'):
            should_advance = self.curriculum_manager.should_advance_to_next_stage(current_loss, training_step)
        else:
            # å›é€€åˆ°ç®€å•çš„è¿›é˜¶æ£€æŸ¥
            should_advance = (performance > 0.7 and 
                            len(self.performance_history) > 10 and
                            training_step % 100 == 0)
        
        if should_advance:
            old_stage = self.curriculum_manager.current_stage
            
            if hasattr(self.curriculum_manager, 'advance_to_next_stage'):
                success = self.curriculum_manager.advance_to_next_stage()
            elif hasattr(self.curriculum_manager, 'advance_stage'):
                success = self.curriculum_manager.advance_stage()
            else:
                success = False
                logger.warning("Curriculum manager lacks advancement method")
            
            if success:
                logger.info(f"ğŸ¯ è¯¾ç¨‹è¿›é˜¶: {old_stage} â†’ {self.curriculum_manager.current_stage}")
                if hasattr(self.curriculum_manager, 'get_current_stage_dataset'):
                    new_dataset = self.curriculum_manager.get_current_stage_dataset()
                    logger.info(f"ğŸ“Š æ–°æ•°æ®é›†å¤§å°: {len(new_dataset)}")
        
        # æ¯50æ­¥ä¿å­˜è¯¾ç¨‹çŠ¶æ€
        if training_step % 50 == 0:
            self._save_curriculum_state()
    
    def _save_curriculum_state(self):
        """ä¿å­˜è¯¾ç¨‹å­¦ä¹ çŠ¶æ€"""
        if not self.output_dir:
            return
            
        state_data = {
            'current_stage': self.curriculum_manager.current_stage,
            'performance_history': self.performance_history[-100:],  # ä¿å­˜æœ€è¿‘100æ¡
            'timestamp': datetime.now().isoformat()
        }
        
        state_file = os.path.join(self.output_dir, 'curriculum_state_detailed.json')
        try:
            with open(state_file, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.warning(f"ä¿å­˜è¯¾ç¨‹çŠ¶æ€å¤±è´¥: {e}")

class DatasetCoverageMonitorCallback(TrainerCallback):
    """æ•°æ®é›†è¦†ç›–ç‡ç›‘æ§å›è°ƒ - ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½è¢«ä½¿ç”¨"""
    
    def __init__(self, curriculum_manager, output_dir: Optional[str] = None):
        self.curriculum_manager = curriculum_manager
        self.output_dir = output_dir
        self.used_sample_indices = set()
        self.stage_sample_usage = {}
        self.coverage_log_file = None
        
        if self.output_dir:
            os.makedirs(self.output_dir, exist_ok=True)
            self.coverage_log_file = os.path.join(self.output_dir, "dataset_coverage_monitor.txt")
            
            with open(self.coverage_log_file, 'w', encoding='utf-8') as f:
                f.write(f"=== Dataset Coverage Monitor - {datetime.now()} ===\n")
                f.write("ç›‘æ§æ•°æ®é›†ä½¿ç”¨è¦†ç›–ç‡\n")
                f.write("="*80 + "\n")
        
        logger.info(f"âœ… DatasetCoverageMonitorCallback initialized. Log: {self.coverage_log_file}")

    def _write_coverage_log(self, message: str):
        """å†™å…¥è¦†ç›–ç‡ç›‘æ§æ—¥å¿—"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_message = f"[{timestamp}] COVERAGE: {message}"
        
        logger.info(log_message)
        
        if self.coverage_log_file:
            try:
                with open(self.coverage_log_file, 'a', encoding='utf-8') as f:
                    f.write(log_message + "\n")
            except Exception as e:
                logger.warning(f"Failed to write coverage log: {e}")

    def on_train_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """è®­ç»ƒå¼€å§‹æ—¶åˆå§‹åŒ–è¦†ç›–ç‡ç›‘æ§"""
        if not self.curriculum_manager:
            return
            
        self._write_coverage_log("ğŸš€ å¼€å§‹ç›‘æ§æ•°æ®é›†è¦†ç›–ç‡")
        
        # è·å–æ€»æ•°æ®é›†å¤§å°
        total_samples = len(self.curriculum_manager.full_dataset)
        self._write_coverage_log(f"ğŸ“Š æ€»æ•°æ®é›†å¤§å°: {total_samples} æ ·æœ¬")
        
        # åˆ†ææ¯ä¸ªé˜¶æ®µçš„ç†è®ºè¦†ç›–æƒ…å†µ
        if hasattr(self.curriculum_manager, 'coverage_analysis'):
            coverage = self.curriculum_manager.coverage_analysis
            self._write_coverage_log(f"ğŸ“ˆ ç†è®ºè¦†ç›–ç‡: {coverage['coverage_ratio']*100:.1f}%")
            self._write_coverage_log(f"ğŸ“ˆ ç†è®ºè¦†ç›–æ ·æœ¬: {coverage['covered_samples']}/{coverage['total_samples']}")
            
            if coverage['uncovered_count'] > 0:
                self._write_coverage_log(f"âš ï¸ è­¦å‘Š: {coverage['uncovered_count']} ä¸ªæ ·æœ¬æœªè¢«ä»»ä½•é˜¶æ®µè¦†ç›–")

    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs: Optional[Dict[str, float]] = None, **kwargs):
        """è®°å½•å½“å‰é˜¶æ®µçš„æ•°æ®ä½¿ç”¨æƒ…å†µ"""
        if not self.curriculum_manager or args.local_rank > 0:
            return

        current_step = getattr(state, 'global_step', 0) or 0
        current_stage_idx = self.curriculum_manager.current_stage
        
        # æ¯100æ­¥è®°å½•ä¸€æ¬¡è¦†ç›–ç‡çŠ¶æ€
        if current_step % 100 == 0 and current_step > 0:
            self._log_coverage_status(current_step, current_stage_idx)

    def _log_coverage_status(self, step: int, stage_idx: int):
        """è®°å½•è¦†ç›–ç‡çŠ¶æ€"""
        if stage_idx >= len(self.curriculum_manager.curriculum_stages):
            stage_name = "completed"
            dataset_size = len(self.curriculum_manager.full_dataset)
        else:
            stage = self.curriculum_manager.curriculum_stages[stage_idx]
            stage_name = stage.name
            current_dataset = self.curriculum_manager.get_current_stage_dataset()
            dataset_size = len(current_dataset)
            
            # è®°å½•å½“å‰é˜¶æ®µä½¿ç”¨çš„æ ·æœ¬
            if stage_name not in self.stage_sample_usage:
                self.stage_sample_usage[stage_name] = set()
            
            # è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„é€»è¾‘æ¥è·Ÿè¸ªå®é™…ä½¿ç”¨çš„æ ·æœ¬ç´¢å¼•
            # ç›®å‰åªè®°å½•ç†è®ºä¸Šçš„æ•°æ®é›†å¤§å°
        
        total_samples = len(self.curriculum_manager.full_dataset)
        coverage_ratio = dataset_size / total_samples if total_samples > 0 else 0
        
        self._write_coverage_log(f"ğŸ“Š æ­¥æ•° {step} - é˜¶æ®µ {stage_name}")
        self._write_coverage_log(f"  - å½“å‰é˜¶æ®µæ•°æ®é›†: {dataset_size} æ ·æœ¬")
        self._write_coverage_log(f"  - å½“å‰é˜¶æ®µè¦†ç›–ç‡: {coverage_ratio*100:.1f}%")
        
        # ç´¯è®¡è¦†ç›–ç‡ç»Ÿè®¡
        total_used = sum(len(usage) for usage in self.stage_sample_usage.values())
        cumulative_coverage = total_used / total_samples if total_samples > 0 else 0
        self._write_coverage_log(f"  - ç´¯è®¡è¦†ç›–ç‡: {cumulative_coverage*100:.1f}%")

    def on_train_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):
        """è®­ç»ƒç»“æŸæ—¶ç”Ÿæˆæœ€ç»ˆè¦†ç›–ç‡æŠ¥å‘Š"""
        if not self.curriculum_manager:
            return
            
        self._write_coverage_log("ğŸ è®­ç»ƒç»“æŸ - ç”Ÿæˆæœ€ç»ˆè¦†ç›–ç‡æŠ¥å‘Š")
        
        total_samples = len(self.curriculum_manager.full_dataset)
        
        # ç»Ÿè®¡æ¯ä¸ªé˜¶æ®µçš„ä½¿ç”¨æƒ…å†µ
        self._write_coverage_log("ğŸ“ˆ å„é˜¶æ®µæ•°æ®ä½¿ç”¨ç»Ÿè®¡:")
        for stage_name, usage in self.stage_sample_usage.items():
            count = len(usage)
            ratio = count / total_samples if total_samples > 0 else 0
            self._write_coverage_log(f"  - {stage_name}: {count} æ ·æœ¬ ({ratio*100:.1f}%)")
        
        # æ€»ä½“è¦†ç›–ç‡
        all_used = set()
        for usage in self.stage_sample_usage.values():
            all_used.update(usage)
        
        final_coverage = len(all_used) / total_samples if total_samples > 0 else 0
        unused_count = total_samples - len(all_used)
        
        self._write_coverage_log(f"ğŸ“Š æœ€ç»ˆè¦†ç›–ç‡ç»Ÿè®¡:")
        self._write_coverage_log(f"  - æ€»æ ·æœ¬æ•°: {total_samples}")
        self._write_coverage_log(f"  - å·²ä½¿ç”¨æ ·æœ¬: {len(all_used)} ({final_coverage*100:.1f}%)")
        self._write_coverage_log(f"  - æœªä½¿ç”¨æ ·æœ¬: {unused_count} ({(1-final_coverage)*100:.1f}%)")
        
        if unused_count > 0:
            self._write_coverage_log(f"âš ï¸ è­¦å‘Š: {unused_count} ä¸ªæ ·æœ¬åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ä»æœªè¢«ä½¿ç”¨!")
        else:
            self._write_coverage_log("âœ… æ‰€æœ‰æ•°æ®æ ·æœ¬éƒ½è¢«ä½¿ç”¨äº†")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        self._save_detailed_coverage_report()

    def _save_detailed_coverage_report(self):
        """ä¿å­˜è¯¦ç»†çš„è¦†ç›–ç‡æŠ¥å‘Š"""
        if not self.output_dir:
            return
            
        report_file = os.path.join(self.output_dir, "dataset_coverage_detailed_report.json")
        
        total_samples = len(self.curriculum_manager.full_dataset)
        all_used = set()
        for usage in self.stage_sample_usage.values():
            all_used.update(usage)
        
        report_data = {
            "timestamp": datetime.now().isoformat(),
            "total_samples": total_samples,
            "total_used_samples": len(all_used),
            "final_coverage_ratio": len(all_used) / total_samples if total_samples > 0 else 0,
            "unused_sample_count": total_samples - len(all_used),
            "stage_usage": {
                stage_name: {
                    "sample_count": len(usage),
                    "coverage_ratio": len(usage) / total_samples if total_samples > 0 else 0,
                    "sample_indices": list(usage)
                }
                for stage_name, usage in self.stage_sample_usage.items()
            },
            "unused_sample_indices": list(set(range(total_samples)) - all_used)
        }
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
            self._write_coverage_log(f"ğŸ’¾ è¯¦ç»†è¦†ç›–ç‡æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        except Exception as e:
            self._write_coverage_log(f"âŒ ä¿å­˜è¦†ç›–ç‡æŠ¥å‘Šå¤±è´¥: {e}")