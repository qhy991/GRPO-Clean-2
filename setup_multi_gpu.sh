#!/bin/bash
# setup_multi_gpu.sh - å¿«é€Ÿè®¾ç½®å¤šGPUç¯å¢ƒçš„è„šæœ¬

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() { echo -e "${GREEN}[INFO]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_debug() { echo -e "${BLUE}[DEBUG]${NC} $1"; }

# è·å–è„šæœ¬ç›®å½•
SCRIPT_DIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" &> /dev/null && pwd)

echo "========================================================================"
echo "            å¤šGPUæ¨¡å‹å¹¶è¡Œè®­ç»ƒç¯å¢ƒè®¾ç½®è„šæœ¬"
echo "========================================================================"

# 1. æ£€æŸ¥GPUç¯å¢ƒ
check_gpu_environment() {
    log_info "ğŸ” æ£€æŸ¥GPUç¯å¢ƒ..."
    
    if ! command -v nvidia-smi &> /dev/null; then
        log_error "âŒ nvidia-smiæœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿NVIDIAé©±åŠ¨å·²å®‰è£…"
        exit 1
    fi
    
    GPU_COUNT=$(nvidia-smi --query-gpu=count --format=csv,noheader,nounits | head -1)
    log_info "ğŸ“Š æ£€æµ‹åˆ° ${GPU_COUNT} å¼ GPU"
    
    if [ "${GPU_COUNT}" -lt 2 ]; then
        log_warning "âš ï¸ æ£€æµ‹åˆ°å°‘äº2å¼ GPUï¼Œå¤šGPUå¹¶è¡Œå°†ä¸å¯ç”¨"
        return 1
    fi
    
    log_info "ğŸ’¾ GPUè¯¦ç»†ä¿¡æ¯:"
    nvidia-smi --query-gpu=index,name,memory.total,driver_version --format=csv
    
    return 0
}

# 2. æ£€æŸ¥Pythonç¯å¢ƒ
check_python_environment() {
    log_info "ğŸ æ£€æŸ¥Pythonç¯å¢ƒ..."
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    PYTHON_VERSION=$(python3 --version 2>&1 | cut -d' ' -f2)
    log_info "  Pythonç‰ˆæœ¬: ${PYTHON_VERSION}"
    
    # æ£€æŸ¥å…³é”®åŒ…
    log_info "ğŸ“¦ æ£€æŸ¥å…³é”®PythonåŒ…..."
    
    declare -A packages=(
        ["torch"]="PyTorch"
        ["transformers"]="Transformers"
        ["accelerate"]="Accelerate"
        ["peft"]="PEFT"
        ["trl"]="TRL"
        ["datasets"]="Datasets"
        ["wandb"]="WandB"
    )
    
    missing_packages=()
    
    for package in "${!packages[@]}"; do
        if python3 -c "import ${package}" 2>/dev/null; then
            version=$(python3 -c "import ${package}; print(${package}.__version__)" 2>/dev/null || echo "unknown")
            log_info "  âœ… ${packages[$package]}: ${version}"
        else
            log_error "  âŒ ${packages[$package]}: æœªå®‰è£…"
            missing_packages+=("$package")
        fi
    done
    
    if [ ${#missing_packages[@]} -gt 0 ]; then
        log_error "âŒ ç¼ºå°‘å¿…è¦çš„PythonåŒ…: ${missing_packages[*]}"
        log_info "ğŸ’¡ å®‰è£…å‘½ä»¤:"
        log_info "  pip install torch transformers accelerate peft trl datasets wandb"
        return 1
    fi
    
    return 0
}

# 3. æ£€æŸ¥CUDAå…¼å®¹æ€§
check_cuda_compatibility() {
    log_info "ğŸ”§ æ£€æŸ¥CUDAå…¼å®¹æ€§..."
    
    # æ£€æŸ¥CUDAç‰ˆæœ¬
    if command -v nvcc &> /dev/null; then
        CUDA_VERSION=$(nvcc --version | grep "release" | sed 's/.*release \([0-9.]*\).*/\1/')
        log_info "  CUDAç‰ˆæœ¬: ${CUDA_VERSION}"
    else
        log_warning "  âš ï¸ nvccæœªæ‰¾åˆ°ï¼Œæ— æ³•æ£€æµ‹CUDAç‰ˆæœ¬"
    fi
    
    # æ£€æŸ¥PyTorch CUDAæ”¯æŒ
    if python3 -c "import torch; print(f'PyTorch CUDAå¯ç”¨: {torch.cuda.is_available()}')" 2>/dev/null; then
        TORCH_CUDA_VERSION=$(python3 -c "import torch; print(torch.version.cuda)" 2>/dev/null || echo "unknown")
        log_info "  PyTorch CUDAç‰ˆæœ¬: ${TORCH_CUDA_VERSION}"
        
        # æµ‹è¯•GPUé€šä¿¡
        log_info "ğŸ”— æµ‹è¯•GPUé—´é€šä¿¡..."
        if python3 -c "
import torch
if torch.cuda.device_count() >= 2:
    try:
        x = torch.randn(1000, 1000, device='cuda:0')
        y = x.to('cuda:1')
        z = y.to('cuda:0')
        print(f'âœ… GPUé€šä¿¡æµ‹è¯•æˆåŠŸ: æ•°æ®ä¸€è‡´æ€§ {torch.allclose(x, z)}')
    except Exception as e:
        print(f'âŒ GPUé€šä¿¡æµ‹è¯•å¤±è´¥: {e}')
        exit(1)
else:
    print('âš ï¸ GPUæ•°é‡ä¸è¶³ï¼Œè·³è¿‡é€šä¿¡æµ‹è¯•')
"; then
            log_info "  âœ… GPUé€šä¿¡æ­£å¸¸"
        else
            log_error "  âŒ GPUé€šä¿¡æµ‹è¯•å¤±è´¥"
            return 1
        fi
    else
        log_error "  âŒ PyTorch CUDAä¸å¯ç”¨"
        return 1
    fi
    
    return 0
}

# 4. è®¾ç½®Accelerateé…ç½®
setup_accelerate_config() {
    log_info "âš™ï¸ è®¾ç½®Accelerateé…ç½®..."
    
    CONFIG_FILE="${SCRIPT_DIR}/accelerate_config_multi_gpu.yaml"
    
    # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
    if [ ! -f "${CONFIG_FILE}" ]; then
        log_info "ğŸ“ åˆ›å»ºAccelerateé…ç½®æ–‡ä»¶..."
        cat > "${CONFIG_FILE}" << 'EOF'
compute_environment: LOCAL_MACHINE
distributed_type: MULTI_GPU
downcast_bf16: 'no'
gpu_ids: '0,1'
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 2
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
EOF
        log_info "  âœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º: ${CONFIG_FILE}"
    else
        log_info "  âœ… é…ç½®æ–‡ä»¶å·²å­˜åœ¨: ${CONFIG_FILE}"
    fi
    
    # éªŒè¯é…ç½®
    if accelerate config --config_file "${CONFIG_FILE}" 2>/dev/null; then
        log_info "  âœ… Accelerateé…ç½®éªŒè¯é€šè¿‡"
    else
        log_warning "  âš ï¸ Accelerateé…ç½®éªŒè¯å¤±è´¥ï¼Œä½†æ–‡ä»¶å·²åˆ›å»º"
    fi
    
    return 0
}

# 5. åˆ›å»ºä¾¿æ·è„šæœ¬
create_convenience_scripts() {
    log_info "ğŸ“œ åˆ›å»ºä¾¿æ·è„šæœ¬..."
    
    # GPUç›‘æ§è„šæœ¬
    GPU_MONITOR="${SCRIPT_DIR}/monitor_gpu.sh"
    cat > "${GPU_MONITOR}" << 'EOF'
#!/bin/bash
# å®æ—¶GPUç›‘æ§è„šæœ¬
echo "æŒ‰ Ctrl+C åœæ­¢ç›‘æ§"
echo "========================================"
while true; do
    clear
    echo "GPUçŠ¶æ€ç›‘æ§ - $(date)"
    echo "========================================"
    nvidia-smi --query-gpu=index,name,temperature.gpu,memory.used,memory.total,utilization.gpu --format=csv
    echo ""
    echo "è¿›ç¨‹ä¿¡æ¯:"
    nvidia-smi pmon -c 1 2>/dev/null || echo "æ— GPUè¿›ç¨‹"
    sleep 2
done
EOF
    chmod +x "${GPU_MONITOR}"
    log_info "  âœ… GPUç›‘æ§è„šæœ¬: ${GPU_MONITOR}"
    
    # å†…å­˜æ¸…ç†è„šæœ¬
    GPU_CLEANUP="${SCRIPT_DIR}/cleanup_gpu.sh"
    cat > "${GPU_CLEANUP}" << 'EOF'
#!/bin/bash
# GPUå†…å­˜æ¸…ç†è„šæœ¬
echo "ğŸ§¹ æ¸…ç†GPUå†…å­˜..."

# æ€æ­»æ‰€æœ‰Python GPUè¿›ç¨‹ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
# pkill -f "python.*cuda" 2>/dev/null || true

# æ¸…ç†PyTorchç¼“å­˜
python3 -c "
import torch
if torch.cuda.is_available():
    for i in range(torch.cuda.device_count()):
        torch.cuda.set_device(i)
        torch.cuda.empty_cache()
        print(f'âœ… GPU {i} å†…å­˜å·²æ¸…ç†')
else:
    print('âŒ CUDAä¸å¯ç”¨')
"

echo "âœ… GPUå†…å­˜æ¸…ç†å®Œæˆ"
nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv
EOF
    chmod +x "${GPU_CLEANUP}"
    log_info "  âœ… GPUæ¸…ç†è„šæœ¬: ${GPU_CLEANUP}"
    
    # å¿«é€Ÿæµ‹è¯•è„šæœ¬
    QUICK_TEST="${SCRIPT_DIR}/test_multi_gpu.sh"
    cat > "${QUICK_TEST}" << 'EOF'
#!/bin/bash
# å¿«é€Ÿå¤šGPUæµ‹è¯•è„šæœ¬
echo "ğŸ§ª å¤šGPUåŠŸèƒ½æµ‹è¯•..."

python3 << 'PYEOF'
import torch
import torch.distributed as dist
from transformers import AutoTokenizer, AutoModelForCausalLM
import time

def test_multi_gpu():
    print(f"ğŸ” æ£€æµ‹ç¯å¢ƒ:")
    print(f"  - CUDAå¯ç”¨: {torch.cuda.is_available()}")
    print(f"  - GPUæ•°é‡: {torch.cuda.device_count()}")
    
    if torch.cuda.device_count() < 2:
        print("âš ï¸ éœ€è¦è‡³å°‘2å¼ GPUè¿›è¡Œæµ‹è¯•")
        return False
    
    try:
        print(f"\nğŸ”§ æµ‹è¯•GPUé€šä¿¡...")
        # åŸºæœ¬GPUé€šä¿¡æµ‹è¯•
        x = torch.randn(1000, 1000, device='cuda:0', dtype=torch.float16)
        y = x.to('cuda:1')
        z = y.back()
        
        print(f"  âœ… æ•°æ®ä¼ è¾“æˆåŠŸï¼Œä¸€è‡´æ€§: {torch.allclose(x, z)}")
        
        # æµ‹è¯•å†…å­˜åˆ†é…
        print(f"\nğŸ’¾ æµ‹è¯•å†…å­˜åˆ†é…...")
        for i in range(torch.cuda.device_count()):
            allocated = torch.cuda.memory_allocated(i) / 1024**3
            reserved = torch.cuda.memory_reserved(i) / 1024**3
            total = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"  GPU {i}: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved, {total:.2f}GB total")
        
        print(f"\nâœ… å¤šGPUæµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ å¤šGPUæµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = test_multi_gpu()
    exit(0 if success else 1)
PYEOF
EOF
    chmod +x "${QUICK_TEST}"
    log_info "  âœ… å¿«é€Ÿæµ‹è¯•è„šæœ¬: ${QUICK_TEST}"
    
    return 0
}

# 6. éªŒè¯è®¾ç½®
verify_setup() {
    log_info "âœ… éªŒè¯å¤šGPUè®¾ç½®..."
    
    # è¿è¡Œå¿«é€Ÿæµ‹è¯•
    if [ -f "${SCRIPT_DIR}/test_multi_gpu.sh" ]; then
        log_info "ğŸ§ª è¿è¡Œå¿«é€Ÿæµ‹è¯•..."
        if "${SCRIPT_DIR}/test_multi_gpu.sh"; then
            log_info "  âœ… å¤šGPUè®¾ç½®éªŒè¯æˆåŠŸ"
        else
            log_warning "  âš ï¸ å¤šGPUæµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œä½†åŸºç¡€è®¾ç½®å·²å®Œæˆ"
        fi
    fi
    
    # æ£€æŸ¥æ¨¡å‹ç®¡ç†å™¨é…ç½®
    if [ -f "${SCRIPT_DIR}/grpo_project/core/models.py" ]; then
        if grep -q "use_multi_gpu" "${SCRIPT_DIR}/grpo_project/core/models.py" 2>/dev/null; then
            log_info "  âœ… ModelManagerå·²é…ç½®å¤šGPUæ”¯æŒ"
        else
            log_warning "  âš ï¸ ModelManagerå¯èƒ½éœ€è¦æ›´æ–°ä»¥æ”¯æŒå¤šGPU"
        fi
    fi
    
    return 0
}

# 7. æä¾›ä½¿ç”¨è¯´æ˜
show_usage_instructions() {
    echo ""
    echo "========================================================================"
    echo "                        ä½¿ç”¨è¯´æ˜"
    echo "========================================================================"
    log_info "ğŸš€ å¤šGPUç¯å¢ƒè®¾ç½®å®Œæˆï¼"
    echo ""
    log_info "ğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:"
    echo ""
    echo "1. å¯åŠ¨è®­ç»ƒ:"
    echo "   ./run_enhanced_grpo_training_multi_gpu.sh"
    echo ""
    echo "2. ç›‘æ§GPUçŠ¶æ€:"
    echo "   ./monitor_gpu.sh"
    echo ""
    echo "3. æ¸…ç†GPUå†…å­˜(å¦‚éœ€è¦):"
    echo "   ./cleanup_gpu.sh"
    echo ""
    echo "4. å¿«é€Ÿæµ‹è¯•å¤šGPUåŠŸèƒ½:"
    echo "   ./test_multi_gpu.sh"
    echo ""
    log_info "âš™ï¸ é…ç½®æ–‡ä»¶:"
    echo "   - Accelerateé…ç½®: ./accelerate_config_multi_gpu.yaml"
    echo "   - è®­ç»ƒè„šæœ¬: ./run_enhanced_grpo_training_multi_gpu.sh"
    echo ""
    log_info "ğŸ”§ å¦‚æœé‡åˆ°é—®é¢˜:"
    echo "   1. æ£€æŸ¥GPUçŠ¶æ€: nvidia-smi"
    echo "   2. éªŒè¯CUDA: python3 -c 'import torch; print(torch.cuda.is_available())'"
    echo "   3. æ¸…ç†å†…å­˜: ./cleanup_gpu.sh"
    echo "   4. é‡æ–°è¿è¡Œæ­¤è®¾ç½®è„šæœ¬"
    echo ""
    log_info "ğŸ“Š æ¨èçš„è®­ç»ƒé…ç½®(å·²åœ¨è®­ç»ƒè„šæœ¬ä¸­è®¾ç½®):"
    echo "   - åºåˆ—é•¿åº¦: 6144 (å……åˆ†åˆ©ç”¨å†…å­˜)"
    echo "   - æ‰¹æ¬¡å¤§å°: 2 per GPU"
    echo "   - LoRA rank: 64 (é€‚ä¸­çš„å‚æ•°é‡)"
    echo "   - ç²¾åº¦: bfloat16 (æœ€ä½³æ€§èƒ½)"
    echo ""
}

# ä¸»æ‰§è¡Œæµç¨‹
main() {
    log_info "ğŸš€ å¼€å§‹å¤šGPUç¯å¢ƒè®¾ç½®..."
    
    # 1. æ£€æŸ¥GPUç¯å¢ƒ
    if ! check_gpu_environment; then
        log_error "âŒ GPUç¯å¢ƒæ£€æŸ¥å¤±è´¥"
        exit 1
    fi
    
    # 2. æ£€æŸ¥Pythonç¯å¢ƒ
    if ! check_python_environment; then
        log_error "âŒ Pythonç¯å¢ƒæ£€æŸ¥å¤±è´¥"
        exit 1
    fi
    
    # 3. æ£€æŸ¥CUDAå…¼å®¹æ€§
    if ! check_cuda_compatibility; then
        log_error "âŒ CUDAå…¼å®¹æ€§æ£€æŸ¥å¤±è´¥"
        exit 1
    fi
    
    # 4. è®¾ç½®Accelerateé…ç½®
    setup_accelerate_config
    
    # 5. åˆ›å»ºä¾¿æ·è„šæœ¬
    create_convenience_scripts
    
    # 6. éªŒè¯è®¾ç½®
    verify_setup
    
    # 7. æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    show_usage_instructions
    
    log_info "âœ… å¤šGPUç¯å¢ƒè®¾ç½®å®Œæˆï¼"
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"